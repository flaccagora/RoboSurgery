\chapter{Introduction}

The advancement of robotic systems has significantly improved minimally 
invasive surgery, allowing for smaller incisions, reduced blood loss, and faster recovery times, 
while enabling complex procedures that require exceptional dexterity and visualization capabilities.
The marriage of robotic surgery and AI promises further innovations which could redefine 
healthcare access and delivery on a global scale.
Among these, remote surgical capabilities, enhanced imaging technologies, real-time decision 
support, personalized treatments and autonomous surgical systems are some of the most promising applications
of AI in healthcare. 

As robotic-assisted surgical techniques gain traction - increasingly relevant as the demand for minimally 
invasive approaches grows -
the integration of \gls{rl} algorithms into these workflows has become notable for its potential to 
transform patient outcomes enhanceing once more surgical precision. 

The development of \gls{rl} techniques in this field leverages the ability of algorithms to learn 
from complex interactions within dynamic environments by training robotic systems to 
optimize intricate tasks through feedback mechanisms, \gls{rl} not only enhances the operational efficiency 
of surgical robots but also contributes to more informed preoperative planning through predictive 
analytics. 
These advancements allow for tailored risk assessments that improve decision-making in patient care.


Despite its promise, integration of such techniques into minimally surgery faces
challenges, including the need for robust regulatory frameworks and ongoing ethical scrutiny.
Moreover manipulating and navigating in deformable environments, such as soft tissues, 
remains a major challenge due to their dynamic and unpredictable nature. 
Traditional control algorithms struggle to adapt to these uncertainties, leading to 
suboptimal performance and potential risks during surgical procedures. 

Overall, the ongoing research and development in \gls{rl} for minimally 
surgery exemplify a transformative potential in the healthcare landscape, with opportunities for 
improving surgical techniques, outcomes, and training methods while navigating the complexities 
of integrating AI into human-centered care.

% Methodology
\section{Problem Statement}
\gls{rl} has emerged as a promising approach, 
however, applying \gls{rl} to robotic surgery introduces additional challenges, since surgical environments 
are inherently partially observable, as direct and complete state information is 
often unavailable due to occlusions, sensor noise, and real-time constraints. 
Existing \gls{rl} techniques often assume full observability, limiting their 
effectiveness in real-world surgical applications.

This thesis aims to address these challenges by developing \gls{rl}-based 
strategies for minimally invasive robotic surgery, specifically focused on deformable environment navigation 
and manipulation under partial observability. The research will explore 
\gls{pomdp}-based RL frameworks, integrating advanced perception models, uncertainty-aware 
decision-making, and efficient policy learning methods. The goal is to enhance 
robotic surgical capabilities by improving adaptability, robustness, and precision 
in deformable tissue interactions, ultimately contributing to safer and more reliable 
autonomous surgical systems.


% \paragraph{Research Context}
% Robotic surgery represents a critical frontier in medical technology, where precise manipulation and navigation of surgical instruments in complex, deformable environments demand advanced computational approaches. Traditional control methods struggle to address the inherent uncertainties and dynamic challenges present in surgical scenarios, particularly when dealing with soft tissues and organs that exhibit non-linear deformation characteristics.

% \paragraph{Current Limitations}
% Existing robotic surgical systems face significant challenges in:
% \begin{itemize}
%     \item Accurately modeling and predicting soft tissue deformation during surgical interventions
%     \item Handling partial observability of the surgical environment
%     \item Adapting to real-time changes in tissue geometry and mechanical properties
%     \item Developing robust control strategies that can generalize across different surgical tasks and anatomical configurations
% \end{itemize}

% \paragraph{Research Objectives}
% The primary objectives of this research are to:
% \begin{itemize}
%     \item Develop a reinforcement learning framework specifically tailored to \glspl{pomdp} in robotic surgical navigation
%     \item Create a computational model that can effectively learn and adapt to deformable environment dynamics
%     \item Demonstrate improved precision and adaptability in robotic instrument manipulation compared to existing control methodologies
%     \item Investigate the potential of deep reinforcement learning techniques in mitigating uncertainty in surgical navigation
% \end{itemize}

% \paragraph{Methodological Approach}
% The proposed research will:
% \begin{itemize}
%     \item Utilize advanced deep reinforcement learning algorithms, with a focus on POMDP-based approaches
%     \item Implement simulation-based training environments that accurately model soft tissue mechanical properties
%     \item Develop state estimation and observation strategies to address partial observability challenges
%     \item Evaluate performance through comprehensive metrics of navigation accuracy, adaptation speed, and generalization capability
% \end{itemize}

% \paragraph{Potential Impact}
% By addressing these challenges, the research aims to:
% \begin{itemize}
%     \item Enhance the autonomy and precision of robotic surgical systems
%     \item Provide a foundational framework for adaptive robotic manipulation in complex medical environments
%     \item Contribute to the advancement of machine learning techniques in critical medical technologies
% \end{itemize}

% \gls{pomdp}s, with their capacity to model uncertainty, and RL, with its learning-based adaptability, 
% present a promising synergy for addressing these challenges. However, their 
% application to real-time intraoperative decision-making remains unexplored.


\section{Related Work}

While robotic systems have drastically improved surgeon skills, they still 
only replicate motions performed by surgeons in a console, lacking the 
ability to adapt to unexpected intraoperative changes autonomously. 

To address these limitations, integration of
Computer vision, \gls{dl} and \gls{rl} has been explored to possibly enhance the 
autonomy and adaptability of robotic systems in surgical environments.

Computer vision techniques such as classification, detection and segmentation, have been used to recognize anatomical structures
and surgical instruments to provide support and valuable intraoperative information 
to the surgeon and eventually to autonomous robotic systems 
\citep{AMPARORE2022e312, cancers16051047}. 

\gls{rl} algorithms have been tested in simulation based training 
environments to directly control robotic systems for surgical tasks. 
The need for simulation is dual, it provides a safe environment
and it allows to circumvent the high costs of real-world needs amplifyed 
by sample inefficience of \gls{rl}. 
The policy learned in simulation can then be transferred to the real-world setting, 
where it can be further fine-tuned to account for the discrepancies between 
the two environments \citep{10065553}.


A large number of recent research focuses on the automation of surgical sub-tasks, 
such as needle manipulation \citep{10100702}, suturing \citep{9223543}, cutting \citep{Shahkoo2023},
vessel manipulation \citep{10160966}, blood suction \citep{10578312}, tissue retraction and
deformation \citep{9976185}. Imitation Learning and expert demonstrations have shown to be effective in
training robotic systems for surgical tasks \citep{kim2024surgicalrobottransformersrt}.

% The formalization of the surgical task as a \gls{pomdp} has not been widely explored. 


