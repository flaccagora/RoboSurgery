{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import itertools\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from agents.dqn import DoubleDQNAgent, QNetwork\n",
    "from env import GridEnvDeform, POMDPWrapper_v0, create_maze\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maze size\n",
    "N = 2\n",
    "\n",
    "# thetas deformations (range(a,b),range(c,d))\n",
    "l0 = 1\n",
    "h0 = 3\n",
    "l1 = 1\n",
    "h1 = 2\n",
    "\n",
    "maze = np.load(\"maze/maze_2.npy\")\n",
    "env = GridEnvDeform(maze,l0,h0,l1,h1)\n",
    "env.render()\n",
    "\n",
    "states = [((x,y,phi),(i,j)) for x in range(1,env.max_shape[0]-1) for y in range(1,env.max_shape[1]-1) for phi in range(4) for i in range(l0,h0) for j in range(l1,h1)] \n",
    "actions = [0,1,2,3]\n",
    "obs = list(itertools.product([0,1], repeat=5))\n",
    "thetas = [(i,j) for i in range(l0,h0) for j in range(l1,h1)]\n",
    "\n",
    "state_dict = {state: i for i, state in enumerate(states)}\n",
    "obs_dict = {obs : i for i, obs in enumerate(obs)}\n",
    "\n",
    "# Actions are: 0-listen, 1-open-left, 2-open-right\n",
    "lenS = len(states)\n",
    "lenA = len(actions)\n",
    "lenO = len(obs)\n",
    "\n",
    "print(f\"States: {lenS}, Actions: {lenA}, Observations {lenO}, Thetas {thetas}\\n\")\n",
    "\n",
    "\n",
    "print(\"setting reward function\\n\")\n",
    "R = torch.zeros(lenS,lenA,lenS)\n",
    "for s in range(lenS):\n",
    "    for a in range(lenA):\n",
    "        r = env.R(states[s],a)\n",
    "        for s_ in range(lenS):\n",
    "            R[s][a][s_] = r\n",
    "\n",
    "print(\"setting transition function\\n\")\n",
    "T = torch.zeros(lenS,lenA,lenS)\n",
    "for s, state in enumerate(states):\n",
    "    for a, action in enumerate(actions):\n",
    "        for s_, state_ in enumerate(states):\n",
    "            T[s,a,s_] = env.T(state,action,state_)\n",
    "\n",
    "print(\"setting observation function\\n\")\n",
    "O = torch.zeros(lenS,lenA,lenO)\n",
    "for s, state in enumerate(states):\n",
    "    for o, observation in enumerate(obs):\n",
    "        prob = env.O(state,action,observation)\n",
    "        for a, action in enumerate(actions):\n",
    "            O[s,a,o] = prob \n",
    "\n",
    "\n",
    "    for a in range(lenA):\n",
    "        r = env.R(states[s],a)\n",
    "        for s_ in range(lenS):\n",
    "            R[s][a][s_] = r\n",
    "\n",
    "print(\"setting transition function\\n\")\n",
    "T = torch.zeros(lenS,lenA,lenS)\n",
    "for s, state in enumerate(states):\n",
    "    for a, action in enumerate(actions):\n",
    "        for s_, state_ in enumerate(states):\n",
    "            T[s,a,s_] = env.T(state,action,state_)\n",
    "\n",
    "print(\"setting observation function\\n\")\n",
    "O = torch.zeros(lenS,lenA,lenO)\n",
    "for s, state in enumerate(states):\n",
    "    for o, observation in enumerate(obs):\n",
    "        prob = env.O(state,action,observation)\n",
    "        for a, action in enumerate(actions):\n",
    "            O[s,a,o] = prob \n",
    "\n",
    "\n",
    "\n",
    "print(\"transition probability shape: \", T.shape)\n",
    "print(\"reward shape: \", R.shape)\n",
    "print(\"observation shape: \", O.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(T, \"T_maze_2.pt\")\n",
    "torch.save(R, \"R_maze_2.pt\")\n",
    "torch.save(O, \"O_maze_2.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
