{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import itertools\n",
    "\n",
    "from dqn import DoubleDQNAgent\n",
    "from env import GridEnvDeform, POMDPWrapper_v0, create_maze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFhCAYAAAAsiOM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATtklEQVR4nO3dX2yVBx3/8W+h9rA/pcImjEph081NhtQNBkH8gwO3EEK2m20xM1amJjNFQWKy9Eb0wpUbzaaSDubcTJSwZQlMlwAi0pIlI0AJCZvJdLpolUFdoqV0Sbe053dlfz9+G87Dvuc8lL5eyZPsHM7Z8zlhS9+c85TWlcvlcgAAJJhU9AAA4NIhLACANMICAEgjLACANMICAEgjLACANMICAEhTX+sTjo6OxsmTJ6OxsTHq6upqfXoA4AKUy+UYHByM5ubmmDTp/O9L1DwsTp48GS0tLbU+LQCQoK+vL2bPnn3eX695WDQ2NkZExDPPPBOXX355rU8PAFyAN998M+69996xr+PnU/Ow+M/HH5dffnlcccUVtT49APA+vNdlDC7eBADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSXFBYbNmyJa699tqYMmVKLFmyJA4fPpy9CwAYhyoOi6effjo2btwYmzZtimPHjkVra2vceeed0d/fX419AMA4UnFY/OhHP4qvf/3rsXbt2pg3b1489thjcfnll8fPf/7zd3388PBwnDlz5pwDALg0VRQWb731VvT29sbKlSv/779g0qRYuXJlvPjii+/6nM7Ozmhqaho7Wlpa3t9iAOCiVVFYvPHGGzEyMhIzZ8485/6ZM2fGqVOn3vU5HR0dMTAwMHb09fVd+FoA4KJWX+0TlEqlKJVK1T4NAHARqOgdi6uvvjomT54cp0+fPuf+06dPxzXXXJM6DAAYfyoKi4aGhli4cGHs379/7L7R0dHYv39/LF26NH0cADC+VPxRyMaNG6OtrS0WLVoUixcvjkceeSSGhoZi7dq11dgHAIwjFYfFfffdF//85z/ju9/9bpw6dSo++clPxp49e95xQScAMPFc0MWb69ati3Xr1mVvAQDGOT8rBABIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIU1/0gIlk+fLlRU8AIEF3d3fREy5a3rEAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANJUHBYHDx6MNWvWRHNzc9TV1cWuXbuqMAsAGI8qDouhoaFobW2NLVu2VGMPADCO1Vf6hFWrVsWqVav+58cPDw/H8PDw2O0zZ85UekoAYJyo+jUWnZ2d0dTUNHa0tLRU+5QAQEGqHhYdHR0xMDAwdvT19VX7lABAQSr+KKRSpVIpSqVStU8DAFwEfLspAJBGWAAAaSr+KOTs2bPx6quvjt1+7bXX4vjx4zF9+vSYM2dO6jgAYHypOCyOHj0an//858dub9y4MSIi2tra4qmnnkobBgCMPxWHxfLly6NcLldjCwAwzrnGAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIU1/0gImku7u76AlAlSxfvrzoCXBR8I4FAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJCmorDo7OyM2267LRobG2PGjBlx9913xyuvvFKtbQDAOFNRWPT09ER7e3scOnQo9u3bF2+//XbccccdMTQ0VK19AMA4Ul/Jg/fs2XPO7aeeeipmzJgRvb298dnPfvZdnzM8PBzDw8Njt8+cOXMBMwGA8eB9XWMxMDAQERHTp08/72M6Ozujqalp7GhpaXk/pwQALmIXHBajo6OxYcOGWLZsWcyfP/+8j+vo6IiBgYGxo6+v70JPCQBc5Cr6KOT/1d7eHi+99FK88MIL//VxpVIpSqXShZ4GABhHLigs1q1bF88//3wcPHgwZs+enb0JABinKgqLcrkc3/zmN2Pnzp3R3d0d1113XbV2AQDjUEVh0d7eHtu3b4/nnnsuGhsb49SpUxER0dTUFJdddllVBgIA40dFF292dXXFwMBALF++PGbNmjV2PP3009XaBwCMIxV/FAIAcD5+VggAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkKa+6AETyfLly4ueAJCqrq6u6AmFOHDgQNETLlresQAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0lQUFl1dXbFgwYKYOnVqTJ06NZYuXRq7d++u1jYAYJypKCxmz54dmzdvjt7e3jh69Gjcfvvtcdddd8XLL79crX0AwDhSX8mD16xZc87tH/zgB9HV1RWHDh2Km2+++V2fMzw8HMPDw2O3z5w5cwEzAYDx4IKvsRgZGYkdO3bE0NBQLF269LyP6+zsjKamprGjpaXlQk8JAFzkKg6LEydOxJVXXhmlUikefPDB2LlzZ8ybN++8j+/o6IiBgYGxo6+v730NBgAuXhV9FBIRceONN8bx48djYGAgnn322Whra4uenp7zxkWpVIpSqfS+hwIAF7+Kw6KhoSGuv/76iIhYuHBhHDlyJB599NHYunVr+jgAYHx533+Pxejo6DkXZwIAE1dF71h0dHTEqlWrYs6cOTE4OBjbt2+P7u7u2Lt3b7X2AQDjSEVh0d/fH1/+8pfj9ddfj6ampliwYEHs3bs3vvCFL1RrHwAwjlQUFk888US1dgAAlwA/KwQASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASFNf9ICJpLu7u+gJAKkOHDhQ9AQuMt6xAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAIM37CovNmzdHXV1dbNiwIWkOADCeXXBYHDlyJLZu3RoLFizI3AMAjGMXFBZnz56N+++/Px5//PGYNm1a9iYAYJy6oLBob2+P1atXx8qVK9/zscPDw3HmzJlzDgDg0lRf6RN27NgRx44diyNHjvxPj+/s7Izvf//7FQ8DAMafit6x6Ovri/Xr18evfvWrmDJlyv/0nI6OjhgYGBg7+vr6LmgoAHDxq+gdi97e3ujv749bb7117L6RkZE4ePBg/PSnP43h4eGYPHnyOc8plUpRKpVy1gIAF7WKwmLFihVx4sSJc+5bu3Zt3HTTTfHQQw+9IyoAgImlorBobGyM+fPnn3PfFVdcEVddddU77gcAJh5/8yYAkKbi7wr5/3V3dyfMAAAuBd6xAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADS1Nf6hOVyOSIi3nzzzVqfGgC4QP/5uv2fr+PnU1d+r0ck+/vf/x4tLS21PCUAkKSvry9mz5593l+veViMjo7GyZMno7GxMerq6mp56jhz5ky0tLREX19fTJ06tabnLpLX7XVPBF631z0RFPm6y+VyDA4ORnNzc0yadP4rKWr+UcikSZP+a+nUwtSpUyfUf4j/4XVPLF73xOJ1TyxFve6mpqb3fIyLNwGANMICAEgzocKiVCrFpk2bolQqFT2lprxur3si8Lq97olgPLzuml+8CQBcuibUOxYAQHUJCwAgjbAAANIICwAgjbAAANJMmLDYsmVLXHvttTFlypRYsmRJHD58uOhJVXfw4MFYs2ZNNDc3R11dXezatavoSVXX2dkZt912WzQ2NsaMGTPi7rvvjldeeaXoWVXX1dUVCxYsGPvb+JYuXRq7d+8uelbNbd68Oerq6mLDhg1FT6mq733ve1FXV3fOcdNNNxU9qyb+8Y9/xJe+9KW46qqr4rLLLotPfOITcfTo0aJnVdW11177jt/vurq6aG9vL3rau5oQYfH000/Hxo0bY9OmTXHs2LFobW2NO++8M/r7+4ueVlVDQ0PR2toaW7ZsKXpKzfT09ER7e3scOnQo9u3bF2+//XbccccdMTQ0VPS0qpo9e3Zs3rw5ent74+jRo3H77bfHXXfdFS+//HLR02rmyJEjsXXr1liwYEHRU2ri5ptvjtdff33seOGFF4qeVHX/+te/YtmyZfGBD3wgdu/eHX/4wx/ihz/8YUybNq3oaVV15MiRc36v9+3bFxER99xzT8HLzqM8ASxevLjc3t4+dntkZKTc3Nxc7uzsLHBVbUVEeefOnUXPqLn+/v5yRJR7enqKnlJz06ZNK//sZz8rekZNDA4Olm+44Ybyvn37yp/73OfK69evL3pSVW3atKnc2tpa9Iyae+ihh8qf/vSni55RuPXr15c/+tGPlkdHR4ue8q4u+Xcs3nrrrejt7Y2VK1eO3Tdp0qRYuXJlvPjiiwUuoxYGBgYiImL69OkFL6mdkZGR2LFjRwwNDcXSpUuLnlMT7e3tsXr16nP+P7/U/elPf4rm5ub4yEc+Evfff3/87W9/K3pS1f3617+ORYsWxT333BMzZsyIW265JR5//PGiZ9XUW2+9Fb/85S/jgQceqPlPCP9fXfJh8cYbb8TIyEjMnDnznPtnzpwZp06dKmgVtTA6OhobNmyIZcuWxfz584ueU3UnTpyIK6+8MkqlUjz44IOxc+fOmDdvXtGzqm7Hjh1x7Nix6OzsLHpKzSxZsiSeeuqp2LNnT3R1dcVrr70Wn/nMZ2JwcLDoaVX1l7/8Jbq6uuKGG26IvXv3xje+8Y341re+Fb/4xS+KnlYzu3btin//+9/xla98pegp51XzH5sOtdLe3h4vvfTShPjsOSLixhtvjOPHj8fAwEA8++yz0dbWFj09PZd0XPT19cX69etj3759MWXKlKLn1MyqVavG/nnBggWxZMmSmDt3bjzzzDPx1a9+tcBl1TU6OhqLFi2Khx9+OCIibrnllnjppZfisccei7a2toLX1cYTTzwRq1atiubm5qKnnNcl/47F1VdfHZMnT47Tp0+fc//p06fjmmuuKWgV1bZu3bp4/vnn48CBAzF79uyi59REQ0NDXH/99bFw4cLo7OyM1tbWePTRR4ueVVW9vb3R398ft956a9TX10d9fX309PTEj3/846ivr4+RkZGiJ9bEBz/4wfjYxz4Wr776atFTqmrWrFnvCOWPf/zjE+JjoIiIv/71r/G73/0uvva1rxU95b+65MOioaEhFi5cGPv37x+7b3R0NPbv3z9hPn+eSMrlcqxbty527twZv//97+O6664relJhRkdHY3h4uOgZVbVixYo4ceJEHD9+fOxYtGhR3H///XH8+PGYPHly0RNr4uzZs/HnP/85Zs2aVfSUqlq2bNk7vn38j3/8Y8ydO7egRbX15JNPxowZM2L16tVFT/mvJsRHIRs3boy2trZYtGhRLF68OB555JEYGhqKtWvXFj2tqs6ePXvOn2Bee+21OH78eEyfPj3mzJlT4LLqaW9vj+3bt8dzzz0XjY2NY9fRNDU1xWWXXVbwuurp6OiIVatWxZw5c2JwcDC2b98e3d3dsXfv3qKnVVVjY+M7rp+54oor4qqrrrqkr6v5zne+E2vWrIm5c+fGyZMnY9OmTTF58uT44he/WPS0qvr2t78dn/rUp+Lhhx+Oe++9Nw4fPhzbtm2Lbdu2FT2t6kZHR+PJJ5+Mtra2qK+/yL90F/1tKbXyk5/8pDxnzpxyQ0NDefHixeVDhw4VPanqDhw4UI6IdxxtbW1FT6uad3u9EVF+8skni55WVQ888EB57ty55YaGhvKHPvSh8ooVK8q//e1vi55ViInw7ab33XdfedasWeWGhobyhz/84fJ9991XfvXVV4ueVRO/+c1vyvPnzy+XSqXyTTfdVN62bVvRk2pi79695Ygov/LKK0VPeU915XK5XEzSAACXmkv+GgsAoHaEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGn+D/PuMrxQgvB/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: 144, Actions: 4, Observations 32, Thetas [(1, 1), (2, 1)]\n",
      "\n",
      "setting reward function\n",
      "\n",
      "setting transition function\n",
      "\n",
      "setting observation function\n",
      "\n",
      "transition probability shape:  torch.Size([144, 4, 144])\n",
      "reward shape:  torch.Size([144, 4, 144])\n",
      "observation shape:  torch.Size([144, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "# maze size\n",
    "N = 2\n",
    "\n",
    "# thetas deformations (range(a,b),range(c,d))\n",
    "l0 = 1\n",
    "h0 = 3\n",
    "l1 = 1\n",
    "h1 = 2\n",
    "\n",
    "maze = create_maze(N)\n",
    "env = GridEnvDeform(maze,l0,h0,l1,h1)\n",
    "env.render()\n",
    "\n",
    "states = [((x,y,phi),(i,j)) for x in range(1,env.max_shape[0]-1) for y in range(1,env.max_shape[1]-1) for phi in range(4) for i in range(l0,h0) for j in range(l1,h1)] \n",
    "actions = [0,1,2,3]\n",
    "obs = list(itertools.product([0,1], repeat=5))\n",
    "thetas = [(i,j) for i in range(l0,h0) for j in range(l1,h1)]\n",
    "\n",
    "state_dict = {state: i for i, state in enumerate(states)}\n",
    "obs_dict = {obs : i for i, obs in enumerate(obs)}\n",
    "\n",
    "# Actions are: 0-listen, 1-open-left, 2-open-right\n",
    "lenS = len(states)\n",
    "lenA = len(actions)\n",
    "lenO = len(obs)\n",
    "\n",
    "print(f\"States: {lenS}, Actions: {lenA}, Observations {lenO}, Thetas {thetas}\\n\")\n",
    "\n",
    "\n",
    "print(\"setting reward function\\n\")\n",
    "R = torch.zeros(lenS,lenA,lenS)\n",
    "for s in range(lenS):\n",
    "    for a in range(lenA):\n",
    "        r = env.R(states[s],a)\n",
    "        for s_ in range(lenS):\n",
    "            R[s][a][s_] = r\n",
    "\n",
    "print(\"setting transition function\\n\")\n",
    "T = torch.zeros(lenS,lenA,lenS)\n",
    "for s, state in enumerate(states):\n",
    "    for a, action in enumerate(actions):\n",
    "        for s_, state_ in enumerate(states):\n",
    "            T[s,a,s_] = env.T(state,action,state_)\n",
    "\n",
    "print(\"setting observation function\\n\")\n",
    "O = torch.zeros(lenS,lenA,lenO)\n",
    "for s, state in enumerate(states):\n",
    "    for o, observation in enumerate(obs):\n",
    "        prob = env.O(state,action,observation)\n",
    "        for a, action in enumerate(actions):\n",
    "            O[s,a,o] = prob \n",
    "\n",
    "\n",
    "\n",
    "print(\"transition probability shape: \", T.shape)\n",
    "print(\"reward shape: \", R.shape)\n",
    "print(\"observation shape: \", O.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fully observable train\n",
    "\n",
    "notice that the train is fully observable, in the following cell each transition is \\\n",
    "(1) the current state \\\n",
    "(2) the action taken \\\n",
    "(3) the reward received \\\n",
    "(4) the next state \\\n",
    "(5) the done flag\n",
    "\n",
    "where current state is an int (range(0, len(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(env : POMDPWrapper_v0, agent : DoubleDQNAgent, num_episodes=10):\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        c = 25\n",
    "        while c > 0:\n",
    "            # Render the environment\n",
    "            # env.render()\n",
    "\n",
    "            # Agent takes an action using a greedy policy (without exploration)\n",
    "            action = agent.choose_action([state])\n",
    "            obs, reward, done, info = env.step(state, action)\n",
    "            state = info['actual_state']\n",
    "\n",
    "            episode_reward += reward\n",
    "            \n",
    "            if done or c == 1:\n",
    "                total_rewards.append(episode_reward)\n",
    "                print(f\"Episode {episode + 1}/{num_episodes}, Reward: {episode_reward}\")\n",
    "\n",
    "            c -= 1\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {avg_reward}\")\n",
    "    return avg_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 1\n",
    "action_dim = 4\n",
    "\n",
    "agent = DoubleDQNAgent(state_dim, action_dim)\n",
    "\n",
    "env_wrapper = POMDPWrapper_v0(env, agent, T, O, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "Episode 1/100, Reward: -60, Epsilon: 0.99\n",
      "(1, 1)\n",
      "Episode 2/100, Reward: -151.5, Epsilon: 0.99\n",
      "(1, 1)\n",
      "Episode 3/100, Reward: -15.5, Epsilon: 0.99\n",
      "(1, 1)\n",
      "Episode 4/100, Reward: -62.0, Epsilon: 0.98\n",
      "(1, 1)\n",
      "Episode 5/100, Reward: -9.5, Epsilon: 0.98\n",
      "(1, 1)\n",
      "Episode 6/100, Reward: -10, Epsilon: 0.97\n",
      "(2, 1)\n",
      "Episode 7/100, Reward: -2.0, Epsilon: 0.97\n",
      "(1, 1)\n",
      "Episode 8/100, Reward: -68.5, Epsilon: 0.96\n",
      "(1, 1)\n",
      "Episode 9/100, Reward: -17.5, Epsilon: 0.96\n",
      "(2, 1)\n",
      "Episode 10/100, Reward: -0.5, Epsilon: 0.95\n",
      "(2, 1)\n",
      "Episode 11/100, Reward: 1, Epsilon: 0.95\n",
      "(1, 1)\n",
      "Episode 12/100, Reward: -119.0, Epsilon: 0.94\n",
      "(2, 1)\n",
      "Episode 13/100, Reward: -36.0, Epsilon: 0.94\n",
      "(1, 1)\n",
      "Episode 14/100, Reward: -37.0, Epsilon: 0.93\n",
      "(2, 1)\n",
      "Episode 15/100, Reward: -12.5, Epsilon: 0.93\n",
      "(2, 1)\n",
      "Episode 16/100, Reward: -98.5, Epsilon: 0.92\n",
      "(1, 1)\n",
      "Episode 17/100, Reward: -28.5, Epsilon: 0.92\n",
      "(2, 1)\n",
      "Episode 18/100, Reward: -107.5, Epsilon: 0.91\n",
      "(1, 1)\n",
      "Episode 19/100, Reward: -27.0, Epsilon: 0.91\n",
      "(1, 1)\n",
      "Episode 20/100, Reward: -23.5, Epsilon: 0.90\n",
      "(2, 1)\n",
      "Episode 21/100, Reward: -111.5, Epsilon: 0.90\n",
      "Episode 1/10, Reward: -30.5\n",
      "Episode 2/10, Reward: -24.5\n",
      "Episode 3/10, Reward: -19.0\n",
      "Episode 4/10, Reward: -43.0\n",
      "Episode 5/10, Reward: -20.0\n",
      "Episode 6/10, Reward: -33.0\n",
      "Episode 7/10, Reward: -26.5\n",
      "Episode 8/10, Reward: -40.0\n",
      "Episode 9/10, Reward: -21.0\n",
      "Episode 10/10, Reward: -18.5\n",
      "Average Reward over 10 episodes: -27.6\n",
      "Episode 21/100, Average Reward: -27.6\n",
      "(1, 1)\n",
      "Episode 22/100, Reward: -1.5, Epsilon: 0.90\n",
      "(2, 1)\n",
      "Episode 23/100, Reward: -10.5, Epsilon: 0.89\n",
      "(2, 1)\n",
      "Episode 24/100, Reward: -95.5, Epsilon: 0.89\n",
      "(2, 1)\n",
      "Episode 25/100, Reward: -0.5, Epsilon: 0.88\n",
      "(2, 1)\n",
      "Episode 26/100, Reward: -11.5, Epsilon: 0.88\n",
      "(1, 1)\n",
      "Episode 27/100, Reward: -55.5, Epsilon: 0.87\n",
      "(1, 1)\n",
      "Episode 28/100, Reward: -6.5, Epsilon: 0.87\n",
      "(2, 1)\n",
      "Episode 29/100, Reward: -7.0, Epsilon: 0.86\n",
      "(1, 1)\n",
      "Episode 30/100, Reward: -140.0, Epsilon: 0.86\n",
      "(2, 1)\n",
      "Episode 31/100, Reward: -28.5, Epsilon: 0.86\n",
      "(2, 1)\n",
      "Episode 32/100, Reward: -82.5, Epsilon: 0.85\n",
      "(2, 1)\n",
      "Episode 33/100, Reward: -91.5, Epsilon: 0.85\n",
      "(1, 1)\n",
      "Episode 34/100, Reward: -127.5, Epsilon: 0.84\n",
      "(2, 1)\n",
      "Episode 35/100, Reward: -17.5, Epsilon: 0.84\n",
      "(2, 1)\n",
      "Episode 36/100, Reward: -45.5, Epsilon: 0.83\n",
      "(2, 1)\n",
      "Episode 37/100, Reward: -1, Epsilon: 0.83\n",
      "(1, 1)\n",
      "Episode 38/100, Reward: -6, Epsilon: 0.83\n",
      "(1, 1)\n",
      "Episode 39/100, Reward: -22.5, Epsilon: 0.82\n",
      "(1, 1)\n",
      "Episode 40/100, Reward: -122.0, Epsilon: 0.82\n",
      "(2, 1)\n",
      "Episode 41/100, Reward: -4.5, Epsilon: 0.81\n",
      "Episode 1/10, Reward: -42.0\n",
      "Episode 2/10, Reward: -28.0\n",
      "Episode 3/10, Reward: -31.5\n",
      "Episode 4/10, Reward: -5.0\n",
      "Episode 5/10, Reward: -25.0\n",
      "Episode 6/10, Reward: -18.0\n",
      "Episode 7/10, Reward: -27.5\n",
      "Episode 8/10, Reward: -21.5\n",
      "Episode 9/10, Reward: -30.0\n",
      "Episode 10/10, Reward: -20.5\n",
      "Average Reward over 10 episodes: -24.9\n",
      "Episode 41/100, Average Reward: -24.9\n",
      "(1, 1)\n",
      "Episode 42/100, Reward: -28.0, Epsilon: 0.81\n",
      "(1, 1)\n",
      "Episode 43/100, Reward: -26, Epsilon: 0.81\n",
      "(1, 1)\n",
      "Episode 44/100, Reward: -3.0, Epsilon: 0.80\n",
      "(1, 1)\n",
      "Episode 45/100, Reward: -68, Epsilon: 0.80\n",
      "(1, 1)\n",
      "Episode 46/100, Reward: -114.0, Epsilon: 0.79\n",
      "(2, 1)\n",
      "Episode 47/100, Reward: -61.5, Epsilon: 0.79\n",
      "(1, 1)\n",
      "Episode 48/100, Reward: -2.5, Epsilon: 0.79\n",
      "(1, 1)\n",
      "Episode 49/100, Reward: -58.5, Epsilon: 0.78\n",
      "(1, 1)\n",
      "Episode 50/100, Reward: -52.5, Epsilon: 0.78\n",
      "(1, 1)\n",
      "Episode 51/100, Reward: -24, Epsilon: 0.77\n",
      "(2, 1)\n",
      "Episode 52/100, Reward: -3.0, Epsilon: 0.77\n",
      "(2, 1)\n",
      "Episode 53/100, Reward: -11.5, Epsilon: 0.77\n",
      "(2, 1)\n",
      "Episode 54/100, Reward: -14.0, Epsilon: 0.76\n",
      "(2, 1)\n",
      "Episode 55/100, Reward: -82.5, Epsilon: 0.76\n",
      "(2, 1)\n",
      "Episode 56/100, Reward: -35.0, Epsilon: 0.76\n",
      "(1, 1)\n",
      "Episode 57/100, Reward: -3.5, Epsilon: 0.75\n",
      "(1, 1)\n",
      "Episode 58/100, Reward: 1, Epsilon: 0.75\n",
      "(1, 1)\n",
      "Episode 59/100, Reward: -11.0, Epsilon: 0.74\n",
      "(1, 1)\n",
      "Episode 60/100, Reward: -20, Epsilon: 0.74\n",
      "(1, 1)\n",
      "Episode 61/100, Reward: 0.5, Epsilon: 0.74\n",
      "Episode 1/10, Reward: -27.5\n",
      "Episode 2/10, Reward: -17.5\n",
      "Episode 3/10, Reward: -28.0\n",
      "Episode 4/10, Reward: -19.5\n",
      "Episode 5/10, Reward: -15.5\n",
      "Episode 6/10, Reward: -19.0\n",
      "Episode 7/10, Reward: -28.0\n",
      "Episode 8/10, Reward: -16.5\n",
      "Episode 9/10, Reward: -30.5\n",
      "Episode 10/10, Reward: -5.0\n",
      "Average Reward over 10 episodes: -20.7\n",
      "Episode 61/100, Average Reward: -20.7\n",
      "(1, 1)\n",
      "Episode 62/100, Reward: -10.5, Epsilon: 0.73\n",
      "(1, 1)\n",
      "Episode 63/100, Reward: -10.5, Epsilon: 0.73\n",
      "(1, 1)\n",
      "Episode 64/100, Reward: -3, Epsilon: 0.73\n",
      "(2, 1)\n",
      "Episode 65/100, Reward: -106.0, Epsilon: 0.72\n",
      "(2, 1)\n",
      "Episode 66/100, Reward: -22.5, Epsilon: 0.72\n",
      "(2, 1)\n",
      "Episode 67/100, Reward: -94.5, Epsilon: 0.71\n",
      "(1, 1)\n",
      "Episode 68/100, Reward: -29.5, Epsilon: 0.71\n",
      "(1, 1)\n",
      "Episode 69/100, Reward: -21.5, Epsilon: 0.71\n",
      "(1, 1)\n",
      "Episode 70/100, Reward: -45, Epsilon: 0.70\n",
      "(2, 1)\n",
      "Episode 71/100, Reward: 1, Epsilon: 0.70\n",
      "(2, 1)\n",
      "Episode 72/100, Reward: -20.5, Epsilon: 0.70\n",
      "(1, 1)\n",
      "Episode 73/100, Reward: 1, Epsilon: 0.69\n",
      "(2, 1)\n",
      "Episode 74/100, Reward: -42.5, Epsilon: 0.69\n",
      "(2, 1)\n",
      "Episode 75/100, Reward: -19.5, Epsilon: 0.69\n",
      "(2, 1)\n",
      "Episode 76/100, Reward: -40.5, Epsilon: 0.68\n",
      "(1, 1)\n",
      "Episode 77/100, Reward: -47.0, Epsilon: 0.68\n",
      "(1, 1)\n",
      "Episode 78/100, Reward: -151.5, Epsilon: 0.68\n",
      "(2, 1)\n",
      "Episode 79/100, Reward: -59.0, Epsilon: 0.67\n",
      "(1, 1)\n",
      "Episode 80/100, Reward: 0, Epsilon: 0.67\n",
      "(2, 1)\n",
      "Episode 81/100, Reward: 1, Epsilon: 0.67\n",
      "Episode 1/10, Reward: -26.0\n",
      "Episode 2/10, Reward: -18.5\n",
      "Episode 3/10, Reward: -13.5\n",
      "Episode 4/10, Reward: -27.5\n",
      "Episode 5/10, Reward: -38.0\n",
      "Episode 6/10, Reward: -16.5\n",
      "Episode 7/10, Reward: -19.5\n",
      "Episode 8/10, Reward: -24.5\n",
      "Episode 9/10, Reward: -20.0\n",
      "Episode 10/10, Reward: -24.5\n",
      "Average Reward over 10 episodes: -22.85\n",
      "Episode 81/100, Average Reward: -22.85\n",
      "(2, 1)\n",
      "Episode 82/100, Reward: 0.0, Epsilon: 0.66\n",
      "(1, 1)\n",
      "Episode 83/100, Reward: -63.5, Epsilon: 0.66\n",
      "(1, 1)\n",
      "Episode 84/100, Reward: -29, Epsilon: 0.66\n",
      "(1, 1)\n",
      "Episode 85/100, Reward: -3.5, Epsilon: 0.65\n",
      "(2, 1)\n",
      "Episode 86/100, Reward: -2.0, Epsilon: 0.65\n",
      "(1, 1)\n",
      "Episode 87/100, Reward: -19, Epsilon: 0.65\n",
      "(1, 1)\n",
      "Episode 88/100, Reward: -23.0, Epsilon: 0.64\n",
      "(2, 1)\n",
      "Episode 89/100, Reward: -96.5, Epsilon: 0.64\n",
      "(1, 1)\n",
      "Episode 90/100, Reward: -27.0, Epsilon: 0.64\n",
      "(1, 1)\n",
      "Episode 91/100, Reward: -21.5, Epsilon: 0.63\n",
      "(2, 1)\n",
      "Episode 92/100, Reward: -24.0, Epsilon: 0.63\n",
      "(2, 1)\n",
      "Episode 93/100, Reward: -9.0, Epsilon: 0.63\n",
      "(2, 1)\n",
      "Episode 94/100, Reward: -104.0, Epsilon: 0.62\n",
      "(2, 1)\n",
      "Episode 95/100, Reward: -13.5, Epsilon: 0.62\n",
      "(2, 1)\n",
      "Episode 96/100, Reward: -1.5, Epsilon: 0.62\n",
      "(1, 1)\n",
      "Episode 97/100, Reward: -21.5, Epsilon: 0.61\n",
      "(1, 1)\n",
      "Episode 98/100, Reward: -12, Epsilon: 0.61\n",
      "(2, 1)\n",
      "Episode 99/100, Reward: -24.0, Epsilon: 0.61\n",
      "(1, 1)\n",
      "Episode 100/100, Reward: -48.5, Epsilon: 0.61\n",
      "Training complete.\n",
      "evalrewards:  [np.float64(-27.6), np.float64(-24.9), np.float64(-20.7), np.float64(-22.85)]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "\n",
    "\n",
    "rewards = []\n",
    "evalrewards = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    #\n",
    "    #state, _ = env_wrapper.reset()\n",
    "    \n",
    "    # when bypassing the wrapper, we need to convert the state to the actual state\n",
    "    s, _ = env.reset()\n",
    "    state = state_dict[s]\n",
    "    \n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action([state])\n",
    "        \n",
    "        # obs, reward, done, info = env_wrapper.step(state, action)\n",
    "        # next_state = info['actual_state']\n",
    "        # agent.store_transition([state], action, reward, [next_state], done)\n",
    "        \n",
    "        # bypassing the wrapper to get the actual state should be equilvalent to the above\n",
    "        # remember to reset the environment with the actual state and not the wrapper \n",
    "        s_ , reward, done , _, _ = env.step(action, states[state], execute=True)\n",
    "        next_state = state_dict[s_]\n",
    "        agent.store_transition([state], action, reward, [next_state], done)\n",
    "\n",
    "        agent.train()\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        steps += 1        \n",
    "        if done or steps > 100:\n",
    "            agent.update_epsilon()\n",
    "            rewards.append(episode_reward)\n",
    "            print(f\"Episode {episode + 1}/{num_episodes}, Reward: {episode_reward}, Epsilon: {agent.epsilon:.2f}\")\n",
    "            break\n",
    "    if episode != 0 and episode % 20 == 0:\n",
    "        avg_reward = evaluate_agent(env_wrapper, agent)\n",
    "        evalrewards.append(avg_reward)\n",
    "        print(f\"Episode {episode + 1}/{num_episodes}, Average Reward: {avg_reward}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(\"evalrewards: \", evalrewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rendered evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(1, 5, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Reward over \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_episodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m episodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_reward\n\u001b[0;32m---> 36\u001b[0m \u001b[43mevaluate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mevaluate_agent\u001b[0;34m(env, agent, num_episodes)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m c \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Render the environment\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# env.render()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Agent takes an action using a greedy policy (without exploration)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s)\n\u001b[0;32m---> 18\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchoose_action([\u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m])\n\u001b[1;32m     19\u001b[0m     s_, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(s, action, execute\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m state_dict[s_]\n",
      "\u001b[0;31mKeyError\u001b[0m: (1, 5, 0)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_agent(env : GridEnvDeform, agent : DoubleDQNAgent, num_episodes=10):\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        s, _ = env.reset()\n",
    "        env.render()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        c = 25\n",
    "        while c > 0:\n",
    "            # Render the environment\n",
    "            # env.render()\n",
    "\n",
    "            # Agent takes an action using a greedy policy (without exploration)\n",
    "            print(s)\n",
    "            action = agent.choose_action([state_dict[s]])\n",
    "            s_, reward, done, info = env.step(s, action, execute=True)\n",
    "\n",
    "            next_state = state_dict[s_]\n",
    "            state = next_state\n",
    "\n",
    "            episode_reward += reward\n",
    "            \n",
    "            if done or c == 1:\n",
    "                total_rewards.append(episode_reward)\n",
    "                print(f\"Episode {episode + 1}/{num_episodes}, Reward: {episode_reward}\")\n",
    "\n",
    "            c -= 1\n",
    "            time.sleep(0.1)\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {avg_reward}\")\n",
    "    return avg_reward\n",
    "\n",
    "evaluate_agent(env, agent, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transition check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 3, -2.0, 122, False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy what is done in training:\n",
    "# start from a random state chose an action and store the transition \n",
    "state, _ = env_wrapper.reset()\n",
    "action = agent.choose_action([state])\n",
    "\n",
    "obs, reward, done, info = env_wrapper.step(state, action)\n",
    "next_state = info['actual_state'] # next true state (not observation or belief)\n",
    "\n",
    "agent.store_transition([state], action, reward, [next_state], done)\n",
    "state, action, reward, next_state, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((3, 3, 2), (1, 1))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFhCAYAAAAsiOM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATu0lEQVR4nO3db2yVhd3/8W+h6wG1dKAD6SjgptMho1MQwtgfpkxDCNEnahaXdbgtcSkbjCwxfTK2B7M82aLbSP0zp0s2gsYE3EyAMUYhJhKhhARc4sZGtm4InclWoCbVtOd+8Iv93dzK3Knfcy5KX6/kSjyHc7w+J0j69pyrtK5cLpcDACDBhKIHAACXDmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAmvpan3B4eDhOnjwZjY2NUVdXV+vTAwCjUC6X4+zZs9Hc3BwTJlz4fYmah8XJkyejpaWl1qcFABL09vbGrFmzLvjrNQ+LxsbGiIh49tln47LLLqv16QGAUXjjjTfinnvuGfk6fiE1D4u3P/647LLL4vLLL6/16QGA9+G9LmNw8SYAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkGZUYbF58+aYO3duTJo0KZYsWRIvv/xy9i4AYAyqOCyeeeaZ2LBhQ2zcuDEOHz4cra2tcccdd0RfX1819gEAY0jFYfGjH/0ovv71r8eaNWti3rx58eijj8Zll10WP//5z9/18YODg3HmzJnzDgDg0lRRWLz55pvR09MTK1as+P//ggkTYsWKFfHSSy+963M6Ozujqalp5GhpaXl/iwGAi1ZFYfH666/H0NBQzJgx47z7Z8yYEadOnXrX53R0dER/f//I0dvbO/q1AMBFrb7aJyiVSlEqlap9GgDgIlDROxZXXXVVTJw4MU6fPn3e/adPn46rr746dRgAMPZUFBYNDQ2xcOHC2LNnz8h9w8PDsWfPnli6dGn6OABgbKn4o5ANGzZEW1tbLFq0KBYvXhwPP/xwDAwMxJo1a6qxDwAYQyoOi3vvvTf++c9/xne/+904depUfPKTn4ydO3e+44JOAGD8GdXFm2vXro21a9dmbwEAxjg/KwQASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASFNf9IDxZPny5UVPgKrr7u4uegJQIO9YAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABphAUAkEZYAABpKg6L/fv3x+rVq6O5uTnq6upi+/btVZgFAIxFFYfFwMBAtLa2xubNm6uxBwAYw+orfcLKlStj5cqV//XjBwcHY3BwcOT2mTNnKj0lADBGVP0ai87Ozmhqaho5Wlpaqn1KAKAgVQ+Ljo6O6O/vHzl6e3urfUoAoCAVfxRSqVKpFKVSqdqnAQAuAr7dFABIIywAgDQVfxRy7ty5OH78+MjtEydOxJEjR2LatGkxe/bs1HEAwNhScVgcOnQoPv/5z4/c3rBhQ0REtLW1xdNPP502DAAYeyoOi+XLl0e5XK7GFgBgjHONBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQpr7oAeNJd3d30ROooeXLlxc9AaDmvGMBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKSpKCw6OzvjlltuicbGxpg+fXrcdddd8eqrr1ZrGwAwxlQUFvv27Yv29vY4cOBA7N69O9566624/fbbY2BgoFr7AIAxpL6SB+/cufO8208//XRMnz49enp64rOf/ey7PmdwcDAGBwdHbp85c2YUMwGAseB9XWPR398fERHTpk274GM6Ozujqalp5GhpaXk/pwQALmKjDovh4eFYv359LFu2LObPn3/Bx3V0dER/f//I0dvbO9pTAgAXuYo+Cvnf2tvb49ixY/Hiiy/+x8eVSqUolUqjPQ0AMIaMKizWrl0bL7zwQuzfvz9mzZqVvQkAGKMqCotyuRzf/OY3Y9u2bdHd3R3XXHNNtXYBAGNQRWHR3t4eW7Zsieeffz4aGxvj1KlTERHR1NQUkydPrspAAGDsqOjiza6urujv74/ly5fHzJkzR45nnnmmWvsAgDGk4o9CAAAuxM8KAQDSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADS1Bc9YDxZvnx50ROoobq6uqInFGLjxo1FTyiEP9/w/3jHAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIU1FYdHV1xYIFC2LKlCkxZcqUWLp0aezYsaNa2wCAMaaisJg1a1Zs2rQpenp64tChQ3HrrbfGnXfeGa+88kq19gEAY0h9JQ9evXr1ebd/8IMfRFdXVxw4cCBuvPHGd33O4OBgDA4Ojtw+c+bMKGYCAGPBqK+xGBoaiq1bt8bAwEAsXbr0go/r7OyMpqamkaOlpWW0pwQALnIVh8XRo0fjiiuuiFKpFA888EBs27Yt5s2bd8HHd3R0RH9//8jR29v7vgYDABevij4KiYi4/vrr48iRI9Hf3x/PPfdctLW1xb59+y4YF6VSKUql0vseCgBc/CoOi4aGhrj22msjImLhwoVx8ODBeOSRR+Kxxx5LHwcAjC3v+++xGB4ePu/iTABg/KroHYuOjo5YuXJlzJ49O86ePRtbtmyJ7u7u2LVrV7X2AQBjSEVh0dfXF1/+8pfjtddei6ampliwYEHs2rUrvvCFL1RrHwAwhlQUFk8++WS1dgAAlwA/KwQASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASCMsAIA0wgIASFNf9IDxpLu7u+gJ1NDevXuLngBQc96xAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAIM37CotNmzZFXV1drF+/PmkOADCWjTosDh48GI899lgsWLAgcw8AMIaNKizOnTsX9913XzzxxBMxderU7E0AwBg1qrBob2+PVatWxYoVK97zsYODg3HmzJnzDgDg0lRf6RO2bt0ahw8fjoMHD/5Xj+/s7Izvf//7FQ8DAMaeit6x6O3tjXXr1sWvfvWrmDRp0n/1nI6Ojujv7x85ent7RzUUALj4VfSORU9PT/T19cXNN988ct/Q0FDs378/fvrTn8bg4GBMnDjxvOeUSqUolUo5awGAi1pFYXHbbbfF0aNHz7tvzZo1ccMNN8SDDz74jqgAAMaXisKisbEx5s+ff959l19+eVx55ZXvuB8AGH/8zZsAQJqKvyvk/+ru7k6YAQBcCrxjAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkqa/1CcvlckREvPHGG7U+NQAwSm9/3X776/iF1JXf6xHJ/v73v0dLS0stTwkAJOnt7Y1Zs2Zd8NdrHhbDw8Nx8uTJaGxsjLq6ulqeOs6cORMtLS3R29sbU6ZMqem5i+R1e93jgdftdY8HRb7ucrkcZ8+ejebm5pgw4cJXUtT8o5AJEyb8x9KphSlTpoyr/xDf5nWPL173+OJ1jy9Fve6mpqb3fIyLNwGANMICAEgzrsKiVCrFxo0bo1QqFT2lprxur3s88Lq97vFgLLzuml+8CQBcusbVOxYAQHUJCwAgjbAAANIICwAgjbAAANKMm7DYvHlzzJ07NyZNmhRLliyJl19+uehJVbd///5YvXp1NDc3R11dXWzfvr3oSVXX2dkZt9xySzQ2Nsb06dPjrrvuildffbXoWVXX1dUVCxYsGPnb+JYuXRo7duwoelbNbdq0Kerq6mL9+vVFT6mq733ve1FXV3feccMNNxQ9qyb+8Y9/xJe+9KW48sorY/LkyfGJT3wiDh06VPSsqpo7d+47fr/r6uqivb296GnvalyExTPPPBMbNmyIjRs3xuHDh6O1tTXuuOOO6OvrK3paVQ0MDERra2ts3ry56Ck1s2/fvmhvb48DBw7E7t2746233orbb789BgYGip5WVbNmzYpNmzZFT09PHDp0KG699da4884745VXXil6Ws0cPHgwHnvssViwYEHRU2rixhtvjNdee23kePHFF4ueVHX/+te/YtmyZfGBD3wgduzYEX/4wx/ihz/8YUydOrXoaVV18ODB836vd+/eHRERd999d8HLLqA8DixevLjc3t4+cntoaKjc3Nxc7uzsLHBVbUVEedu2bUXPqLm+vr5yRJT37dtX9JSamzp1avlnP/tZ0TNq4uzZs+XrrruuvHv37vLnPve58rp164qeVFUbN24st7a2Fj2j5h588MHypz/96aJnFG7dunXlj370o+Xh4eGip7yrS/4dizfffDN6enpixYoVI/dNmDAhVqxYES+99FKBy6iF/v7+iIiYNm1awUtqZ2hoKLZu3RoDAwOxdOnSoufURHt7e6xateq8P+eXuj/96U/R3NwcH/nIR+K+++6Lv/3tb0VPqrpf//rXsWjRorj77rtj+vTpcdNNN8UTTzxR9KyaevPNN+OXv/xl3H///TX/CeH/rUs+LF5//fUYGhqKGTNmnHf/jBkz4tSpUwWtohaGh4dj/fr1sWzZspg/f37Rc6ru6NGjccUVV0SpVIoHHnggtm3bFvPmzSt6VtVt3bo1Dh8+HJ2dnUVPqZklS5bE008/HTt37oyurq44ceJEfOYzn4mzZ88WPa2q/vKXv0RXV1dcd911sWvXrvjGN74R3/rWt+IXv/hF0dNqZvv27fHvf/87vvKVrxQ95YJq/mPToVba29vj2LFj4+Kz54iI66+/Po4cORL9/f3x3HPPRVtbW+zbt++Sjove3t5Yt25d7N69OyZNmlT0nJpZuXLlyD8vWLAglixZEnPmzIlnn302vvrVrxa4rLqGh4dj0aJF8dBDD0VExE033RTHjh2LRx99NNra2gpeVxtPPvlkrFy5Mpqbm4ueckGX/DsWV111VUycODFOnz593v2nT5+Oq6++uqBVVNvatWvjhRdeiL1798asWbOKnlMTDQ0Nce2118bChQujs7MzWltb45FHHil6VlX19PREX19f3HzzzVFfXx/19fWxb9+++PGPfxz19fUxNDRU9MSa+OAHPxgf+9jH4vjx40VPqaqZM2e+I5Q//vGPj4uPgSIi/vrXv8bvfve7+NrXvlb0lP/okg+LhoaGWLhwYezZs2fkvuHh4dizZ8+4+fx5PCmXy7F27drYtm1b/P73v49rrrmm6EmFGR4ejsHBwaJnVNVtt90WR48ejSNHjowcixYtivvuuy+OHDkSEydOLHpiTZw7dy7+/Oc/x8yZM4ueUlXLli17x7eP//GPf4w5c+YUtKi2nnrqqZg+fXqsWrWq6Cn/0bj4KGTDhg3R1tYWixYtisWLF8fDDz8cAwMDsWbNmqKnVdW5c+fO+z+YEydOxJEjR2LatGkxe/bsApdVT3t7e2zZsiWef/75aGxsHLmOpqmpKSZPnlzwuurp6OiIlStXxuzZs+Ps2bOxZcuW6O7ujl27dhU9raoaGxvfcf3M5ZdfHldeeeUlfV3Nd77znVi9enXMmTMnTp48GRs3boyJEyfGF7/4xaKnVdW3v/3t+NSnPhUPPfRQ3HPPPfHyyy/H448/Ho8//njR06pueHg4nnrqqWhra4v6+ov8S3fR35ZSKz/5yU/Ks2fPLjc0NJQXL15cPnDgQNGTqm7v3r3liHjH0dbWVvS0qnm31xsR5aeeeqroaVV1//33l+fMmVNuaGgof+hDHyrfdttt5d/+9rdFzyrEePh203vvvbc8c+bMckNDQ/nDH/5w+d577y0fP3686Fk18Zvf/KY8f/78cqlUKt9www3lxx9/vOhJNbFr165yRJRfffXVoqe8p7pyuVwuJmkAgEvNJX+NBQBQO8ICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANP8DRHEyvGKUhngAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transition is  correct\n"
     ]
    }
   ],
   "source": [
    "# set state and render\n",
    "env.set_state(states[state])\n",
    "print(states[state])\n",
    "env.render()\n",
    "\n",
    "# step and render\n",
    "_ , _, _ , _, _ = env.step(action, states[state], execute=True)\n",
    "env.render()\n",
    "\n",
    "# check if the transition is correct\n",
    "assert env.get_state() == states[next_state]\n",
    "print(\"Training transition is \", \"correct\" if env.get_state() == states[next_state] else \"incorrect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
