{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pygame\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import os \n",
    "# import sys\n",
    "# \n",
    "# sys.path.append(os.path.abspath('..'))\n",
    "# \n",
    "# from environment.env import ObservableDeformedGridworld\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_rectangle(vertices):\n",
    "    \"\"\"\n",
    "    Computes the bounding rectangle for a quadrilateral.\n",
    "    \n",
    "    Parameters:\n",
    "        vertices (list of tuples): Vertices of the quadrilateral.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Vertices of the bounding rectangle.\n",
    "    \"\"\"\n",
    "    x_coords = [v[0] for v in vertices]\n",
    "    y_coords = [v[1] for v in vertices]\n",
    "    xmin, xmax = min(x_coords), max(x_coords)\n",
    "    ymin, ymax = min(y_coords), max(y_coords)\n",
    "    \n",
    "    return [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "\n",
    "def is_point_in_triangle(point, triangle):\n",
    "    \"\"\"\n",
    "    Check if a point is inside a triangle using barycentric coordinates.\n",
    "    \n",
    "    Args:\n",
    "        point (tuple): (x, y) coordinates of the point to check\n",
    "        triangle (list): List of 3 tuples, each representing vertex coordinates [(x1,y1), (x2,y2), (x3,y3)]\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if point is inside the triangle, False otherwise\n",
    "    \"\"\"\n",
    "    def compute_barycentric_coordinates(pt, v1, v2, v3):\n",
    "        \"\"\"\n",
    "        Compute barycentric coordinates of a point with respect to a triangle.\n",
    "        \n",
    "        Args:\n",
    "            pt (tuple): Point coordinates\n",
    "            v1, v2, v3 (tuple): Vertex coordinates of the triangle\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Barycentric coordinates (u, v, w)\n",
    "        \"\"\"\n",
    "        pt = np.array(pt)\n",
    "        v1, v2, v3 = np.array(v1), np.array(v2), np.array(v3)\n",
    "        \n",
    "        # Vectorized area computation\n",
    "        triangle_area = np.abs(np.cross(v2 - v1, v3 - v1)) / 2\n",
    "        \n",
    "        # Areas of sub-triangles\n",
    "        area1 = np.abs(np.cross(pt - v2, v3 - v2)) / 2\n",
    "        area2 = np.abs(np.cross(v1 - pt, v3 - v1)) / 2\n",
    "        area3 = np.abs(np.cross(v1 - v2, pt - v2)) / 2\n",
    "        \n",
    "        # Compute barycentric coordinates\n",
    "        u = area1 / triangle_area\n",
    "        v = area2 / triangle_area\n",
    "        w = area3 / triangle_area\n",
    "        \n",
    "        return u, v, w\n",
    "    \n",
    "    # Compute barycentric coordinates\n",
    "    u, v, w = compute_barycentric_coordinates(point, triangle[0], triangle[1], triangle[2])\n",
    "    \n",
    "    # Point is inside if all barycentric coordinates are between 0 and 1 (inclusive)\n",
    "    return 0 <= u <= 1 and 0 <= v <= 1 and 0 <= w <= 1 and np.abs(u + v + w - 1) < 1e-10\n",
    "\n",
    "def is_point_in_parallelogram(point, box):\n",
    "    \"\"\"\n",
    "    Check if a point is inside a parallelogram.\n",
    "    \n",
    "    Args:\n",
    "        point (tuple): (x, y) coordinates of the point to check\n",
    "        box (list): List of 4 tuples, each representing vertex coordinates [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if point is inside the parallelogram, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if the point is in one of the two triangles of the parallelogram\n",
    "    return is_point_in_triangle(point, [box[0], box[1], box[2]]) or is_point_in_triangle(point, [box[0], box[2], box[3]])\n",
    "\n",
    "def sample_in_parallelogram(box):\n",
    "    \"\"\"\n",
    "    Sample a point uniformly inside a parallelogram.\n",
    "    \n",
    "    Args:\n",
    "        box (list): List of 4 tuples, each representing vertex coordinates [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x, y) coordinates of the sampled point\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute bounding box\n",
    "    rect = bounding_rectangle(box)\n",
    "    x_min, y_min = rect[0]\n",
    "    x_max, y_max = rect[2]    \n",
    "    # Keep sampling until a point inside the parallelogram is found\n",
    "\n",
    "    x = np.random.uniform(x_min, x_max)\n",
    "    y = np.random.uniform(y_min, y_max)\n",
    "    while not is_point_in_parallelogram((x, y), box):\n",
    "        x = np.random.uniform(x_min, x_max)\n",
    "        y = np.random.uniform(y_min, y_max)\n",
    "    \n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point: [0.45388612 0.95050459]\n",
      "Box: [array([0., 0.]), array([0.55654792, 0.14692519]), array([0.53335694, 1.08853905]), array([-0.02319099,  0.94161386])]\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "point = env.state\n",
    "box = env.transformed_corners\n",
    "\n",
    "print(\"Point:\", point)\n",
    "print(\"Box:\", box)\n",
    "\n",
    "print(is_point_in_parallelogram(point, box))\n",
    "\n",
    "# sample 100 points in the parallelogram and plot them along with the parallelogram\n",
    "points = [sample_in_parallelogram(box) for _ in range(100)]\n",
    "points = np.array(points)\n",
    "# box = [(0, 0), (2, 1), (3, 2), (1, 1)]\n",
    "rectangle = bounding_rectangle(box)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.gca().add_patch(patches.Polygon(box, fill=None, edgecolor='r'))\n",
    "plt.gca().add_patch(patches.Polygon(rectangle, fill=None, edgecolor='g'))\n",
    "plt.scatter(points[:, 0], points[:, 1], c='b', s=5)\n",
    "plt.scatter(point[0], point[1], c='r', s=10)\n",
    "plt.xlim(-.5, 2)\n",
    "plt.ylim(-.5, 2)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableDeformedGridworld(gym.Env):\n",
    "\n",
    "    def __init__(self, grid_size=(1.0, 1.0), step_size=0.02, goal=(0.9, 0.9), \n",
    "                 obstacles=None, stretch=(1.0, 1.0), shear=(0.0, 0.0), observation_radius=0.05, render_mode=None,shear_range=(-0.2,0.2),stretch_range=(0.4,1)):\n",
    "        \"\"\"\n",
    "        Initialize the observable deformed continuous gridworld.\n",
    "        :param grid_size: Size of the grid (width, height).\n",
    "        :param step_size: Step size for the agent's movement.\n",
    "        :param goal: Coordinates of the goal position.\n",
    "        :param obstacles: List of obstacles as rectangles [(x_min, y_min), (x_max, y_max)].\n",
    "        :param stretch: Tuple (s_x, s_y) for stretching the grid in x and y directions.\n",
    "        :param shear: Tuple (sh_x, sh_y) for shearing the grid.\n",
    "        :param observation_radius: Radius within which the agent can observe its surroundings.\n",
    "        \"\"\"\n",
    "        self.grid_size = np.array(grid_size)\n",
    "        self.step_size = step_size\n",
    "        self.goal = np.array(goal)\n",
    "        self.state = np.array([0.1, 0.1])  # Start at the origin\n",
    "        self.obstacles = obstacles if obstacles else []\n",
    "        self.observation_radius = observation_radius\n",
    "\n",
    "        # Transformation matrix\n",
    "        self.transformation_matrix = np.array([\n",
    "            [stretch[0], shear[0]],\n",
    "            [shear[1], stretch[1]]\n",
    "        ])\n",
    "        self.inverse_transformation_matrix = np.linalg.inv(self.transformation_matrix)\n",
    "\n",
    "        # Rendering mode\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # gymnasium compatibility\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space =  Dict({\n",
    "            \"pos\": gym.spaces.Box(low=.0, high=1.0, shape=(2,),dtype=float),\n",
    "            \"theta\": gym.spaces.Box(low=.0, high=1.0, shape=(4,),dtype=float), # deformation is a 2x2 tensor\n",
    "        })\n",
    "\n",
    "        self.stretch_range = stretch_range\n",
    "        self.shear_range = shear_range\n",
    "\n",
    "        self.timestep = 0\n",
    "\n",
    "        self.corners = [\n",
    "            np.array([0, 0]),\n",
    "            np.array([self.grid_size[0], 0]),\n",
    "            self.grid_size,\n",
    "            np.array([0, self.grid_size[1]]),\n",
    "        ]\n",
    "        self.transformed_corners = [self.transform(corner) for corner in self.corners]\n",
    "        \n",
    "    def reset(self,seed=None):\n",
    "        \"\"\"\n",
    "        Reset the environment to the initial state.\n",
    "        :return: Initial state and observation.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.set_deformation(self.sample(2,self.stretch_range), self.sample(2,self.shear_range))  # Reset deformation to random\n",
    "        self.transformed_corners = [self.transform(corner) for corner in self.corners]\n",
    "        # self.state = np.array([0.1, 0.1])  # Start at the origin\n",
    "        #self.state = np.random.rand(2) * self.transform(self.grid_size) # Random start position in the deformable grid\n",
    "        self.state = sample_in_parallelogram(self.transformed_corners)\n",
    "\n",
    "\n",
    "        state = OrderedDict({\n",
    "            \"pos\": self.state,\n",
    "            \"theta\": self.transformation_matrix.flatten(),\n",
    "        }) \n",
    "        \n",
    "        self.timestep = 0\n",
    "\n",
    "        # print(f\"Initial agent position: {self.state}\",\n",
    "        #       f\"Initial goal position: {self.goal}\",\n",
    "        #       f\"Initial deformation: {self.transformation_matrix}\",\n",
    "        #       f\"Initial observation: {self.observe_obstacle()}\",\n",
    "        #       sep=\"\\n\")\n",
    "        \n",
    "        return state, {}\n",
    "    \n",
    "    def set_deformation(self, stretch, shear):\n",
    "        \"\"\"\n",
    "        Set the deformation transformation matrix based on stretch and shear parameters.\n",
    "        \n",
    "        This function creates a transformation matrix to apply grid deformations, including \n",
    "        stretching and shearing, to the grid coordinates. It also computes the inverse of \n",
    "        this transformation for reversing the deformation.\n",
    "\n",
    "        :param stretch: A tuple (s_x, s_y) for stretching the grid in the x and y directions.\n",
    "        :param shear: A tuple (sh_x, sh_y) for shearing the grid in the x and y directions.\n",
    "        \"\"\"\n",
    "        # Create the transformation matrix based on stretch and shear\n",
    "        self.transformation_matrix = np.array([\n",
    "            [stretch[0], shear[0]],  # First row: stretch in x and shear in x direction\n",
    "            [shear[1], stretch[1]]   # Second row: shear in y and stretch in y direction\n",
    "        ])\n",
    "\n",
    "        # Calculate the inverse transformation matrix for reversing the deformation\n",
    "        self.inverse_transformation_matrix = np.linalg.inv(self.transformation_matrix)\n",
    "\n",
    "        # Optionally, print the transformation matrices for debugging\n",
    "        # print(f\"Transformation Matrix:\\n{self.transformation_matrix}\")\n",
    "        # print(f\"Inverse Transformation Matrix:\\n{self.inverse_transformation_matrix}\")\n",
    "\n",
    "    def set_pos(self, pos):\n",
    "        \"\"\"\n",
    "        Set the agent's state to a new position.\n",
    "        \n",
    "        This function directly updates the agent's position (state) to the provided coordinates.\n",
    "\n",
    "        :param pos: A tuple or array representing the new position of the agent in the grid.\n",
    "        \"\"\"\n",
    "        # Update the state (agent's position)\n",
    "        self.state = np.array(pos)\n",
    "\n",
    "        # Optionally, print the new state for debugging\n",
    "        # print(f\"New agent position: {self.state}\")\n",
    "\n",
    "    def transform(self, position):\n",
    "        \"\"\"\n",
    "        Apply the grid deformation to a given position.\n",
    "        :param position: (x, y) in original space.\n",
    "        :return: Transformed position in the deformed grid.\n",
    "        \"\"\"\n",
    "        return np.dot(self.transformation_matrix, position)\n",
    "\n",
    "    def inverse_transform(self, position):\n",
    "        \"\"\"\n",
    "        Map a position from the deformed grid back to the original space.\n",
    "        :param position: (x, y) in the deformed grid.\n",
    "        :return: Original position.\n",
    "        \"\"\"\n",
    "        return np.dot(self.inverse_transformation_matrix, position)\n",
    "    \n",
    "    def is_in_obstacle(self, position):\n",
    "        \"\"\"\n",
    "        Check if a given position is inside any obstacle.\n",
    "        :param position: The (x, y) coordinates to check in the original space.\n",
    "        :return: True if the position is inside an obstacle, False otherwise.\n",
    "        \"\"\"\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            bottom_left = self.transform(np.array([x_min, y_min]))\n",
    "            bottom_right = self.transform(np.array([x_max, y_min]))\n",
    "            top_left = self.transform(np.array([x_min, y_max]))\n",
    "            top_right = self.transform(np.array([x_max, y_max]))\n",
    "            obstacle = [bottom_left, bottom_right, top_right, top_left]\n",
    "            if is_point_in_parallelogram(position, obstacle):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def observe_obstacle_rectangle(self):\n",
    "        \"\"\"\n",
    "        Efficiently and precisely check for obstacles in the four cardinal directions (N, E, S, W).\n",
    "        Each direction checks for obstacles in a quarter-circle arc within the observation radius.\n",
    "        :return: A numpy array of shape (4,), where each entry indicates the presence of obstacles \n",
    "                in the respective direction (North, East, South, West).\n",
    "        \"\"\"\n",
    "        directions = [\"N\", \"E\", \"S\", \"W\"]\n",
    "        obstacle_presence = np.zeros(4)  # Default: no obstacles in any direction\n",
    "\n",
    "        # Precompute direction boundaries in radians\n",
    "        direction_ranges = [\n",
    "            (315, 45),   # North: [-45°, +45°]\n",
    "            (45, 135),   # East: [+45°, +135°]\n",
    "            (135, 225),  # South: [+135°, +225°]\n",
    "            (225, 315)   # West: [+225°, +315°]\n",
    "        ]\n",
    "        direction_ranges_rad = [(np.deg2rad(a1), np.deg2rad(a2)) for a1, a2 in direction_ranges]\n",
    "\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            x_min, y_min = self.transform([x_min, y_min])\n",
    "            x_max, y_max = self.transform([x_max, y_max])\n",
    "\n",
    "            # Generate sampled points along the edges of the obstacle\n",
    "            num_samples = 5  # Increase for more precision\n",
    "            edge_points = np.concatenate([\n",
    "                np.linspace([x_min, y_min], [x_max, y_min], num_samples),  # Bottom edge\n",
    "                np.linspace([x_max, y_min], [x_max, y_max], num_samples),  # Right edge\n",
    "                np.linspace([x_max, y_max], [x_min, y_max], num_samples),  # Top edge\n",
    "                np.linspace([x_min, y_max], [x_min, y_min], num_samples)   # Left edge\n",
    "            ])\n",
    "\n",
    "            # Compute vectors from agent to sampled points\n",
    "            vectors = edge_points - self.state\n",
    "            distances = np.linalg.norm(vectors, axis=1)\n",
    "\n",
    "            # Filter points that are outside the observation radius\n",
    "            within_radius = distances <= self.observation_radius\n",
    "            if not np.any(within_radius):\n",
    "                continue  # Skip obstacles entirely outside the radius\n",
    "\n",
    "            # Compute angles relative to positive Y-axis\n",
    "            angles = np.arctan2(vectors[:, 1], vectors[:, 0])  # Radians\n",
    "            angles = (angles + 2 * np.pi) % (2 * np.pi)  # Normalize to [0, 2π)\n",
    "\n",
    "            # Check which direction each point falls into\n",
    "            for i, (angle_min, angle_max) in enumerate(direction_ranges_rad):\n",
    "                if obstacle_presence[i] == 1:\n",
    "                    continue  # Early exit if the direction is already flagged\n",
    "                for angle in angles[within_radius]:\n",
    "                    if (angle_min <= angle < angle_max) or (\n",
    "                        angle_max < angle_min and (angle >= angle_min or angle < angle_max)\n",
    "                    ):\n",
    "                        obstacle_presence[i] = 1\n",
    "                        break  # No need to check further points for this direction\n",
    "\n",
    "        return obstacle_presence\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take a step in the environment, interpreting the action in the deformed space.\n",
    "        :param action: One of ['N', 'S', 'E', 'W'].\n",
    "        :return: Tuple (next_state, observation, reward, done, info).\n",
    "        \"\"\"\n",
    "        # Map actions to movements in the deformed space\n",
    "        moves = [np.array([0, self.step_size]),   # Move up in deformed space\n",
    "            np.array([0, -self.step_size]),  # Move down in deformed space\n",
    "            np.array([self.step_size, 0]),   # Move right in deformed space\n",
    "            np.array([-self.step_size, 0])   # Move left in deformed space\n",
    "        ]\n",
    "\n",
    "        # Get the movement vector in the deformed space\n",
    "        move = moves[action]\n",
    "\n",
    "        # Map the movement to the original space using the inverse transformation\n",
    "        # move_original = np.dot(self.inverse_transformation_matrix, move)\n",
    "\n",
    "        # Update state in the original grid space\n",
    "        next_state = self.state + move\n",
    "\n",
    "        num_samples = 10  # Number of points to sample along the path\n",
    "        path = np.linspace(self.state, next_state, num_samples)\n",
    "\n",
    "        # Check for collisions along the path\n",
    "        collision = any(self.is_in_obstacle(point) for point in path)\n",
    "\n",
    "        # Check if the new state is in an obstacle\n",
    "        if np.linalg.norm(next_state - self.transform(self.goal)) < self.observation_radius:\n",
    "            terminated = True\n",
    "            reward = 1.0 \n",
    "            info = {\"collision\": False, \"out\": False, 'goal': True}\n",
    "        # Check if the is inside the deformed grid boundaries\n",
    "        elif not is_point_in_parallelogram(next_state, self.transformed_corners):\n",
    "            reward = -2.0\n",
    "            info = {\"out\": True}\n",
    "            next_state = self.state\n",
    "            terminated = False\n",
    "        elif collision:   \n",
    "            reward = -2.0  # Penalty for hitting an obstacle\n",
    "            info = {\"collision\": True}\n",
    "            terminated = False\n",
    "        else:\n",
    "            terminated = False\n",
    "            reward = -0.5\n",
    "            info = {\"collision\": False, \"out\": False, \"goal\": False}\n",
    "    \n",
    "        self.state = next_state\n",
    "        self.timestep += 1\n",
    "        truncated = self.timestep > 500 \n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        state = OrderedDict({\n",
    "                    \"pos\": self.state,\n",
    "                    \"theta\": self.transformation_matrix.flatten(),\n",
    "                })\n",
    "\n",
    "        # Return the transformed state, reward, and terminated truncated flag\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    def render_old(self):\n",
    "        \"\"\"\n",
    "        Render the deformed gridworld environment using Pygame, ensuring the entire deformed grid fits within the screen.\n",
    "        \"\"\"\n",
    "        import pygame  # Ensure Pygame is imported\n",
    "\n",
    "        # Define colors\n",
    "        WHITE = (255, 255, 255)\n",
    "        BLUE = (0, 0, 255)\n",
    "        GREEN = (0, 255, 0)\n",
    "        RED = (255, 0, 0)\n",
    "        YELLOW = (255, 255, 0)\n",
    "        BLACK = (0, 0, 0)\n",
    "\n",
    "        # Initialize the screen\n",
    "        if not hasattr(self, \"screen\"):\n",
    "            self.screen_width = 800\n",
    "            self.screen_height = 600\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            pygame.display.set_caption(\"Deformed Gridworld Environment\")\n",
    "\n",
    "        # Fill background with white\n",
    "        self.screen.fill(WHITE)\n",
    "\n",
    "        # Compute the bounding box of the deformed grid\n",
    "        corners = [\n",
    "            self.transform(np.array([0, 0])),\n",
    "            self.transform(np.array([self.grid_size[0], 0])),\n",
    "            self.transform(self.grid_size),\n",
    "            self.transform(np.array([0, self.grid_size[1]])),\n",
    "        ]\n",
    "        x_coords, y_coords = zip(*corners)\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "\n",
    "        # Define scaling factors to fit the deformed grid within the screen\n",
    "        scale_x = self.screen_width / (max_x - min_x)\n",
    "        scale_y = self.screen_height / (max_y - min_y)\n",
    "        scale = min(scale_x, scale_y)  # Uniform scaling to maintain aspect ratio\n",
    "\n",
    "        # Transform helper for rendering\n",
    "        def to_screen_coords(pos):\n",
    "            \"\"\"\n",
    "            Map transformed coordinates to screen coordinates, scaled and shifted to fit the screen.\n",
    "            \"\"\"\n",
    "            x, y = pos\n",
    "            x_screen = int((x - min_x) * scale)\n",
    "            y_screen = int((max_y - y) * scale)  # Flip y-axis for screen rendering\n",
    "            return x_screen, y_screen\n",
    "\n",
    "        # Draw the deformed grid boundaries\n",
    "        pygame.draw.polygon(self.screen, BLACK, [to_screen_coords(corner) for corner in corners], width=3)\n",
    "\n",
    "        # Draw the obstacles\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            bottom_left = self.transform(np.array([x_min, y_min]))\n",
    "            bottom_right = self.transform(np.array([x_max, y_min]))\n",
    "            top_left = self.transform(np.array([x_min, y_max]))\n",
    "            top_right = self.transform(np.array([x_max, y_max]))\n",
    "            \n",
    "            # Draw each obstacle as a polygon in the deformed space\n",
    "            pygame.draw.polygon(self.screen, RED, [\n",
    "                to_screen_coords(bottom_left),\n",
    "                to_screen_coords(bottom_right),\n",
    "                to_screen_coords(top_right),\n",
    "                to_screen_coords(top_left)\n",
    "            ])\n",
    "\n",
    "        # Draw the agent\n",
    "        agent_position = self.transform(self.state)\n",
    "        pygame.draw.circle(self\n",
    "        .screen, BLUE, to_screen_coords(agent_position), 10)\n",
    "\n",
    "        # Draw the goal\n",
    "        goal_position = self.transform(self.goal)\n",
    "        pygame.draw.circle(self.screen, GREEN, to_screen_coords(goal_position), 12)\n",
    "\n",
    "        # Draw observation radius as a dashed circle around the agent\n",
    "        observation_radius = self.observation_radius * max(self.transformation_matrix.diagonal())\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(agent_position), \n",
    "                        int(observation_radius * scale), 1)\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Handle key events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                # Press 'r' to reset environment\n",
    "                if event.key == pygame.K_r:\n",
    "                    self.reset()\n",
    "                # Press 'w' to quit\n",
    "                elif event.key == pygame.K_w:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                # Press 's' to save current state\n",
    "                elif event.key == pygame.K_s:\n",
    "                    self.save_state()\n",
    "                # Press space to pause/resume\n",
    "                elif event.key == pygame.K_SPACE:\n",
    "                    self.pause()\n",
    "                # Press arrow keys for manual control\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    return self.step(3)  # Left action\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    return self.step(2)  # Right action\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    return self.step(0)  # Up action\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    return self.step(1)  # Down action\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    def close(self):\n",
    "        self.render_mode = None\n",
    "        pygame.quit()\n",
    "    \n",
    "    def sample(self,num,limit):\n",
    "        low,high = limit\n",
    "        return low + np.random.rand(num)*(high-low)\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Render the deformed gridworld environment along with the original gridworld.\n",
    "        The original gridworld serves as a reference background.\n",
    "        \"\"\"\n",
    "        import pygame  # Ensure Pygame is imported\n",
    "\n",
    "        # Define colors\n",
    "        WHITE = (255, 255, 255)\n",
    "        LIGHT_GRAY = (200, 200, 200)\n",
    "        BLUE = (0, 0, 255)\n",
    "        GREEN = (0, 255, 0)\n",
    "        RED = (255, 0, 0)\n",
    "        PINK = (255, 105, 180)  \n",
    "        YELLOW = (255, 255, 0)\n",
    "        BLACK = (0, 0, 0)\n",
    "\n",
    "        # Initialize the screen\n",
    "        if not hasattr(self, \"screen\"):\n",
    "            self.screen_width = 1000\n",
    "            self.screen_height = 1000\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            pygame.display.set_caption(\"Deformed and Original Gridworld\")\n",
    "\n",
    "        # Fill background with white\n",
    "        self.screen.fill(WHITE)\n",
    "\n",
    "    # Compute the bounding box of the deformed grid\n",
    "        corners = [\n",
    "            np.array([0, 0]),\n",
    "            np.array([self.grid_size[0], 0]),\n",
    "            self.grid_size,\n",
    "            np.array([0, self.grid_size[1]]),\n",
    "        ]\n",
    "        transformed_corners = [self.transform(corner) for corner in corners]\n",
    "        x_coords, y_coords = zip(*transformed_corners)\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "\n",
    "        # Define scaling factors to fit the deformed grid within the screen\n",
    "        scale_x = self.screen_width / (max_x - min_x)\n",
    "        scale_y = self.screen_height / (max_y - min_y)\n",
    "        scale = min(scale_x, scale_y)  # Uniform scaling to maintain aspect ratio\n",
    "\n",
    "        # Add upward translation offset\n",
    "        y_translation = max(0, -min_y * scale)\n",
    "\n",
    "        # Transform helper for rendering\n",
    "        def to_screen_coords(pos):\n",
    "            \"\"\"\n",
    "            Map transformed coordinates to screen coordinates, scaled and shifted to fit the screen.\n",
    "            \"\"\"\n",
    "            x, y = pos\n",
    "            x_screen = int((x - min_x) * scale)\n",
    "            y_screen = int((max_y - y) * scale + y_translation)  # Flip y-axis and add upward translation\n",
    "            return x_screen, y_screen\n",
    "        \n",
    "        # Draw the un-deformed grid (background)\n",
    "        for i in range(int(self.grid_size[0]) + 1):\n",
    "            pygame.draw.line(self.screen, LIGHT_GRAY,\n",
    "                            to_screen_coords((i, 0)),\n",
    "                            to_screen_coords((i, self.grid_size[1])), width=1)\n",
    "        for j in range(int(self.grid_size[1]) + 1):\n",
    "            pygame.draw.line(self.screen, LIGHT_GRAY,\n",
    "                            to_screen_coords((0, j)),\n",
    "                            to_screen_coords((self.grid_size[0], j)), width=1)\n",
    "\n",
    "        # Draw the deformed grid boundaries\n",
    "        corners = [\n",
    "            np.array([0, 0]),\n",
    "            np.array([self.grid_size[0], 0]),\n",
    "            self.grid_size,\n",
    "            np.array([0, self.grid_size[1]]),\n",
    "        ]\n",
    "        transformed_corners = [self.transform(corner) for corner in corners]\n",
    "        pygame.draw.polygon(self.screen, BLACK, [to_screen_coords(corner) for corner in transformed_corners], width=3)\n",
    "\n",
    "        # Draw the obstacles in both grids\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            # Original obstacle\n",
    "            pygame.draw.rect(self.screen, PINK,\n",
    "                            (*to_screen_coords((x_min, y_max)),  # Top-left corner\n",
    "                            int((x_max - x_min) * scale),      # Width\n",
    "                            int((y_max - y_min) * scale)),    # Height\n",
    "                            width=0)\n",
    "\n",
    "            # Transformed obstacle\n",
    "            bottom_left = self.transform(np.array([x_min, y_min]))\n",
    "            bottom_right = self.transform(np.array([x_max, y_min]))\n",
    "            top_left = self.transform(np.array([x_min, y_max]))\n",
    "            top_right = self.transform(np.array([x_max, y_max]))\n",
    "            pygame.draw.polygon(self.screen, RED, [\n",
    "                to_screen_coords(bottom_left),\n",
    "                to_screen_coords(bottom_right),\n",
    "                to_screen_coords(top_right),\n",
    "                to_screen_coords(top_left)\n",
    "            ])\n",
    "\n",
    "        # Draw the agent in both grids\n",
    "        agent_position = self.state\n",
    "        transformed_agent_position = agent_position\n",
    "        pygame.draw.circle(self.screen, BLUE, to_screen_coords(agent_position), 10)  # Original\n",
    "        pygame.draw.circle(self.screen, GREEN, to_screen_coords(transformed_agent_position), 10)  # Transformed\n",
    "\n",
    "        # Draw the goal in both grids\n",
    "        goal_position = self.goal\n",
    "        transformed_goal_position = self.transform(goal_position)\n",
    "        pygame.draw.circle(self.screen, GREEN, to_screen_coords(goal_position), 12)  # Original\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(transformed_goal_position), 12)  # Transformed\n",
    "\n",
    "        # Draw observation radius as a dashed circle around the agent\n",
    "        observation_radius = self.observation_radius # stays the same in both grids\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(agent_position), \n",
    "                        int(self.observation_radius * scale), 1)  # Original\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(transformed_agent_position), \n",
    "                        int(observation_radius * scale), 1)  # Transformed\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Handle key events\n",
    "        # Handle key events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                # Press 'r' to reset environment\n",
    "                if event.key == pygame.K_r:\n",
    "                    self.reset()\n",
    "                # Press 'w' to quit\n",
    "                elif event.key == pygame.K_w:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                # Press 's' to save current state\n",
    "                elif event.key == pygame.K_s:\n",
    "                    self.save_state()\n",
    "                # Press space to pause/resume\n",
    "                elif event.key == pygame.K_SPACE:\n",
    "                    self.pause()\n",
    "                # Press arrow keys for manual control\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    return self.step(3)  # Left action\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    return self.step(2)  # Right action\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    return self.step(0)  # Up action\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    return self.step(1)  # Down action\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    def set_pos_nodeform(self):\n",
    "        \"\"\"\n",
    "        Set the agent's state to a new position.\n",
    "        \n",
    "        This function directly updates the agent's position (state) to the provided coordinates.\n",
    "\n",
    "        :param pos: A tuple or array representing the new position of the agent in the grid.\n",
    "        \"\"\"\n",
    "        low, high = -.2, 1.2 # depends on the shear (nto stretch since compression)\n",
    "        pos = self.sample(2,limit=(low,high))\n",
    "        \n",
    "        # Update the state (agent's position)\n",
    "        self.state = np.array(pos)\n",
    "\n",
    "        # Optionally, print the new state for debugging\n",
    "        # print(f\"New agent position: {self.state}\")\n",
    "\n",
    "        return pos\n",
    "    def is_in_obstacle_nodeform(self, position):\n",
    "        \"\"\"\n",
    "        Check if a given position is inside any obstacle.\n",
    "        :param position: The (x, y) coordinates to check in the original space.\n",
    "        :return: True if the position is inside an obstacle, False otherwise.\n",
    "        \"\"\"\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            if x_min <= position[0] <= x_max and y_min <= position[1] <= y_max:            \n",
    "                return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "# Example Usage\n",
    "# obstacles = [\n",
    "#     [(0.2, 0.2), (0.6, 0.6)],  # Obstacle 1\n",
    "#     [(0.6, 0.6), (0.8, 0.8)]   # Obstacle 2\n",
    "# ]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, 1),\n",
    "    shear=(.2, .2),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "# state, observation = env.reset(np.random.randint(100))\n",
    "#   \n",
    "# env.reset(seed=np.random.randint(1078890))\n",
    "done = False\n",
    "while not done:\n",
    "    try:\n",
    "        _, reward, terminated, truncated, _ = env.render()\n",
    "        if terminated or truncated:\n",
    "            print(reward)\n",
    "            env.close()\n",
    "            break\n",
    "    except:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((0.14625, 0.3325), (0.565, 0.55625)),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((0.14625, 0.3325), (0.565, 0.55625)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    state, observation = env.reset(np.random.randint(100))\n",
    "    env.set_pos(env.transform([0.9,0.9]))\n",
    "    assert np.linalg.norm(env.state - env.transform(env.goal)) < env.observation_radius\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "\n",
    "def train_dqn(args):\n",
    "    from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "    from wandb.integration.sb3 import WandbCallback\n",
    "    import wandb\n",
    "\n",
    "    total_timesteps = args.total_timesteps\n",
    "    batch_size = args.batch_size\n",
    "    lr = args.learning_rate\n",
    "    target_update = args.target_update\n",
    "    gamma = args.gamma\n",
    "\n",
    "    config = {\n",
    "        \"policy_type\": \"MultiInputPolicy\",\n",
    "        \"env_name\": \"ObservableDeformedGridworld\",\n",
    "        \"total_timesteps\": total_timesteps,\n",
    "        \"Batch_Size\": batch_size,\n",
    "        'grid_size': (1.0,1.0),\n",
    "        'step_size': 0.1,\n",
    "        'obstacles':obstacles,\n",
    "        'observation_radius':0.2,\n",
    "    }\n",
    "    run = wandb.init(\n",
    "        project=\"DQNsb3 - MDP - ObservableDeformedGridworld\",\n",
    "        config=config,\n",
    "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "        monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "        save_code=True,  # optional\n",
    "    )\n",
    "\n",
    "\n",
    "    # Save a checkpoint every 10000 steps\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "                            save_freq=10000,\n",
    "                            save_path=f\"DQNsb3_{run.id}\",\n",
    "                            name_prefix=\"rl_model\",\n",
    "                            save_replay_buffer=False,\n",
    "                            save_vecnormalize=True,\n",
    "                        )\n",
    "\n",
    "    callbacks = [ WandbCallback(\n",
    "                                verbose=2,\n",
    "                                log=\"parameters\",\n",
    "                                ),\n",
    "                checkpoint_callback,\n",
    "                ]\n",
    "\n",
    "\n",
    "    from stable_baselines3.common.monitor import Monitor\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "\n",
    "    def make_env():\n",
    "        env = ObservableDeformedGridworld(\n",
    "            grid_size=(1.0, 1.0),\n",
    "            obstacles=obstacles,\n",
    "            render_mode='human'\n",
    "        )\n",
    "\n",
    "        env = Monitor(env)  # record stats such as returns\n",
    "        return env\n",
    "\n",
    "    env = DummyVecEnv([make_env])\n",
    "\n",
    "\n",
    "    net_arch=[128, 128, 128]\n",
    "    model = DQN(\"MultiInputPolicy\",env,batch_size=batch_size,gamma=gamma, \n",
    "                target_update_interval=target_update, policy_kwargs=dict(net_arch=net_arch), verbose=1,\n",
    "                tensorboard_log=f\"runs/{run.id}\", device=\"cpu\", learning_rate=lr,\n",
    "                train_freq=(1,\"episode\"), gradient_steps=1)\n",
    "    model.learn(total_timesteps,progress_bar=True, callback=callbacks, log_interval=1)\n",
    "    model.save(f\"agents/pretrained/MDP/DQNsb3_{run.id}\")\n",
    "    env.close()\n",
    "    run.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.001)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--total_timesteps\", type=int, default=1000000) # env steps\n",
    "    parser.add_argument(\"--target_update\", type=int, default=555) # in env steps\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99)\n",
    "    parser.add_argument(\"--f\", type=str, default=None)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_dqn(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Linux-6.11.2-amd64-x86_64-with-glibc2.40 # 1 SMP PREEMPT_DYNAMIC Kali 6.11.2-1kali1 (2024-10-15)\n",
      "- Python: 3.11.10\n",
      "- Stable-Baselines3: 2.4.0\n",
      "- PyTorch: 2.5.1+cu124\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.26.4\n",
      "- Cloudpickle: 3.1.0\n",
      "- Gymnasium: 1.0.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Linux-6.10.3-200.fc40.x86_64-x86_64-with-glibc2.39 # 1 SMP PREEMPT_DYNAMIC Mon Aug  5 14:30:00 UTC 2024\n",
      "- Python: 3.11.10\n",
      "- Stable-Baselines3: 2.4.0\n",
      "- PyTorch: 2.5.1+cu121\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.26.3\n",
      "- Cloudpickle: 3.1.0\n",
      "- Gymnasium: 1.0.0\n",
      "\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Observation spaces do not match: Dict('obs': Box(0, 1, (4,), int64), 'pos': Box(0.0, 1.0, (2,), float64), 'theta': Box(0.0, 1.0, (4,), float64)) != Dict('pos': Box(0.0, 1.0, (2,), float64), 'theta': Box(0.0, 1.0, (4,), float64))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m env \u001b[38;5;241m=\u001b[39m ObservableDeformedGridworld(\n\u001b[1;32m     11\u001b[0m     obstacles\u001b[38;5;241m=\u001b[39mobstacles, \n\u001b[1;32m     12\u001b[0m     stretch\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m.5\u001b[39m),\n\u001b[1;32m     13\u001b[0m     shear\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m.0\u001b[39m, \u001b[38;5;241m.0\u001b[39m),\n\u001b[1;32m     14\u001b[0m     render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m net_arch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDQN_continous_t7bhel8y/rl_model_500000_steps.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet_arch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m env \u001b[38;5;241m=\u001b[39m ObservableDeformedGridworld(\n\u001b[1;32m     21\u001b[0m     obstacles\u001b[38;5;241m=\u001b[39mobstacles, \n\u001b[1;32m     22\u001b[0m     stretch\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m.5\u001b[39m),\n\u001b[1;32m     23\u001b[0m     shear\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m.0\u001b[39m, \u001b[38;5;241m.0\u001b[39m),\n\u001b[1;32m     24\u001b[0m     render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m state, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:716\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_env(env, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Check if given env is valid\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m \u001b[43mcheck_for_correct_spaces\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Discard `_last_obs`, this will force the env to reset before training\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;66;03m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_reset \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/utils.py:231\u001b[0m, in \u001b[0;36mcheck_for_correct_spaces\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mChecks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03mspaces match after loading the model with given env.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m:param action_space: Action space to check against\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space:\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Observation spaces do not match: Dict('obs': Box(0, 1, (4,), int64), 'pos': Box(0.0, 1.0, (2,), float64), 'theta': Box(0.0, 1.0, (4,), float64)) != Dict('pos': Box(0.0, 1.0, (2,), float64), 'theta': Box(0.0, 1.0, (4,), float64))"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, .5),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "net_arch=[128, 128, 128]\n",
    "model = DQN.load(\"DQN_continous_t7bhel8y/rl_model_500000_steps.zip\", env=env, policy_kwargs=dict(net_arch=net_arch), print_system_info=True)\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, .5),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "state, _ = env.reset(seed=np.random.randint(100))\n",
    "\n",
    "while True:\n",
    "    action, _ = model.predict(state, deterministic=True)\n",
    "    state, reward, terminated,truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        env.close()\n",
    "        break\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('pos', array([0.03875784, 0.03743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 0., 1.]))]) -2.0\n",
      "None None\n",
      "OrderedDict([('pos', array([0.03875784, 0.05743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.03875784, 0.07743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.03875784, 0.09743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 1., 0.]))]) -2.0\n",
      "None None\n",
      "OrderedDict([('pos', array([0.03875784, 0.09743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 1., 0.]))]) -2.0\n",
      "None None\n",
      "OrderedDict([('pos', array([0.05875784, 0.09743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 0., 0.]))]) -2.0\n",
      "None None\n",
      "OrderedDict([('pos', array([0.05875784, 0.11743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.07875784, 0.11743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 0., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.07875784, 0.13743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([1., 0., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.09875784, 0.13743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([1., 1., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.09875784, 0.15743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([1., 1., 0., 0.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.11875784, 0.15743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([0., 1., 0., 1.]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.13875784, 0.15743978])), ('theta', array([ 0.41215801,  0.19101522, -0.07303316,  0.48146942])), ('obs', array([1., 1., 1., 0.]))]) -2.0\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), ((0.0, 0.00125), (0.01625, 0.99125)), ((0.0075, 0.00125), (0.99875, 0.04)), ((0.98875, 0.0075), (0.99875, 1.0)), ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "state, observation = env.reset(np.random.randint(1005647))\n",
    "previous = None \n",
    "while True:\n",
    "    try:\n",
    "        state, reward, terminated, truncated, info = env.render()\n",
    "        if state != previous:\n",
    "            print(state,reward)\n",
    "            previous = state  \n",
    "        if terminated or truncated:\n",
    "            print(terminated, truncated)\n",
    "            env.close()\n",
    "            break\n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pos_nodeform(self):\n",
    "    \"\"\"\n",
    "    Set the agent's state to a new position.\n",
    "    \n",
    "    This function directly updates the agent's position (state) to the provided coordinates.\n",
    "\n",
    "    :param pos: A tuple or array representing the new position of the agent in the grid.\n",
    "    \"\"\"\n",
    "    low, high = -.2, 1.2 # depends on the shear (nto stretch since compression)\n",
    "    pos = self.sample(2,limit=(low,high))\n",
    "    \n",
    "    # Update the state (agent's position)\n",
    "    self.state = np.array(pos)\n",
    "\n",
    "    # Optionally, print the new state for debugging\n",
    "    # print(f\"New agent position: {self.state}\")\n",
    "\n",
    "def is_in_obstacle_nodeform(self, position):\n",
    "    \"\"\"\n",
    "    Check if a given position is inside any obstacle.\n",
    "    :param position: The (x, y) coordinates to check in the original space.\n",
    "    :return: True if the position is inside an obstacle, False otherwise.\n",
    "    \"\"\"\n",
    "    for obs in self.obstacles:\n",
    "        (x_min, y_min), (x_max, y_max) = obs\n",
    "        if x_min <= position[0] <= x_max and y_min <= position[1] <= y_max:            \n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [16:00<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "num_positions = 1000\n",
    "num_defomations = 1000\n",
    "dataset = []\n",
    "\n",
    "for i in trange(num_positions):\n",
    "    pos = env.set_pos_nodeform()\n",
    "    obstacle = env.is_in_obstacle_nodeform(pos)\n",
    "\n",
    "    for _ in range(num_defomations):\n",
    "        env.set_deformation(env.sample(2,env.stretch_range), env.sample(2,env.shear_range))\n",
    "        defomed_obstacle = env.is_in_obstacle(pos)\n",
    "        \n",
    "        datapoint = {\"pos\":       pos,\n",
    "                    \"theta\":      env.transformation_matrix,\n",
    "                    \"obs\":        1 if obstacle else 0,\n",
    "                    \"deform_obs\": 1 if defomed_obstacle else 0,\n",
    "                }\n",
    "        # env.render()\n",
    "        dataset.append(datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [00:20<14:46,  1.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_defomations):\n\u001b[1;32m     18\u001b[0m     pos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mset_pos_nodeform()\n\u001b[0;32m---> 19\u001b[0m     defomed_obstacle \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_in_obstacle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     datapoint \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m:       pos,\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m:      env\u001b[38;5;241m.\u001b[39mtransformation_matrix,\n\u001b[1;32m     23\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m:        \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obstacle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     24\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeform_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m defomed_obstacle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     25\u001b[0m             }\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# env.render()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[51], line 142\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.is_in_obstacle\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobstacles:\n\u001b[1;32m    141\u001b[0m     (x_min, y_min), (x_max, y_max) \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m--> 142\u001b[0m     bottom_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     bottom_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([x_max, y_min]))\n\u001b[1;32m    144\u001b[0m     top_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([x_min, y_max]))\n",
      "Cell \u001b[0;32mIn[51], line 124\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.transform\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, position):\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    Apply the grid deformation to a given position.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    :param position: (x, y) in original space.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    :return: Transformed position in the deformed grid.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformation_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "num_positions = 1000\n",
    "num_defomations = 1000\n",
    "dataset = []\n",
    "\n",
    "for i in trange(num_positions):\n",
    "    env.set_deformation(env.sample(2,env.stretch_range), env.sample(2,env.shear_range))\n",
    "    obstacle = env.is_in_obstacle_nodeform(pos)\n",
    "\n",
    "    for _ in range(num_defomations):\n",
    "        pos = env.set_pos_nodeform()\n",
    "        defomed_obstacle = env.is_in_obstacle(pos)\n",
    "        \n",
    "        datapoint = {\"pos\":       pos,\n",
    "                    \"theta\":      env.transformation_matrix,\n",
    "                    \"obs\":        1 if obstacle else 0,\n",
    "                    \"deform_obs\": 1 if defomed_obstacle else 0,\n",
    "                }\n",
    "        # env.render()\n",
    "        dataset.append(datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "import pickle\n",
    "\n",
    "with open(\"dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# lod dataset\n",
    "with open(\"dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): List of dictionaries containing 'o', 'theta', 'qpos', and 'qpos_new'.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve one sample of data by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with inputs and expected outputs as tensors.\n",
    "        \"\"\"\n",
    "        # Extract the dictionary for the given index\n",
    "        data = self.data_list[idx]\n",
    "        \n",
    "        # Convert data to PyTorch tensors\n",
    "        o = torch.tensor(data['obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        theta = torch.tensor(data['theta'], dtype=torch.float32).flatten()\n",
    "        o_new = torch.tensor(data['deform_obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        pos = torch.tensor(data['pos'], dtype=torch.float32)      \n",
    "        \n",
    "\n",
    "        # Inputs: qpos_new, o, theta\n",
    "        inputs = {\n",
    "            'deform_obs': o_new,\n",
    "            'theta': theta,\n",
    "            'pos': pos\n",
    "        }\n",
    "        \n",
    "        # Output: qpos_new\n",
    "        target = {\n",
    "            'pos': pos,\n",
    "            'obs': o\n",
    "        }\n",
    "        \n",
    "        return inputs, target\n",
    "\n",
    "\n",
    "# Instantiate the dataset\n",
    "custom_dataset = CustomDataset(dataset)\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(custom_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([2048, 1]), torch.Size([2048, 4]))\n"
     ]
    }
   ],
   "source": [
    "for inputs, target in data_loader:\n",
    "    print((inputs['deform_obs'].shape,inputs['theta'].shape))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(5, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x,theta):\n",
    "        x = torch.cat([x,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "# Check the output size\n",
    "# Iterate through the DataLoader\n",
    "for inputs, target in data_loader:\n",
    "    print(model(inputs['deform_obs'],inputs['theta']).shape)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flaccagora/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c277846c674073b0ccb67c48acfa49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runningLoss: 0.10374103590251235\n",
      "runningLoss: 0.10166368307879417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     27\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Zero the parameter gradients\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     33\u001b[0m o_new \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeform_obs\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m      \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Inputs: qpos_new, o, theta\u001b[39;00m\n\u001b[1;32m     38\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeform_obs\u001b[39m\u001b[38;5;124m'\u001b[39m: o_new,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m: theta,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m: pos\n\u001b[1;32m     42\u001b[0m }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train network \n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the model in training mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# tqdm progress bar\n",
    "pbar = tqdm(total=len(data_loader),desc=\"Training\")\n",
    "pbar.refresh()\n",
    "pbar.reset()\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (inputs, target) in enumerate(data_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target['obs'].to(device))\n",
    "\n",
    "        # Backward pass\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.reset()\n",
    "    print(\"runningLoss:\", running_loss/len(data_loader))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deform_obs': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), 'theta': tensor([[ 0.7117,  0.1233,  0.1769,  0.7061],\n",
      "        [ 0.5405, -0.1336, -0.0512,  0.7199],\n",
      "        [ 0.7270,  0.0432, -0.0792,  0.6558],\n",
      "        ...,\n",
      "        [ 0.8958,  0.1708, -0.0496,  0.5805],\n",
      "        [ 0.5689,  0.0363,  0.1134,  0.6968],\n",
      "        [ 0.8995, -0.0529, -0.0650,  0.5625]]), 'pos': tensor([[-0.1547,  0.0083],\n",
      "        [ 0.7960,  0.7271],\n",
      "        [ 0.7162,  0.0198],\n",
      "        ...,\n",
      "        [ 0.1327,  0.1832],\n",
      "        [ 0.6035,  1.1301],\n",
      "        [ 0.9394,  0.9019]])}\n",
      "tensor([[0.1009],\n",
      "        [0.1246],\n",
      "        [0.1134],\n",
      "        ...,\n",
      "        [0.1322],\n",
      "        [0.1096],\n",
      "        [0.1195]])\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, target in data_loader:\n",
    "        outputs = model(inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "        print(inputs)\n",
    "        print(outputs)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
