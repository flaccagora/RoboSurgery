{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "from tqdm import trange\n",
    "\n",
    "from agents.dqn import DoubleDQNAgent, QNetwork\n",
    "from environment.env import GridEnvDeform, POMDPWrapper_v0\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.belief import update_belief\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFhCAYAAAAsiOM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATu0lEQVR4nO3dX2yVhf3H8W+h6wGxdIID6SjoptMhK1MQwtgfJkxDDNEbNQvLOtyWuJQNRpaY3oztYpabLbqNIDqHSzYCxgTcTIAxxp+YSIQSEnCJm5vZuiF0JlspNammPb+r9ffjp0xP/Z7zUPp6JU/iOZzj8zlB0rfnPKV15XK5HAAACcYVPQAAuHwICwAgjbAAANIICwAgjbAAANIICwAgjbAAANLU1/qEQ0NDcfr06WhsbIy6urpanx4AGIFyuRx9fX3R3Nwc48Zd/H2JmofF6dOno6WlpdanBQASdHd3x8yZMy/66zUPi8bGxoiIePrpp+OKK66o9ekBgBF444034r777hv+On4xNQ+L/3z8ccUVV8SkSZNqfXoA4H14t8sYXLwJAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQZUVhs2rQprr322pgwYUIsWrQoXnzxxexdAMAoVHFY7NixI9avXx8bNmyI48ePx7x58+LOO++Mnp6eauwDAEaRisPiRz/6UXz961+P1atXx5w5c+Kxxx6LK664In7+85+/4+MHBgbi3LlzFxwAwOWporB48803o6urK5YvX/6//4Jx42L58uXxwgsvvONzOjs7o6mpafhoaWl5f4sBgEtWRWHx+uuvx+DgYEyfPv2C+6dPnx5nzpx5x+d0dHREb2/v8NHd3T3ytQDAJa2+2icolUpRKpWqfRoA4BJQ0TsWV199dYwfPz7Onj17wf1nz56Na665JnUYADD6VBQWDQ0NMX/+/Ni/f//wfUNDQ7F///5YvHhx+jgAYHSp+KOQ9evXR1tbWyxYsCAWLlwYjzzySPT398fq1aursQ8AGEUqDov7778//vnPf8Z3v/vdOHPmTHzyk5+MPXv2vO2CTgBg7BnRxZtr1qyJNWvWZG8BAEY5PysEAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEhTX/SAsWTp0qVFTyjEwYMHi55QCL/fjAVj9fd7rP75fi+8YwEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApKk4LA4fPhwrV66M5ubmqKuri127dlVhFgAwGlUcFv39/TFv3rzYtGlTNfYAAKNYfaVPWLFiRaxYseI9P35gYCAGBgaGb587d67SUwIAo0TVr7Ho7OyMpqam4aOlpaXapwQAClL1sOjo6Ije3t7ho7u7u9qnBAAKUvFHIZUqlUpRKpWqfRoA4BLg200BgDTCAgBIU/FHIefPn49XXnll+Parr74aJ06ciClTpsSsWbNSxwEAo0vFYXHs2LH4/Oc/P3x7/fr1ERHR1tYWTz31VNowAGD0qTgsli5dGuVyuRpbAIBRzjUWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAECa+qIHADB6LV26tOgJXGK8YwEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApKkoLDo7O+O2226LxsbGmDZtWtxzzz3x8ssvV2sbADDKVBQWhw4divb29jhy5Ejs27cv3nrrrbjjjjuiv7+/WvsAgFGkvpIH79mz54LbTz31VEybNi26urris5/97Ds+Z2BgIAYGBoZvnzt3bgQzAYDR4H1dY9Hb2xsREVOmTLnoYzo7O6OpqWn4aGlpeT+nBAAuYSMOi6GhoVi3bl0sWbIk5s6de9HHdXR0RG9v7/DR3d090lMCAJe4ij4K+b/a29vj1KlT8fzzz//Xx5VKpSiVSiM9DQAwiowoLNasWRPPPfdcHD58OGbOnJm9CQAYpSoKi3K5HN/85jdj586dcfDgwbjuuuuqtQsAGIUqCov29vbYtm1bPPvss9HY2BhnzpyJiIimpqaYOHFiVQYCAKNHRRdvbt68OXp7e2Pp0qUxY8aM4WPHjh3V2gcAjCIVfxQCAHAxflYIAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJCmvugBXP6WLl1a9IRC1NXVFT2hEAcOHCh6AlAg71gAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGkqCovNmzdHa2trTJ48OSZPnhyLFy+O3bt3V2sbADDKVBQWM2fOjI0bN0ZXV1ccO3Ysbr/99rj77rvjpZdeqtY+AGAUqa/kwStXrrzg9g9+8IPYvHlzHDlyJG6++eZ3fM7AwEAMDAwM3z537twIZgIAo8GIr7EYHByM7du3R39/fyxevPiij+vs7Iympqbho6WlZaSnBAAucRWHxcmTJ+PKK6+MUqkUDz74YOzcuTPmzJlz0cd3dHREb2/v8NHd3f2+BgMAl66KPgqJiLjxxhvjxIkT0dvbG88880y0tbXFoUOHLhoXpVIpSqXS+x4KAFz6Kg6LhoaGuP766yMiYv78+XH06NF49NFHY8uWLenjAIDR5X3/PRZDQ0MXXJwJAIxdFb1j0dHREStWrIhZs2ZFX19fbNu2LQ4ePBh79+6t1j4AYBSpKCx6enriy1/+crz22mvR1NQUra2tsXfv3vjCF75QrX0AwChSUVg8+eST1doBAFwG/KwQACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACCNsAAA0ggLACBNfdEDxpKDBw8WPYEaOnDgQNETAGrOOxYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkERYAQBphAQCkeV9hsXHjxqirq4t169YlzQEARrMRh8XRo0djy5Yt0dramrkHABjFRhQW58+fj1WrVsUTTzwRV111VfYmAGCUGlFYtLe3x1133RXLly9/18cODAzEuXPnLjgAgMtTfaVP2L59exw/fjyOHj36nh7f2dkZ3//+9yseBgCMPhW9Y9Hd3R1r166NX/3qVzFhwoT39JyOjo7o7e0dPrq7u0c0FAC49FX0jkVXV1f09PTErbfeOnzf4OBgHD58OH7605/GwMBAjB8//oLnlEqlKJVKOWsBgEtaRWGxbNmyOHny5AX3rV69Om666aZ46KGH3hYVAMDYUlFYNDY2xty5cy+4b9KkSTF16tS33Q8AjD3+5k0AIE3F3xXy/x08eDBhBgBwOfCOBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQpr7WJyyXyxER8cYbb9T61ADACP3n6/Z/vo5fTF353R6R7O9//3u0tLTU8pQAQJLu7u6YOXPmRX+95mExNDQUp0+fjsbGxqirq6vlqePcuXPR0tIS3d3dMXny5Jqeu0het9c9FnjdXvdYUOTrLpfL0dfXF83NzTFu3MWvpKj5RyHjxo37r6VTC5MnTx5T/yH+h9c9tnjdY4vXPbYU9bqbmpre9TEu3gQA0ggLACDNmAqLUqkUGzZsiFKpVPSUmvK6ve6xwOv2useC0fC6a37xJgBw+RpT71gAANUlLACANMICAEgjLACANMICAEgzZsJi06ZNce2118aECRNi0aJF8eKLLxY9qeoOHz4cK1eujObm5qirq4tdu3YVPanqOjs747bbbovGxsaYNm1a3HPPPfHyyy8XPavqNm/eHK2trcN/G9/ixYtj9+7dRc+quY0bN0ZdXV2sW7eu6ClV9b3vfS/q6uouOG666aaiZ9XEP/7xj/jSl74UU6dOjYkTJ8YnPvGJOHbsWNGzquraa6992+93XV1dtLe3Fz3tHY2JsNixY0esX78+NmzYEMePH4958+bFnXfeGT09PUVPq6r+/v6YN29ebNq0qegpNXPo0KFob2+PI0eOxL59++Ktt96KO+64I/r7+4ueVlUzZ86MjRs3RldXVxw7dixuv/32uPvuu+Oll14qelrNHD16NLZs2RKtra1FT6mJm2++OV577bXh4/nnny96UtX961//iiVLlsQHPvCB2L17d/zhD3+IH/7wh3HVVVcVPa2qjh49esHv9b59+yIi4t577y142UWUx4CFCxeW29vbh28PDg6Wm5uby52dnQWuqq2IKO/cubPoGTXX09NTjojyoUOHip5Sc1dddVX5Zz/7WdEzaqKvr698ww03lPft21f+3Oc+V167dm3Rk6pqw4YN5Xnz5hU9o+Yeeuih8qc//emiZxRu7dq15Y9+9KPloaGhoqe8o8v+HYs333wzurq6Yvny5cP3jRs3LpYvXx4vvPBCgcuohd7e3oiImDJlSsFLamdwcDC2b98e/f39sXjx4qLn1ER7e3vcddddF/w5v9z96U9/iubm5vjIRz4Sq1atir/97W9FT6q6X//617FgwYK49957Y9q0aXHLLbfEE088UfSsmnrzzTfjl7/8ZTzwwAM1/wnh79VlHxavv/56DA4OxvTp0y+4f/r06XHmzJmCVlELQ0NDsW7duliyZEnMnTu36DlVd/LkybjyyiujVCrFgw8+GDt37ow5c+YUPavqtm/fHsePH4/Ozs6ip9TMokWL4qmnnoo9e/bE5s2b49VXX43PfOYz0dfXV/S0qvrLX/4SmzdvjhtuuCH27t0b3/jGN+Jb3/pW/OIXvyh6Ws3s2rUr/v3vf8dXvvKVoqdcVM1/bDrUSnt7e5w6dWpMfPYcEXHjjTfGiRMnore3N5555ploa2uLQ4cOXdZx0d3dHWvXro19+/bFhAkTip5TMytWrBj+59bW1li0aFHMnj07nn766fjqV79a4LLqGhoaigULFsTDDz8cERG33HJLnDp1Kh577LFoa2sreF1tPPnkk7FixYpobm4uespFXfbvWFx99dUxfvz4OHv27AX3nz17Nq655pqCVlFta9asieeeey4OHDgQM2fOLHpOTTQ0NMT1118f8+fPj87Ozpg3b148+uijRc+qqq6urujp6Ylbb7016uvro76+Pg4dOhQ//vGPo76+PgYHB4ueWBMf/OAH42Mf+1i88sorRU+pqhkzZrwtlD/+8Y+PiY+BIiL++te/xu9+97v42te+VvSU/+qyD4uGhoaYP39+7N+/f/i+oaGh2L9//5j5/HksKZfLsWbNmti5c2f8/ve/j+uuu67oSYUZGhqKgYGBomdU1bJly+LkyZNx4sSJ4WPBggWxatWqOHHiRIwfP77oiTVx/vz5+POf/xwzZswoekpVLVmy5G3fPv7HP/4xZs+eXdCi2tq6dWtMmzYt7rrrrqKn/Fdj4qOQ9evXR1tbWyxYsCAWLlwYjzzySPT398fq1auLnlZV58+fv+D/YF599dU4ceJETJkyJWbNmlXgsuppb2+Pbdu2xbPPPhuNjY3D19E0NTXFxIkTC15XPR0dHbFixYqYNWtW9PX1xbZt2+LgwYOxd+/eoqdVVWNj49uun5k0aVJMnTr1sr6u5jvf+U6sXLkyZs+eHadPn44NGzbE+PHj44tf/GLR06rq29/+dnzqU5+Khx9+OO6777548cUX4/HHH4/HH3+86GlVNzQ0FFu3bo22traor7/Ev3QX/W0ptfKTn/ykPGvWrHJDQ0N54cKF5SNHjhQ9qeoOHDhQjoi3HW1tbUVPq5p3er0RUd66dWvR06rqgQceKM+ePbvc0NBQ/tCHPlRetmxZ+be//W3RswoxFr7d9P777y/PmDGj3NDQUP7whz9cvv/++8uvvPJK0bNq4je/+U157ty55VKpVL7pppvKjz/+eNGTamLv3r3liCi//PLLRU95V3XlcrlcTNIAAJeby/4aCwCgdoQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaYQFAJBGWAAAaf4HQwE2fNUqu/8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: 144, Actions: 4, Observations 32, Thetas [(1, 1), (2, 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# maze size\n",
    "N = 2\n",
    "\n",
    "# thetas deformations (range(a,b),range(c,d))\n",
    "l0 = 1\n",
    "h0 = 3\n",
    "l1 = 1\n",
    "h1 = 2\n",
    "\n",
    "maze = np.load(f\"maze/maze_{N}.npy\")\n",
    "env = GridEnvDeform(maze,l0,h0,l1,h1)\n",
    "env.render()\n",
    "\n",
    "states = [((x,y,phi),(i,j)) for x in range(1,env.max_shape[0]-1) for y in range(1,env.max_shape[1]-1) for phi in range(4) for i in range(l0,h0) for j in range(l1,h1)] \n",
    "actions = [0,1,2,3]\n",
    "obs = list(itertools.product([0,1], repeat=5))\n",
    "thetas = [(i,j) for i in range(l0,h0) for j in range(l1,h1)]\n",
    "\n",
    "state_dict = {state: i for i, state in enumerate(states)}\n",
    "obs_dict = {obs : i for i, obs in enumerate(obs)}\n",
    "\n",
    "# Actions are: 0-listen, 1-open-left, 2-open-right\n",
    "lenS = len(states)\n",
    "lenA = len(actions)\n",
    "lenO = len(obs)\n",
    "\n",
    "print(f\"States: {lenS}, Actions: {lenA}, Observations {lenO}, Thetas {thetas}\\n\")\n",
    "\n",
    "T = torch.load(f\"models/T_maze_{N}.pt\", weights_only=True)\n",
    "R = torch.load(f\"models/R_maze_{N}.pt\", weights_only=True)\n",
    "O = torch.load(f\"models/O_maze_{N}.pt\", weights_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POMDP  train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DoubleDQNAgent(state_dim=144, action_dim=4, lr = 0.01)\n",
    "\n",
    "pomdp_env = POMDPWrapper_v0(env, agent, T, R, O, state_dict, obs_dict, thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–Ž         | 37/1000 [00:08<03:53,  4.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m max_episode_steps:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m         next_obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43mpomdp_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         b_prime \u001b[38;5;241m=\u001b[39m update_belief(b, action,obs,T,O)\n\u001b[1;32m     24\u001b[0m         agent\u001b[38;5;241m.\u001b[39mstore_transition(b, action, reward, b_prime, done)\n",
      "File \u001b[0;32m~/Desktop/RoboSurgery/src/environment/env.py:253\u001b[0m, in \u001b[0;36mPOMDPWrapper_v0.step\u001b[0;34m(self, s, a)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m,s,a):\n\u001b[1;32m    252\u001b[0m     s_prime \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT[s,a,:])\n\u001b[0;32m--> 253\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR[s,a,\u001b[43ms_prime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    254\u001b[0m     obs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mO[s_prime,\u001b[38;5;241m0\u001b[39m,:])\n\u001b[1;32m    255\u001b[0m     info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: s_prime\u001b[38;5;241m.\u001b[39mitem()}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "max_episode_steps = 100\n",
    "\n",
    "rewards = []\n",
    "evalrewards = []\n",
    "\n",
    "for episode in trange(num_episodes):\n",
    "    \n",
    "    obs, info = pomdp_env.reset()\n",
    "    s = info['actual_state']\n",
    "\n",
    "    b_0 = torch.ones(len(states)) / len(states)   \n",
    "    b = update_belief(b_0, 0, obs, T,O)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    steps = 0\n",
    "    while not done and steps < max_episode_steps:\n",
    "        \n",
    "        for action in range(4):\n",
    "            next_obs, reward, done, info = pomdp_env.step(s,action)\n",
    "            b_prime = update_belief(b, action,obs,T,O)\n",
    "            agent.store_transition(b, action, reward, b_prime, done)\n",
    "\n",
    "        action = agent.choose_action(b)\n",
    "        obs, reward, done, info = pomdp_env.step(s,action)\n",
    "        next_state = info['actual_state']\n",
    "        b_prime = update_belief(b, action,obs,T,O)\n",
    "\n",
    "\n",
    "        agent.train()\n",
    "        b = b_prime\n",
    "        s = next_state\n",
    "\n",
    "        episode_reward += reward\n",
    "        steps += 1        \n",
    "    \n",
    "    agent.update_epsilon()\n",
    "    rewards.append(episode_reward)\n",
    "            \n",
    "\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
