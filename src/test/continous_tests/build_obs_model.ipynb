{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import ObservableDeformedGridworld\n",
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 14/1000 [00:16<19:05,  1.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_defomations):\n\u001b[1;32m     17\u001b[0m     env\u001b[38;5;241m.\u001b[39mset_deformation(env\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m2\u001b[39m,env\u001b[38;5;241m.\u001b[39mstretch_range), env\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m2\u001b[39m,env\u001b[38;5;241m.\u001b[39mshear_range))\n\u001b[0;32m---> 18\u001b[0m     defomed_obstacle \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_in_obstacle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     datapoint \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m:       pos,\n\u001b[1;32m     21\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m:      env\u001b[38;5;241m.\u001b[39mtransformation_matrix,\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m:        \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obstacle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     23\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeform_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m defomed_obstacle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     24\u001b[0m             }\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# env.render()\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/RoboSurgery/src/environment/env.py:1261\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.is_in_obstacle\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     top_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([x_max, y_max]))\n\u001b[1;32m   1260\u001b[0m     obstacle \u001b[38;5;241m=\u001b[39m [bottom_left, bottom_right, top_right, top_left]\n\u001b[0;32m-> 1261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_point_in_parallelogram(position, obstacle):\n\u001b[1;32m   1262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = ObservableDeformedGridworld(\n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "num_positions = 1000\n",
    "num_defomations = 1000\n",
    "dataset = []\n",
    "\n",
    "for i in trange(num_positions):\n",
    "    pos = env.set_pos_nodeform()\n",
    "    obstacle = env.is_in_obstacle_nodeform(pos)\n",
    "\n",
    "    for _ in range(num_defomations):\n",
    "        env.set_deformation(env.sample(2,env.stretch_range), env.sample(2,env.shear_range))\n",
    "        defomed_obstacle = env.is_in_obstacle(pos)\n",
    "        \n",
    "        datapoint = {\"pos\":       pos,\n",
    "                    \"theta\":      env.transformation_matrix,\n",
    "                    \"obs\":        1 if obstacle else 0,\n",
    "                    \"deform_obs\": 1 if defomed_obstacle else 0,\n",
    "                }\n",
    "        # env.render()\n",
    "        dataset.append(datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "import pickle\n",
    "\n",
    "with open(\"dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# lod dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# lod dataset\n",
    "with open(\"dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): List of dictionaries containing 'o', 'theta', 'qpos', and 'qpos_new'.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve one sample of data by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with inputs and expected outputs as tensors.\n",
    "        \"\"\"\n",
    "        # Extract the dictionary for the given index\n",
    "        data = self.data_list[idx]\n",
    "        \n",
    "        # Convert data to PyTorch tensors\n",
    "        o = torch.tensor(data['obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        theta = torch.tensor(data['theta'], dtype=torch.float32).flatten()\n",
    "        o_new = torch.tensor(data['deform_obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        pos = torch.tensor(data['pos'], dtype=torch.float32)      \n",
    "        \n",
    "\n",
    "        # Inputs: qpos_new, o, theta\n",
    "        inputs = {\n",
    "            'deform_obs': o_new,\n",
    "            'theta': theta,\n",
    "            'pos': pos\n",
    "        }\n",
    "        \n",
    "        # Output: qpos_new\n",
    "        target = {\n",
    "            'pos': pos,\n",
    "            'obs': o\n",
    "        }\n",
    "        \n",
    "        return inputs, target\n",
    "\n",
    "\n",
    "# Instantiate the dataset\n",
    "custom_dataset = CustomDataset(dataset)\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(custom_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([1024, 1]), torch.Size([1024, 4]))\n"
     ]
    }
   ],
   "source": [
    "for inputs, target in data_loader:\n",
    "    print((inputs['deform_obs'].shape,inputs['theta'].shape))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "# Check the output size\n",
    "# Iterate through the DataLoader\n",
    "for inputs, target in data_loader:\n",
    "    print(model(inputs['pos'],inputs['deform_obs'],inputs['theta']).shape)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0665ffc4c197460d8e93cdce93f5e47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runningLoss: 0.36275911962607743\n",
      "runningLoss: 0.28178783790603995\n",
      "runningLoss: 0.2606878045149445\n",
      "runningLoss: 0.24350653864832228\n",
      "runningLoss: 0.22974412823467685\n"
     ]
    }
   ],
   "source": [
    "# train network \n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the model in training mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e2deebe0df4106853955292a46e62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runningLoss: 0.06769560960368344\n",
      "runningLoss: 0.06450088120455508\n",
      "runningLoss: 0.06130198488810777\n",
      "runningLoss: 0.05854604267415151\n",
      "runningLoss: 0.05574614926410063\n"
     ]
    }
   ],
   "source": [
    "# tqdm progress bar\n",
    "pbar = tqdm(total=len(data_loader),desc=\"Training\")\n",
    "pbar.refresh()\n",
    "pbar.reset()\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (inputs, target) in enumerate(data_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs['pos'].to(device),inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target['obs'].to(device))\n",
    "\n",
    "        # Backward pass\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.reset()\n",
    "    print(\"runningLoss:\", running_loss/len(data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"obs_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter target with obstacle\n",
    "count = 0\n",
    "for inputs, target in data_loader:\n",
    "    count += torch.count_nonzero(target['obs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 121000, 0.121)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dataset), count.item(), count.item()/len(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(121000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deform_obs': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), 'theta': tensor([[ 0.6069,  0.0460, -0.1410,  0.7324],\n",
      "        [ 0.4951, -0.0290, -0.1900,  0.5352],\n",
      "        [ 0.5310, -0.0502,  0.1989,  0.4344],\n",
      "        ...,\n",
      "        [ 0.5591, -0.1723,  0.1204,  0.5878],\n",
      "        [ 0.9620,  0.1982, -0.0428,  0.7177],\n",
      "        [ 0.4606, -0.0163,  0.0165,  0.8431]]), 'pos': tensor([[0.7033, 0.4231],\n",
      "        [0.5368, 0.4076],\n",
      "        [1.1467, 1.1071],\n",
      "        ...,\n",
      "        [0.4275, 1.1039],\n",
      "        [1.0132, 1.0841],\n",
      "        [0.0238, 1.0522]])}\n",
      "tensor([[4.3709e-04],\n",
      "        [4.6240e-01],\n",
      "        [6.8391e-05],\n",
      "        ...,\n",
      "        [4.8210e-02],\n",
      "        [1.5263e-03],\n",
      "        [1.8719e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, target in data_loader:\n",
    "        outputs = model(inputs['pos'].to(device),inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "        print(inputs)\n",
    "        print(outputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs[outputs>0.5].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
