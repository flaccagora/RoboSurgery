{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import ObservableDeformedGridworld\n",
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [15:16<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = ObservableDeformedGridworld(\n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "num_positions = 1000\n",
    "num_defomations = 1000\n",
    "dataset = []\n",
    "\n",
    "for i in trange(num_positions):\n",
    "    pos = env.set_pos_nodeform()\n",
    "    obstacle = env.is_in_obstacle_nodeform(pos)\n",
    "\n",
    "    for _ in range(num_defomations):\n",
    "        env.set_deformation(env.sample(2,env.stretch_range), env.sample(2,env.shear_range))\n",
    "        defomed_obstacle = env.is_in_obstacle(pos)\n",
    "        \n",
    "        datapoint = {\"pos\":       pos,\n",
    "                    \"theta\":      env.transformation_matrix,\n",
    "                    \"obs\":        1 if obstacle else 0,\n",
    "                    \"deform_obs\": 1 if defomed_obstacle else 0,\n",
    "                }\n",
    "        # env.render()\n",
    "        dataset.append(datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "import pickle\n",
    "\n",
    "with open(\"dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# lod dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# lod dataset\n",
    "with open(\"dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): List of dictionaries containing 'o', 'theta', 'qpos', and 'qpos_new'.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve one sample of data by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with inputs and expected outputs as tensors.\n",
    "        \"\"\"\n",
    "        # Extract the dictionary for the given index\n",
    "        data = self.data_list[idx]\n",
    "        \n",
    "        # Convert data to PyTorch tensors\n",
    "        o = torch.tensor(data['obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        theta = torch.tensor(data['theta'], dtype=torch.float32).flatten()\n",
    "        o_new = torch.tensor(data['deform_obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        pos = torch.tensor(data['pos'], dtype=torch.float32)      \n",
    "        \n",
    "\n",
    "        # Inputs: qpos_new, o, theta\n",
    "        inputs = {\n",
    "            'deform_obs': o_new,\n",
    "            'theta': theta,\n",
    "            'pos': pos\n",
    "        }\n",
    "        \n",
    "        # Output: qpos_new\n",
    "        target = {\n",
    "            'pos': pos,\n",
    "            'obs': o\n",
    "        }\n",
    "        \n",
    "        return inputs, target\n",
    "\n",
    "\n",
    "# Instantiate the dataset\n",
    "custom_dataset = CustomDataset(dataset)\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(custom_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([1024, 1]), torch.Size([1024, 4]))\n"
     ]
    }
   ],
   "source": [
    "for inputs, target in data_loader:\n",
    "    print((inputs['deform_obs'].shape,inputs['theta'].shape))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "# Check the output size\n",
    "# Iterate through the DataLoader\n",
    "for inputs, target in data_loader:\n",
    "    print(model(inputs['pos'],inputs['deform_obs'],inputs['theta']).shape)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (f1): Linear(in_features=7, out_features=128, bias=True)\n",
       "  (f2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (f3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (f4): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train network \n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the model in training mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeac07ed6c604980a62b67b88a1b4cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runningLoss: 0.2144535858653097\n",
      "runningLoss: 0.08388630141377328\n",
      "runningLoss: 0.039968182678842494\n",
      "runningLoss: 0.025597751540958332\n",
      "runningLoss: 0.019215802113480767\n",
      "runningLoss: 0.01612439852716933\n",
      "runningLoss: 0.012459583046198836\n",
      "runningLoss: 0.011921922532801527\n",
      "runningLoss: 0.010664185627764939\n",
      "runningLoss: 0.009455553987235053\n",
      "runningLoss: 0.007602920692114726\n",
      "runningLoss: 0.0078061302932467365\n",
      "runningLoss: 0.007648480576610797\n",
      "runningLoss: 0.008177641274797384\n",
      "runningLoss: 0.006873367383943617\n",
      "runningLoss: 0.007289401397462686\n",
      "runningLoss: 0.006344022617404642\n",
      "runningLoss: 0.006441807834419137\n",
      "runningLoss: 0.005146051003853147\n",
      "runningLoss: 0.006723761171156859\n",
      "runningLoss: 0.006416656239019724\n",
      "runningLoss: 0.004835184061141473\n",
      "runningLoss: 0.005166999004807937\n",
      "runningLoss: 0.005838286008353621\n",
      "runningLoss: 0.004377752987125997\n"
     ]
    }
   ],
   "source": [
    "# tqdm progress bar\n",
    "pbar = tqdm(total=len(data_loader),desc=\"Training\")\n",
    "pbar.refresh()\n",
    "pbar.reset()\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for epoch in range(25):\n",
    "    running_loss = 0.0\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (inputs, target) in enumerate(data_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs['pos'].to(device),inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target['obs'].to(device))\n",
    "\n",
    "        # Backward pass\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.reset()\n",
    "    print(\"runningLoss:\", running_loss/len(data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"obs_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter target with obstacle\n",
    "count = 0\n",
    "for inputs, target in data_loader:\n",
    "    count += torch.count_nonzero(target['obs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 121000, 0.121)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dataset), count.item(), count.item()/len(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(121000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deform_obs': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), 'theta': tensor([[ 0.6069,  0.0460, -0.1410,  0.7324],\n",
      "        [ 0.4951, -0.0290, -0.1900,  0.5352],\n",
      "        [ 0.5310, -0.0502,  0.1989,  0.4344],\n",
      "        ...,\n",
      "        [ 0.5591, -0.1723,  0.1204,  0.5878],\n",
      "        [ 0.9620,  0.1982, -0.0428,  0.7177],\n",
      "        [ 0.4606, -0.0163,  0.0165,  0.8431]]), 'pos': tensor([[0.7033, 0.4231],\n",
      "        [0.5368, 0.4076],\n",
      "        [1.1467, 1.1071],\n",
      "        ...,\n",
      "        [0.4275, 1.1039],\n",
      "        [1.0132, 1.0841],\n",
      "        [0.0238, 1.0522]])}\n",
      "tensor([[4.3709e-04],\n",
      "        [4.6240e-01],\n",
      "        [6.8391e-05],\n",
      "        ...,\n",
      "        [4.8210e-02],\n",
      "        [1.5263e-03],\n",
      "        [1.8719e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, target in data_loader:\n",
    "        outputs = model(inputs['pos'].to(device),inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "        print(inputs)\n",
    "        print(outputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs[outputs>0.5].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
