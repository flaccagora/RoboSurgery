{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pygame\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import ObservableDeformedGridworld\n",
    "from utils.checkpoints import find_last_checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_rectangle(vertices):\n",
    "    \"\"\"\n",
    "    Computes the bounding rectangle for a quadrilateral.\n",
    "    \n",
    "    Parameters:\n",
    "        vertices (list of tuples): Vertices of the quadrilateral.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Vertices of the bounding rectangle.\n",
    "    \"\"\"\n",
    "    x_coords = [v[0] for v in vertices]\n",
    "    y_coords = [v[1] for v in vertices]\n",
    "    xmin, xmax = min(x_coords), max(x_coords)\n",
    "    ymin, ymax = min(y_coords), max(y_coords)\n",
    "    \n",
    "    return [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "\n",
    "def is_point_in_triangle(point, triangle):\n",
    "    \"\"\"\n",
    "    Check if a point is inside a triangle using barycentric coordinates.\n",
    "    \n",
    "    Args:\n",
    "        point (tuple): (x, y) coordinates of the point to check\n",
    "        triangle (list): List of 3 tuples, each representing vertex coordinates [(x1,y1), (x2,y2), (x3,y3)]\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if point is inside the triangle, False otherwise\n",
    "    \"\"\"\n",
    "    def compute_barycentric_coordinates(pt, v1, v2, v3):\n",
    "        \"\"\"\n",
    "        Compute barycentric coordinates of a point with respect to a triangle.\n",
    "        \n",
    "        Args:\n",
    "            pt (tuple): Point coordinates\n",
    "            v1, v2, v3 (tuple): Vertex coordinates of the triangle\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Barycentric coordinates (u, v, w)\n",
    "        \"\"\"\n",
    "        pt = np.array(pt)\n",
    "        v1, v2, v3 = np.array(v1), np.array(v2), np.array(v3)\n",
    "        \n",
    "        # Vectorized area computation\n",
    "        triangle_area = np.abs(np.cross(v2 - v1, v3 - v1)) / 2\n",
    "        \n",
    "        # Areas of sub-triangles\n",
    "        area1 = np.abs(np.cross(pt - v2, v3 - v2)) / 2\n",
    "        area2 = np.abs(np.cross(v1 - pt, v3 - v1)) / 2\n",
    "        area3 = np.abs(np.cross(v1 - v2, pt - v2)) / 2\n",
    "        \n",
    "        # Compute barycentric coordinates\n",
    "        u = area1 / triangle_area\n",
    "        v = area2 / triangle_area\n",
    "        w = area3 / triangle_area\n",
    "        \n",
    "        return u, v, w\n",
    "    \n",
    "    # Compute barycentric coordinates\n",
    "    u, v, w = compute_barycentric_coordinates(point, triangle[0], triangle[1], triangle[2])\n",
    "    \n",
    "    # Point is inside if all barycentric coordinates are between 0 and 1 (inclusive)\n",
    "    return 0 <= u <= 1 and 0 <= v <= 1 and 0 <= w <= 1 and np.abs(u + v + w - 1) < 1e-10\n",
    "\n",
    "def is_point_in_parallelogram(point, box):\n",
    "    \"\"\"\n",
    "    Check if a point is inside a parallelogram.\n",
    "    \n",
    "    Args:\n",
    "        point (tuple): (x, y) coordinates of the point to check\n",
    "        box (list): List of 4 tuples, each representing vertex coordinates [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if point is inside the parallelogram, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if the point is in one of the two triangles of the parallelogram\n",
    "    return is_point_in_triangle(point, [box[0], box[1], box[2]]) or is_point_in_triangle(point, [box[0], box[2], box[3]])\n",
    "\n",
    "def sample_in_parallelogram(box):\n",
    "    \"\"\"\n",
    "    Sample a point uniformly inside a parallelogram.\n",
    "    \n",
    "    Args:\n",
    "        box (list): List of 4 tuples, each representing vertex coordinates [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x, y) coordinates of the sampled point\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute bounding box\n",
    "    rect = bounding_rectangle(box)\n",
    "    x_min, y_min = rect[0]\n",
    "    x_max, y_max = rect[2]    \n",
    "    # Keep sampling until a point inside the parallelogram is found\n",
    "\n",
    "    x = np.random.uniform(x_min, x_max)\n",
    "    y = np.random.uniform(y_min, y_max)\n",
    "    while not is_point_in_parallelogram((x, y), box):\n",
    "        x = np.random.uniform(x_min, x_max)\n",
    "        y = np.random.uniform(y_min, y_max)\n",
    "    \n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point: [0.45388612 0.95050459]\n",
      "Box: [array([0., 0.]), array([0.55654792, 0.14692519]), array([0.53335694, 1.08853905]), array([-0.02319099,  0.94161386])]\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAH/CAYAAAAVLaS3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3QElEQVR4nO3de3xU9Z3/8XdCMhNREooIBAFFsUDlDoLByKWmoLKubLePpaxVioi1hV+h8eEFtpXbLllbFd3Kb5GHa9FWV2t/K92qVUO4BhAE4VFAREEK1hIUL4mADbmc3x+HmVyYJDNnvucyyev5eOQxzOScmW/GOOedz/eWZlmWJQAAAIPS/W4AAABofQgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDhXA0ZRUZGuuuoqdejQQV26dNHkyZN14MCBFs978cUX1a9fP2VlZWngwIF69dVX3WwmAAAwzNWAsWHDBs2aNUtvvvmmiouLVVVVpQkTJujUqVNNnrNlyxZNnTpVM2bM0K5duzR58mRNnjxZe/fudbOpAADAoDQvNzv75JNP1KVLF23YsEFjxoyJecyUKVN06tQpvfzyy9HHrr76ag0ZMkQrVqzwqqkAACAJGV6+WHl5uSSpU6dOTR6zdetWFRYWNnhs4sSJWr16dczjKysrVVlZGb1fW1urzz77TBdeeKHS0tKSbzQAAK2YZVn68ssv1b17d6Wnm+vY8Cxg1NbWau7cubrmmms0YMCAJo8rKytT165dGzzWtWtXlZWVxTy+qKhIixYtMtpWAADamg8//FA9evQw9nyeBYxZs2Zp7969Ki0tNfq88+bNa1DxKC8vV69evfThhx8qOzvb6GsBANDaVFRUqGfPnurQoYPR5/UkYMyePVsvv/yyNm7c2GI66tatm44fP97gsePHj6tbt24xjw+HwwqHw+c8np2dTcAAACBOpocVuDqLxLIszZ49Wy+99JLWrl2r3r17t3hOXl6eSkpKGjxWXFysvLw8t5oJAAAMc7WCMWvWLD333HP6/e9/rw4dOkTHUeTk5Oi8886TJN122226+OKLVVRUJEmaM2eOxo4dq4cffliTJk3S888/rx07dmjlypVuNhUAABjkagXjP//zP1VeXq5x48YpNzc3+vXCCy9Ejzl69KiOHTsWvT969Gg999xzWrlypQYPHqzf/e53Wr16dbMDQwEAQLB4ug6GFyoqKpSTk6Py8nLGYAAA0AK3rpvsRQIAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMczVgbNy4UTfddJO6d++utLQ0rV69utnj169fr7S0tHO+ysrK3GwmAAAwzNWAcerUKQ0ePFjLly9P6LwDBw7o2LFj0a8uXbq41EIAAOCGDDef/IYbbtANN9yQ8HldunRRx44dzTcIAAB4IpBjMIYMGaLc3Fx961vf0ubNm/1uDgAASJCrFYxE5ebmasWKFRoxYoQqKyv15JNPaty4cdq2bZuGDRsW85zKykpVVlZG71dUVHjVXAAA0IRABYy+ffuqb9++0fujR4/WoUOHtGzZMv3617+OeU5RUZEWLVrkVRMBAEAcAtlFUt/IkSN18ODBJr8/b948lZeXR78+/PBDD1sHAABiCVQFI5bdu3crNze3ye+Hw2GFw2EPWwQAAFriasA4efJkg+rD4cOHtXv3bnXq1Em9evXSvHnz9NFHH+mZZ56RJD366KPq3bu3rrzySv3tb3/Tk08+qbVr1+qNN95ws5kAAMAwVwPGjh07NH78+Oj9wsJCSdK0adO0atUqHTt2TEePHo1+/8yZM7r77rv10UcfqX379ho0aJDWrFnT4DkAAEDwpVmWZfndCJMqKiqUk5Oj8vJyZWdn+90cAAACza3rZuAHeQIAgNRDwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcQQMAABgHAEDAAAYR8AAAADGETAAAIBxBAwAAGAcAQMAABhHwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcQQMAABgHAEDAAAYR8AAAADGETAAAIBxBAwAAGAcAQMAABhHwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcQQMAABgHAEDAAAYR8AAAADGETAAAIBxBAwAAGAcAQMAABhHwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcQQMAABgHAEDAAAYR8AAAADGETAAAIBxBAwAAGAcAQMAABhHwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcQQMAABgHAEDAAAYR8AAAADGETAAAIBxBAwAAGAcAQMAABhHwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcQQMAABgHAEDAAAYl+F3A5B6jpYf1YnTJ/xuBiTp1Cnp7Z3Stu3S9u3SqFHS3XdHv925fWf1yunlYwMBtFUEDCTkaPlR9V/eX6erTvvdFNSXLalAkg5JK5+LPtw+s732z9pPyADgOQIGEnLi9Amdrjqt3/zDb9T/ov5+N6f1q62V3n/frk5s2ybt2iX97W9Shw7SVVfZFYuRI6WePaWnn5aeeUZau1aStP+T/freS9/TidMnCBgAPEfAgCP9L+qvYbnD/G5G63T4sLRmjVRSYn+dOCFlZUnXXiv9YKFUUCANGSK1a9fwvKyN0ke1Ev9dAAQAAQPw2yefSOvW2aFizRo7YKSnSyNGSHfeaQeKvDw7ZDQnHJYqK71pMwC0gIABeO3UKWnTproqxe7d9uP9+kmTJknXXSeNGyd17JjY84ZC0pkzkmVJaWmGGw0AiSFgAG6rqpLeessOE2vWSFu32o91726HiZ/8xL69+OLkXicUsm+rq6XMzOTbDQBJIGAAplmW9M47dV0eGzZIX34p5eTYlYlHHrEDRb9+ZisNkYBRWUnAAOA7AgZgwtGjdYMyS0qksjL7gn/NNdJ999njKIYPlzIyVF0tLV0qlZZK+fnS/PlShon/E8Nh+/bMGQNPBgDJIWAATnz+ecOBme+/b1cjhg6VbrvNDhTXXCO1b3/OqUuXSgsX2oWONWvsxx54IPbLJBRGIhUMAgaAACBgAPH46itp8+a6gZk7d9oJoU8fO0wsXSqNHy9deGGLT1Vaap8q2belpU0f21wYOSd8jAzb/0MTMAAEAAEDiKWmxg4RkYGZmzfbYxu6dLEDxQ9/aI+juOSShJ86P99+yshkj/z8c4+JhIfHHms6jJwTPr7fRw9ITFUFEAgEDECyr9LvvVfX5bF+vfTFF9IFF0hjx0r//u92oBgwIOmBmfPn27f1uz0aqx8eIhqHkXMqIXs72neoYAAIAFd3U924caNuuukmde/eXWlpaVq9enWL56xfv17Dhg1TOBxWnz59tGrVKjebiLbsr3+Vfv1r6fvft5fa7tdPmjtX+vRTe+poaan02WfSyy/bjw8caGTWR0aG3c3xxhv2bawxFfXDgyR16mQHjvphJD+/rjlpaVL+sLP7wxAwAASAqxWMU6dOafDgwbr99tv17W9/u8XjDx8+rEmTJumuu+7Ss88+q5KSEt1xxx3Kzc3VxIkT3Wwq2oLycnvKaGQcxTvv2I8PHixNmWJ3fVx7rV218FnjbpQ5c84dCHpOJeTmz6UnRBcJgEBwNWDccMMNuuGGG+I+fsWKFerdu7cefvhhSVL//v1VWlqqZcuWETCQuMpKe1GryDiKt96SampUfcnlWnrhwyodOFL5N3TQ/H+7wMw0UYPi6UaJVEKi3mcWCYDgCNTH6tatW1VQUNDgsYkTJ2ru3LlNnlNZWanKen+xVVRUuNU8BF1trb3sdiRQbNpkz/648EJ7/MT06VJBgZb+5rK6wZF7JZ3f9DRRv5wTHuLBNFUAARKogFFWVqauXbs2eKxr166qqKjQV199pfPOO++cc4qKirRo0SKvmoggsSzpgw/qujzWrrXHT7Rvb3d1LF5sB4vBg+3Nw85KZJpoSokstEUXCYAACFTAcGLevHkqLCyM3q+oqFDPnj19bBFc9fHHdpCIzPY4csTetnzkSOlHP7IDxdVX111sY4hnmmhKooIBIEACFTC6deum48ePN3js+PHjys7Ojlm9kKRwOKxwMxcTpLiTJ6WNG+uqFH/6k/34lVdKN99sD8wcO1bKzo77KeMZ35CSCBgAAiRQASMvL0+vvvpqg8eKi4uVl5fnU4vguaoqadu2unEUb75przrVo4cdJu65x65S5OY6fglH4xtSQf3NzgDAZ64GjJMnT+rgwYPR+4cPH9bu3bvVqVMn9erVS/PmzdNHH32kZ555RpJ011136fHHH9e9996r22+/XWvXrtVvf/tbvfLKK242E36yLGnvXlW/XqKlKzur9INc5dds0Pyc/6uM68baS1kWFEhXXGF259EUkPCmaJEdVKlgAAgAVwPGjh07NH78+Oj9yFiJadOmadWqVTp27JiOHj0a/X7v3r31yiuv6Cc/+Ykee+wx9ejRQ08++SRTVFubI0fqujxKSqSPP9bSdou0sObHspSuNWnflOYu1AMLXV0HzlfxhIdENkWTZAewUIiAASAQXA0Y48aNk1V/OcJGYq3SOW7cOO3atcvFVsFzn37acOfRQ4fsWR3Dh0szZkjXXafSpeNkrbUDhWWlqXSLuWqFa9ujJ6HZ8LBtm/TeezrxytdlWaMkJTDbhYABICACNQYDrcTp0/bVMFKl2LXLvkL27StNnGh3eYwbJ33ta9FT8jdLa9a5M7Mj4UqAB5qcKnvffdLPfy5J+g9JF+te3a8H439PwmHGYAAIBAIGklddLe3YUTcwc8sW+6/obt3sMPHjH9sDM3v0aPIp3JzZEcR1L2JOld22LRouIu7Tz/XRyG+r86RR8b0nVDAABAQBA84cPiz9brMdKtatkyoqpA4dpPHjpV/8wg4W/fvHPTDTzZkdQVz3Imag+u/3Yh77H7Pfk24dFd8TEzAABAQBA4nZvt2+/c53pBOZ0ujR9tTRggJpxAj/BzfEEMR1L2IGqq9/PfbBTT0eC10kAAIieFcDBNvnn9u3Dz8s/f0PpPPP97c9cTBRHfFkoOioUdK99zbsJrnvPvvxeFHBABAQBAwkJrLWwtChKREuTPFsoOiDD0rf/rb03nt25SKRcCERMAAEBgEDick8+ytTVeVvOzyWzEDRhKsfo0YlHiwiQiG6SAAEAgEDick8uxx1GwsYyQwU9XSabDhMBQNAIBAwkJhIF0mcASOIi1w5kcxAUU+nydJFAiAgUvCjHr5KMGAsXSotWGD/u7hYWr9eeuMN/0KG08CTzEBRT6fJ0kUCICAIGEhMggGj8V/r69bZF3i/VtL0Y1VPT6fJhsPSV1+5+AIAEB8CBhKTYMDIz7crF/Ul2kVgspvFj1U9Pd0ePhSSyss9ejEAaFrr3a4S7kgwYMyfby/uGdFSF0F1tbR4sTRhgn0bCRcLF9pBZeFC+75T+fl1i4sGZVVPoxiDASAgqGAgMQkGDEm69lp7h3ZJuvXW5rsIYnVhmKw6BHFVT6NYyRNAQBAwkJhQ4oM8lyypG+CYnt5890asMGFykKSn3RV+oIIBICAIGEhMxtmAEedFLNHqQ6ww0eqrDiYRMAAEBAEDiYl0kVRXx3V4otWHWGGi1VcdTGKaKoCAIGAgMaHEVvJMtPpAmEgSK3kCCAgCBhITGUAR50XMdGBoLSuDuoYuEgABwUczEhOZ4+nTXiRuLZTVaoILXSQAAiIVP0IRBNX+BAy3FsryY4VPV9BFAiAgWGgLzlTFN8jTNLcWyvJjhU9X0EUCICCoYMAZny5ibk1Z9XRDMjeFQnZ/T22t3y0B0MYRMOCMT2Mw3Jpl0hrW2qiulpa+Olylel35C2t0/Uy/WwSgLSNgwBmfAoZbWsP02KVLpYX/b5AspWnNv1r661fdpAv8bhWAtooxGHCmlQUMt8TavM0tpaWSJXuAimWlafd20gUA/xAw4IzHAcPLC7VJJneCbYk9ANYeqZqWZmnIyJPuvRgAtIAuEjjjccBI1Wmkbs1OibVux/z5kj44rNKnDyp/zlW6/sdleuIpM68HAIkiYMCZqsRmkSS7kFWqTiN1Y3ZKdbVdyVm3zr5fXCw9/bQ0bZo0//t/VcbTE6W73tXb/N8NwEd8BMGZBNfBSLYCkarTSN2YnbJ0aV24iPjgA/v91R2X6gGJ1TwB+I6AAWcS7CJJtgKRqtNIm5qdkkxFp6n3zrKk0j059p0zZ8QQKwB+ImDAmQQX2kq2AtEappHWl0xFJz/f7hZpLC1Nyh/xN+lNnf3vk2WotQCQOAIGnEmwgpGqFYj6TG6IlkxFp/57mZdnB4stW862aUqF9LjOdpEQMAD4h4ABZxKcJ5qRYV8YIxfopUtTb8dSkzNZkqnoNFvN+UvYvmU/EgA+S6GPdwSKg2mqqTrVNMLkTBbXKjqhkH1LwADgMwIGnHFwAUvVqaYRJmeyuDamJBIwmEUCwGcEDDjjoIKRqlNNIxpXHe69115V1MSYjMYcj/cI00UCIBgIGHCmOvGAkSoDPZu6uDeuOixe7F6Xj+PuJLpIAAQEAQPOnEk8YKTKVNN4L+5udvk4fu527aT0dAIGAN+xEg+cacW7qcZ7cbc3F7P/bbrLx8lzRzeEs17X4tWDUmZDOACtExUMONOKA0a8Y0Xc7PJx8tx1lZcCrfmjpb/+xzGJHdsB+ISAAWdaccCI9+LuZpePk+duUHlRmnZvv0D6pvm2AUA8CBhwphUHjFQZK9JYg8qLLA0ZeVLb/G4UgDaLgAFnamqk2lp7QGELTC6xjaZFKy//vkn5Iyp1/Y876Ymn/G0TgLaLj3k4V1VVt+7CWZEwsWmTnUHS0+0csn596q7gmSi/AlW08vLfd0ojJ+ntjH92/0UBoAkEDDhXWXlOwKg/xTOWVFzBM1G+L4keCrGSJwDfMU0VzsVYa6H+QMNYUnEFz0Q1N801OpV0gn3rylTScJh1MAD4jgoGnItxEas/0LC+8ePtEn6QV/A0pblprp5UN0IhAgYA3xEw4FyMMnwkPNQfgzFmTNsa2NncNFdPNnyjiwRAALSRj3y4IsZfyak6xdOk5t4DTzZ8o4sEQAAQMOBcQC9iQZ4W68mGb3SRAAiAgHzsIiUFtAzv+yyOZnhS4QmFpC+/dPlFAKB5zCKBcwH9K3nTpobjHDZt8rc9jbk+k4QxGAACgAoGnIsjYPjRXVFT0/x9v7leYWEMBoAAIGDAuTj+Svaju6Lx6uVxrGbuKddnkjAGA0AABOyjFykljouYJ9MyGxkzxp6hIdm3Y8Ykdr7bXRj5+Q3bV11t+LXoIgEQAFQw4FwTAaN+t0h1tX0RdXVaZiPJztRwu+pSv33V1dK6dfZ9Y69FFwmAACBgwLkmLmKN9yPxehXPZGdquF11qd++CRPqHjf2WnSRAAgAukjgXBNl+Mb7kWRkSG+8YV9UvV6Pwkl3R+MuDDerLq68Fl0kAAKACgacSUtr8q9kT1arjJOT7g5PFsMy9FoxZ+nQRQIgAAgYcCYzs8mLmJcX6JbE6u5oaeqsl8udJ/taMQPUBXSRAPAfAQPOZGY2WYYP0n4ksaopQV7pM1Exx4v8PV0kAPxHwIAzzVQwgiRWNeXGG72fOuuWmN1RkUGe9QfCAIDHCBhwppmAEaTNxmJVU4I0RiRZMbujng3bP1zQljAF0KYQMOBMM10kQe+CcDJGJEihqb6Y3VGhkH1bXeV5ewAgIgAfkUhJzVQwmltHIggXaidjRIIemhqIBIwzBAwA/iFgwJlQ0wGjuS6IlLpQ1+PHkueOhcP2bRUBA4B/CBhwJsPZNNWUulDX09K4jUQrM65WciIVDAIGAB8RMOCMw2mqqTrAsqVxG4lWZlyt5BAwAAQAAQPOONzvIkiLcCWipXEbiVZmXK3k0EUCIAAIGHDG4ToYQVqEy6REKzOuVnKoYAAIAAIGnMnIkL5itciIRCszrlZyorNIgr8QGoDWi4ABZ0IhqZwLWESilRlXKzmRLhLWwQDgIwIGnMnMlM5QwQiKBrNSBlyk+WonVcWxNz0AuISAAWcyM6XKCr9bgbMazkrpKGm+/o4uEgA+Sve7AUhRKbLZWVvRcFZKmkqVzyBPAL4iYMAZAkag5Ofbs1EkKS3NUr5KCRgAfEUXCZxpZqEteK/BrJSrazR/yVL9qXqhr20C0LYRMOAMFQxfNLXEeINZKbXp0pIa/vsA8BUBA840s9kZ3BPXEuPp6XYApIsEgI8YgwFnmtnszLTqamnxYmnCBPu2ug3Pvox7ifFQiIABwFeeBIzly5fr0ksvVVZWlkaNGqXt27c3eeyqVauUlpbW4CsrK8uLZiIRHo7BiPzVXlxs3y5d6snLxs3LANRwMGczS4wTMAD4zPUukhdeeEGFhYVasWKFRo0apUcffVQTJ07UgQMH1KVLl5jnZGdn68CBA9H7aZFPVATH2c3OXN12/Kygb/Hu6s6ojcS9xHg4TMAA4CvXA8YjjzyimTNnavr06ZKkFStW6JVXXtFTTz2l+++/P+Y5aWlp6tatm9tNQzLODvL04uIa9C3eTQWgeMJa3EuMRyoY7Zy1BQCS5WrAOHPmjHbu3Kl58+ZFH0tPT1dBQYG2bt3a5HknT57UJZdcotraWg0bNkxLly7VlVdeGfPYyspKVdYr1VdUsLqkJzIypNpalW6qlWXZPW1uVReCvsW7qQBkNKydrTDpPIfnA0CSXA0YJ06cUE1Njbp27drg8a5du+rdd9+NeU7fvn311FNPadCgQSovL9dDDz2k0aNHa9++ferRo8c5xxcVFWnRokWutB/NOLtjZ/7V1VpTEnK1uhD0Ld5NBaBkKiHnVD8yz2vbo2EB+C5w01Tz8vKUl5cXvT969Gj1799fTzzxhJYsWXLO8fPmzVNhYWH0fkVFhXr27OlJW9u0zExJ0vw5p6XMUGCrC14wFYCSqYScU/3o+kP9XdW65BsFAA65GjA6d+6sdu3a6fjx4w0eP378eNxjLDIzMzV06FAdPHgw5vfD4bDCke2p4Z2zASOjpjKhi6sXg0JTVTKVkHOqH6eH6e/OvG6+kQAQJ1enqYZCIQ0fPlwlJSXRx2pra1VSUtKgStGcmpoa7dmzR7m5uW41E06cDRiJroUR9CmnfopUQt54w75NJHidM321415mkQDwlet/OxYWFmratGkaMWKERo4cqUcffVSnTp2Kziq57bbbdPHFF6uoqEiStHjxYl199dXq06ePvvjiC/3iF7/QkSNHdMcdd7jdVCTCYcBwOs6Aykfzzql+bPit/lRt+dsoAG2a6x/RU6ZM0SeffKIHHnhAZWVlGjJkiF577bXowM+jR48qPb2ukPL5559r5syZKisr09e+9jUNHz5cW7Zs0Te+8Q23m4pEOAwYTscZeLnWRCo6ZxzIpAyp6ivf2gMAnvwNOHv2bM2ePTvm99avX9/g/rJly7Rs2TIPWoWkRAJGgqt5Oh1nEPTFtgInFJLOlPvdCgBtGHuRwBmHFQynGo8xGD2a/UmaxUqeAHxGLzacSXKQZ6JdHY0rHzU1dJk0KxSSviRgAPAPAQPOOOwicdrV0XiMwYQJdJk0i83OAPiMLhI4c3YlTyeDPOPaDdSj52m16CIB4DMqGHAm8+yvToIBw9Sy2kHfn8R3VDAA+IyAAWcynHWRmFpWO+j7k/guFJKqvBmACwCxEDDgjMMuEj95vVhX5PU2bpRqa6V27aRrr/VokbBQSKpiag0A/xAw4EyGsy4SP3m9WFf914uIrJrvevWFMRgAfMYgTziTnm6HjAS7SPzk9WJd9V8vwrMZL6FQSoU/AK0PAQPOhcMpdRHzeuZJ/deL8GzGC4M8AfiMLhI4l2J/JXs98yTy/LHGYLguHGZ5UwC+ImDAuRQLGF7PPPF1pksoRMAA4Cu6SOBcKJRSYzDalMgsHwDwCQEDzqXYGIw2JRz2uwUA2jgCBpxLsS6SNoUKBgCfETDgXEC6SKqr2br9HAQMAD5jkCecC0gXidcLaKUEAgYAn1HBgHMudJE4qUZ4vYBWSmAMBgCfETDgnAtdJJFqRHGxtGCB1Ldvy0GDrdtjoIIBwGd0kcA5F7pIGi+v/cEHduCQmu72YOv2GAgYAHxGwIBzTXSRJLNraX6+PY6ifshoqduDrdtjoIsEgM8IGHAuFJJOnTrn4fqDLouLpfXr7RAQT9iIVB+eftquXkh0ezhCBQOAzwgYcK6JMRiNuznWrbNv45nhEalGzJ9/bhUECSBgAPAZAQPONTEGI1Y3h5TYDI8gdHsk09XjO7pIAPgsVT4uEURNjMGoP+iyutruIrGs1OvqSLX1NRoEouHZut5qJ6nG72YBaKMIGHCuiS6S+tWHWFWAVJEq62tE3uP641bWrMnSX8+fL2mJr20D0HYRMOBcHNNUg9DV4VTjrp5Dh+w1OYLWVVK/0hJhWWnafSaFykUAWh0W2oJzrXyzs/nz7Qv3ZZfZ9yNrcixd6s3rx7uqaeNBtZKUlmZpSCigJRcAbQIBA84FZLOzWExsgBapvlx+ed1jXnaV1F/VtLlgU38lU8kORAsXpun2r/3Ci2YCQEwBKvQi5QRks7NYTA7QrN9V4uVA1XjHgMRayTQjQ3r7Gf5+AOAfAgacC2AXSWTA42OPmRug6ddS5PEGmybHuYRCkk672UQAaBIBA84lEDBMrCkRz3PEGvCYbNUh3oGqptfNSDrYBGkkKoA2h08gOBfpIon8id0ME10W8TxH4wGPnTpJc+bUXZzdXDzL9LoZSc/AycxM4mQASA6dtHAushx1VVWLh5pYUyKe52i8dfucOfZFOhIi4h04KSU+UNTUuhkmBqhKYrlwAL6iggHnIhewM2davJiZGCgZz3O01K2QSAhItCJhajCosUoIFQwAPiJgwLlIqKislC64oNlDTQyUjOc5WupWaC4ENO4+2bgxsYqEqcGgjUPQpk12JSPhbh0CBgAfETDgXGRDrTgGeppY0dPEczQXAhpXDsaNs0NIvBUJU6uWNg5BNTUOKxoEDAA+ImDAufpdJCmiuRDQuHLQrp19Yfd6emrjEJRoJSWKgAHARwQMOFe/i6QVaFw5uPZaf/ZRaRyCFi+W1q51MLaDgAHARwQMOJdAF0kq8GtBrZY4bhcBA4CPCBhwLgW7SJoT1J1fHbeLgAHAR6yDAedaWRdJq0PAAOAjAgaca2VdJK0OAQOAjwgYcM7jLhJjK1y2FazkCcBHjMGAcx4HDNN7fbR6bHYGwEdUMOBcpIvEozEYpvb6aDPoIgHgIwIGnDNYwYin+6PxRmbJbMHeJtBFAsBH1FDhnMGAEU/3R1DXqfBSQtvNU8EA4CMCBpyLXNkMdJHE0/0R1HUqvJTQOJTMDImBsAB8QhcJnEtLs8dhGKhg0P0Rn4TGoWTSRQLAP1QwkJxQKKGA0VSJn+6P+DS33fw5MjOlrzxrGgA0QMBAckKhhLpImirx0/0Rn3iCWCTEvfrcTCk3S9W3e9tGAJAIGEhWgl0kTDVNTjxBrC7EXSEdWKinHjumkQ950jwAiGIMBpKTYBcJYy3cVz/ESenave18P5sDoI2igoHkJBgwGGvhvvrjNKRaDRn6haSOvrYJQNtDwEBywuGExmA0V+JPaI0HNCkS2l793RFtu/C/dPuMsZIu9bNJANogPr6RnAQrGM1hrxEzIiHu7wb8QcP3LFGGled3kwC0QYzBQHIMBgwGgBqWcXYlT482owOA+ggYSE6CXSTNYQCoATU10vbtUlGRtHy5/Rj72gPwAV0kSI7BCgYDQOMXHa+yyVJ+vxOaf8WLylhXLK1fL33xhXTBBdKNQ+2Du3Txs6kA2igCBpJjMGB4udhWSg8o/etftfT/fKyF/zNYltK0Zs2FUvoneiD/M+knP5EKCqSrrpJO7JFWDpfOZ5oqAO+lykcqgioUkk6f9rsVCUupAaXl5dKGDXZD16yR9u9XqV6XJbs/yVK6Ssf+i7R2gc8NBYA6jMFAcgxtduY1LwaUVldLixdLEybYt3EPhaistLs6fvpTKS9PuvBC6eabpT/8QbrmGun555V/7+iG41XG8bcCgGDhUwnJMdhF4qWENg1zKO4qSW2ttHu3VFJiH7hpk/TVV1LnztI3vyndfrt03XXSZZdFT5n/j5LOZ7wKgOAiYCA5CW52FhReDChtskpiWdKhQ3WBYt066dNPpfbtpTFj7HJHQYE0aJCUHrvIyOZwAIKOgIHkpGgXiRcX6IZVEkv5OXukO/7DfvDIEaldO2nkSOlHP7IrFFdfbb+fANAKEDCQnBTtInHdl19q/pBN0tXpKt2To/yTf9T83y2VruwnTZ5sB4qxY6XsbL9bCgCuIGAgOQQMW1WVtG2bXZ0oKZHefFMZ1dV6oEcP6TsFdpfHNz+UcnP9bikAeIKAgeQYXMkzpdTWSnv31o2j2LBBOnVK6tjRHpj52GN2qLjiirrlSQGgDSFgIDltqYLx5z/XBYq1a6WPP7YD1rXX2lNKCwqkoUPtsRUA0MYRMJCc1hwwTpywZ3hEQsWhQ/asjuHDpRkz7HEUo0dL553nd0sBIHAIGEhOa+oiOX3aXoMiEih277angPTtK02caFcoxo2TvvY1v1sKAIFHwEByUrmCUV0t7dhRtwT31q32z5Kba1cn5syxb3v08LulAJByCBhITigk1dSourJGSx9sF+zNwyxL2r+/bqbH+vVSRYXUoYM0frz0i1/YVYr+/RmYCQBJCtolAKkmFJIkLf3XWi38t3ayLKm4WHr6aWnatKaDhme7mf7lL3VdHiUl0rFjUmamPXbinnvsQDFiRADTEACkNj5VkZyzK0/WXxZbkj74wN6HQ4q9YqZru5l+/rldmYgEigMH7GrEkCHS975nd3nk57OFOQC4jICB5JytYOSPPKM1GzIbhIzmdil1upvpOZWPwr8pY9vmuirFzp32GhWXX26HiSVL7O6Pzp2T+CEBAIkiYCA5ZwPG/B99IZ1/vp5+2q5eSM3vUup0N9Ol/1qrhYvTZFlpWlNcKy35uR6oXiBddJEdKH7wA/v20kuT/tEAAM4RMJCcs10kGTWVeuABeyxF47EVscS9m6llSe+/H+3yKP3f2bKs8fa3lK7Sy6ZJL06WBgxocudRAID3CBhIztkKRmSqary7lDZ7XFlZw4GZH35onzBqlF352GDJstLsysctl0iDzPwoAABzCBhITqOA4UhFhb2XRyRQ7NtnPz5woPSd79hdHmPGSB06aH61pDgqJAAAfxEwkJyzXSQJreZZWSm9+WZdlWL7dqmmRurVy542+i//Ym8Y1rXrOafGWyEBAPjLk07r5cuX69JLL1VWVpZGjRql7du3N3v8iy++qH79+ikrK0sDBw7Uq6++6kUz4UQ8FYzaWnvZ7Ycekq6/XurUyV5ye/ly6eKLpccft8dZ/PnP0n/9lzR1asxwAQBIHa4HjBdeeEGFhYVasGCB3n77bQ0ePFgTJ07Uxx9/HPP4LVu2aOrUqZoxY4Z27dqlyZMna/Lkydq7d6/bTYUTTQWMDz6QVq6Upkyxw8LQodLPfmaHjQUL7Omkn3wivfiidNddUp8+rJ4JAK2I6wHjkUce0cyZMzV9+nR94xvf0IoVK9S+fXs99dRTMY9/7LHHdP311+uee+5R//79tWTJEg0bNkyPP/64202FE5Eukr/8RXrhBWnmTKl3b3sdih/+UDpyxJ46unatvQjWG29I994rDRvGrA8AaMVcHYNx5swZ7dy5U/PmzYs+lp6eroKCAm3dujXmOVu3blVhYWGDxyZOnKjVq1fHPL6yslKV9fr/Kyoqkm84WrT/k/32Pyo+l3Il3Xebfb/3pdLNI6VR/8fe1rxDh7qTPn/H62a2adH/RgDgA1cDxokTJ1RTU6OujfrTu3btqnfffTfmOWVlZTGPLysri3l8UVGRFi1aZKbBaFHn9p3VPrO9vvfS9+oe/EH9I/5sf733W+k9T5uGGNpntlfn9qxiCsB7KT+LZN68eQ0qHhUVFerZs6ePLWrdeuX00v5Z+3Xi9Am/m4I4dG7fWb1yevndDABtkKsBo3PnzmrXrp2OHz/e4PHjx4+rW7duMc/p1q1bQseHw2GFI+MA4IleOb24aAEAmuXqKLtQKKThw4erpKQk+lhtba1KSkqUl5cX85y8vLwGx0tScXFxk8cDAIDgcb2LpLCwUNOmTdOIESM0cuRIPfroozp16pSmT58uSbrtttt08cUXq6ioSJI0Z84cjR07Vg8//LAmTZqk559/Xjt27NDKlSvdbioAADDE9YAxZcoUffLJJ3rggQdUVlamIUOG6LXXXosO5Dx69KjS601XHD16tJ577jn99Kc/1fz583XFFVdo9erVGjBggNtNBQAAhqRZlmX53QiTKioqlJOTo/LycmVnZ/vdHAAAAs2t6yYrHQEAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjCBgAAMA4AgYAADCOgAEAAIwjYAAAAOMIGAAAwDgCBgAAMI6AAQAAjCNgAAAA4wgYAADAOAIGAAAwjoABAACMI2AAAADjXAsYn332mW655RZlZ2erY8eOmjFjhk6ePNnsOePGjVNaWlqDr7vuusutJgIAAJdkuPXEt9xyi44dO6bi4mJVVVVp+vTpuvPOO/Xcc881e97MmTO1ePHi6P327du71UQAAOASVwLG/v379dprr+mtt97SiBEjJEm//OUvdeONN+qhhx5S9+7dmzy3ffv26tatmxvNAgAAHnElYGzdulUdO3aMhgtJKigoUHp6urZt26Z/+Id/aPLcZ599Vr/5zW/UrVs33XTTTfrZz37WbBWjsrJSlZWV0fvl5eWSpIqKCgM/CQAArVvkemlZltHndSVglJWVqUuXLg1fKCNDnTp1UllZWZPn/fM//7MuueQSde/eXX/6059033336cCBA/qf//mfJs8pKirSokWLznm8Z8+ezn8AAADamE8//VQ5OTnGni+hgHH//ffrwQcfbPaY/fv3O27MnXfeGf33wIEDlZubq+uuu06HDh3S5ZdfHvOcefPmqbCwMHr/iy++0CWXXKKjR48afaPQtIqKCvXs2VMffvihsrOz/W5Oq8f77S3eb+/xnnurvLxcvXr1UqdOnYw+b0IB4+6779b3v//9Zo+57LLL1K1bN3388ccNHq+urtZnn32W0PiKUaNGSZIOHjzYZMAIh8MKh8PnPJ6Tk8Mvpseys7N5zz3E++0t3m/v8Z57Kz3d7MTShALGRRddpIsuuqjF4/Ly8vTFF19o586dGj58uCRp7dq1qq2tjYaGeOzevVuSlJubm0gzAQCAz1xZB6N///66/vrrNXPmTG3fvl2bN2/W7Nmz9d3vfjc6g+Sjjz5Sv379tH37dknSoUOHtGTJEu3cuVN//vOf9b//+7+67bbbNGbMGA0aNMiNZgIAAJe4ttDWs88+q379+um6667TjTfeqPz8fK1cuTL6/aqqKh04cECnT5+WJIVCIa1Zs0YTJkxQv379dPfdd+sf//Ef9Yc//CGh1w2Hw1qwYEHMbhO4g/fcW7zf3uL99h7vubfcer/TLNPzUgAAQJvHXiQAAMA4AgYAADCOgAEAAIwjYAAAAONaRcBga3j3LV++XJdeeqmysrI0atSo6PTiprz44ovq16+fsrKyNHDgQL366qsetbR1SOT9XrVq1Tm/y1lZWR62NrVt3LhRN910k7p37660tDStXr26xXPWr1+vYcOGKRwOq0+fPlq1apXr7WwtEn2/169ff87vd1paWrPbTqBOUVGRrrrqKnXo0EFdunTR5MmTdeDAgRbPM/EZ3ioCxi233KJ9+/apuLhYL7/8sjZu3Nhg2fGmzJw5U8eOHYt+/fznP/egtannhRdeUGFhoRYsWKC3335bgwcP1sSJE89ZrTViy5Ytmjp1qmbMmKFdu3Zp8uTJmjx5svbu3etxy1NTou+3ZK94WP93+ciRIx62OLWdOnVKgwcP1vLly+M6/vDhw5o0aZLGjx+v3bt3a+7cubrjjjv0+uuvu9zS1iHR9zviwIEDDX7HG+93hdg2bNigWbNm6c0331RxcbGqqqo0YcIEnTp1qslzjH2GWynunXfesSRZb731VvSxP/7xj1ZaWpr10UcfNXne2LFjrTlz5njQwtQ3cuRIa9asWdH7NTU1Vvfu3a2ioqKYx//TP/2TNWnSpAaPjRo1yvrBD37gajtbi0Tf71/96ldWTk6OR61r3SRZL730UrPH3HvvvdaVV17Z4LEpU6ZYEydOdLFlrVM87/e6dessSdbnn3/uSZtau48//tiSZG3YsKHJY0x9hqd8BaOlreGb8+yzz6pz584aMGCA5s2bF130C3XOnDmjnTt3qqCgIPpYenq6CgoKtHXr1pjnbN26tcHxkjRx4sQmj0cdJ++3JJ08eVKXXHKJevbsqZtvvln79u3zorltEr/f/hgyZIhyc3P1rW99S5s3b/a7OSmrvLxckprd2MzU77gr27V7ycut4duiEydOqKamRl27dm3weNeuXfXuu+/GPKesrCzm8fSZtszJ+923b1899dRTGjRokMrLy/XQQw9p9OjR2rdvn3r06OFFs9uUpn6/Kyoq9NVXX+m8887zqWWtU25urlasWKERI0aosrJSTz75pMaNG6dt27Zp2LBhfjcvpdTW1mru3Lm65pprNGDAgCaPM/UZHtiAEcSt4YEgysvLU15eXvT+6NGj1b9/fz3xxBNasmSJjy0Dkte3b1/17ds3en/06NE6dOiQli1bpl//+tc+tiz1zJo1S3v37lVpaaknrxfYgBHEreHbos6dO6tdu3Y6fvx4g8ePHz/e5PvbrVu3hI5HHSfvd2OZmZkaOnSoDh486EYT27ymfr+zs7OpXnhk5MiRnl0kW4vZs2dHJ0G0VNk09Rke2DEYF110kfr169fsVygUarA1fARbw5sTCoU0fPhwlZSURB+rra1VSUlJg7+a68vLy2twvCQVFxc3eTzqOHm/G6upqdGePXv4XXYJv9/+2717N7/fcbIsS7Nnz9ZLL72ktWvXqnfv3i2eY+x33Mko1KC5/vrrraFDh1rbtm2zSktLrSuuuMKaOnVq9Pt/+ctfrL59+1rbtm2zLMuyDh48aC1evNjasWOHdfjwYev3v/+9ddlll1ljxozx60cItOeff94Kh8PWqlWrrHfeece68847rY4dO1plZWWWZVnWrbfeat1///3R4zdv3mxlZGRYDz30kLV//35rwYIFVmZmprVnzx6/foSUkuj7vWjRIuv111+3Dh06ZO3cudP67ne/a2VlZVn79u3z60dIKV9++aW1a9cua9euXZYk65FHHrF27dplHTlyxLIsy7r//vutW2+9NXr8Bx98YLVv39665557rP3791vLly+32rVrZ7322mt+/QgpJdH3e9myZdbq1aut999/39qzZ481Z84cKz093VqzZo1fP0JK+eEPf2jl5ORY69evt44dOxb9On36dPQYtz7DW0XA+PTTT62pU6daF1xwgZWdnW1Nnz7d+vLLL6PfP3z4sCXJWrdunWVZlnX06FFrzJgxVqdOnaxwOGz16dPHuueee6zy8nKffoLg++Uvf2n16tXLCoVC1siRI60333wz+r2xY8da06ZNa3D8b3/7W+vrX/+6FQqFrCuvvNJ65ZVXPG5xakvk/Z47d2702K5du1o33nij9fbbb/vQ6tQUmQbZ+CvyHk+bNs0aO3bsOecMGTLECoVC1mWXXWb96le/8rzdqSrR9/vBBx+0Lr/8cisrK8vq1KmTNW7cOGvt2rX+ND4FxXqvJTX4nXXrM5zt2gEAgHGBHYMBAABSFwEDAAAYR8AAAADGETAAAIBxBAwAAGAcAQMAABhHwAAAAMYRMAAAgHEEDAAAYBwBAwAAGEfAAAAAxhEwAACAcf8fai2Pv9Mjr3EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "point = env.state\n",
    "box = env.transformed_corners\n",
    "\n",
    "print(\"Point:\", point)\n",
    "print(\"Box:\", box)\n",
    "\n",
    "print(is_point_in_parallelogram(point, box))\n",
    "\n",
    "# sample 100 points in the parallelogram and plot them along with the parallelogram\n",
    "points = [sample_in_parallelogram(box) for _ in range(100)]\n",
    "points = np.array(points)\n",
    "# box = [(0, 0), (2, 1), (3, 2), (1, 1)]\n",
    "rectangle = bounding_rectangle(box)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.gca().add_patch(patches.Polygon(box, fill=None, edgecolor='r'))\n",
    "plt.gca().add_patch(patches.Polygon(rectangle, fill=None, edgecolor='g'))\n",
    "plt.scatter(points[:, 0], points[:, 1], c='b', s=5)\n",
    "plt.scatter(point[0], point[1], c='r', s=10)\n",
    "plt.xlim(-.5, 2)\n",
    "plt.ylim(-.5, 2)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableDeformedGridworld(gym.Env):\n",
    "\n",
    "    def __init__(self, grid_size=(1.0, 1.0), step_size=0.02, goal=(0.9, 0.9), \n",
    "                 obstacles=None, stretch=(1.0, 1.0), shear=(0.0, 0.0), observation_radius=0.05, render_mode=None,shear_range=(-0.2,0.2),stretch_range=(0.4,1),max_timesteps=500):\n",
    "        \"\"\"\n",
    "        Initialize the observable deformed continuous gridworld.\n",
    "        :param grid_size: Size of the grid (width, height).\n",
    "        :param step_size: Step size for the agent's movement.\n",
    "        :param goal: Coordinates of the goal position.\n",
    "        :param obstacles: List of obstacles as rectangles [(x_min, y_min), (x_max, y_max)].\n",
    "        :param stretch: Tuple (s_x, s_y) for stretching the grid in x and y directions.\n",
    "        :param shear: Tuple (sh_x, sh_y) for shearing the grid.\n",
    "        :param observation_radius: Radius within which the agent can observe its surroundings.\n",
    "        \"\"\"\n",
    "        self.grid_size = np.array(grid_size)\n",
    "        self.step_size = step_size\n",
    "        self.goal = np.array(goal)\n",
    "        self.state = np.array([0.1, 0.1])  # Start at the origin\n",
    "        self.obstacles = obstacles if obstacles else []\n",
    "        self.observation_radius = observation_radius\n",
    "\n",
    "        # Transformation matrix\n",
    "        self.transformation_matrix = np.array([\n",
    "            [stretch[0], shear[0]],\n",
    "            [shear[1], stretch[1]]\n",
    "        ])\n",
    "        self.inverse_transformation_matrix = np.linalg.inv(self.transformation_matrix)\n",
    "\n",
    "        # Rendering mode\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # gymnasium compatibility\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space =  Dict({\n",
    "            \"pos\": gym.spaces.Box(low=.0, high=1.0, shape=(2,),dtype=float),\n",
    "            \"theta\": gym.spaces.Box(low=.0, high=1.0, shape=(4,),dtype=float), # deformation is a 2x2 tensor\n",
    "        })\n",
    "\n",
    "        self.stretch_range = stretch_range\n",
    "        self.shear_range = shear_range\n",
    "        self.max_timesteps = max_timesteps\n",
    "\n",
    "        self.timestep = 0\n",
    "\n",
    "        self.corners = [\n",
    "            np.array([0, 0]),\n",
    "            np.array([self.grid_size[0], 0]),\n",
    "            self.grid_size,\n",
    "            np.array([0, self.grid_size[1]]),\n",
    "        ]\n",
    "        self.transformed_corners = [self.transform(corner) for corner in self.corners]\n",
    "        \n",
    "    def reset(self,seed=None):\n",
    "        \"\"\"\n",
    "        Reset the environment to the initial state.\n",
    "        :return: Initial state and observation.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.set_deformation(self.sample(2,self.stretch_range), self.sample(2,self.shear_range))  # Reset deformation to random\n",
    "        self.transformed_corners = [self.transform(corner) for corner in self.corners]\n",
    "        # self.state = np.array([0.1, 0.1])  # Start at the origin\n",
    "        #self.state = np.random.rand(2) * self.transform(self.grid_size) # Random start position in the deformable grid\n",
    "        self.state = sample_in_parallelogram(self.transformed_corners)\n",
    "\n",
    "\n",
    "        state = OrderedDict({\n",
    "            \"pos\": self.state,\n",
    "            \"theta\": self.transformation_matrix.flatten(),\n",
    "        }) \n",
    "        \n",
    "        self.timestep = 0\n",
    "\n",
    "        # print(f\"Initial agent position: {self.state}\",\n",
    "        #       f\"Initial goal position: {self.goal}\",\n",
    "        #       f\"Initial deformation: {self.transformation_matrix}\",\n",
    "        #       f\"Initial observation: {self.observe_obstacle()}\",\n",
    "        #       sep=\"\\n\")\n",
    "        \n",
    "        return state, {}\n",
    "    \n",
    "    def set_deformation(self, stretch, shear):\n",
    "        \"\"\"\n",
    "        Set the deformation transformation matrix based on stretch and shear parameters.\n",
    "        \n",
    "        This function creates a transformation matrix to apply grid deformations, including \n",
    "        stretching and shearing, to the grid coordinates. It also computes the inverse of \n",
    "        this transformation for reversing the deformation.\n",
    "\n",
    "        :param stretch: A tuple (s_x, s_y) for stretching the grid in the x and y directions.\n",
    "        :param shear: A tuple (sh_x, sh_y) for shearing the grid in the x and y directions.\n",
    "        \"\"\"\n",
    "        # Create the transformation matrix based on stretch and shear\n",
    "        self.transformation_matrix = np.array([\n",
    "            [stretch[0], shear[0]],  # First row: stretch in x and shear in x direction\n",
    "            [shear[1], stretch[1]]   # Second row: shear in y and stretch in y direction\n",
    "        ])\n",
    "\n",
    "        # Calculate the inverse transformation matrix for reversing the deformation\n",
    "        self.inverse_transformation_matrix = np.linalg.inv(self.transformation_matrix)\n",
    "\n",
    "        # Optionally, print the transformation matrices for debugging\n",
    "        # print(f\"Transformation Matrix:\\n{self.transformation_matrix}\")\n",
    "        # print(f\"Inverse Transformation Matrix:\\n{self.inverse_transformation_matrix}\")\n",
    "\n",
    "    def set_pos(self, pos):\n",
    "        \"\"\"\n",
    "        Set the agent's state to a new position.\n",
    "        \n",
    "        This function directly updates the agent's position (state) to the provided coordinates.\n",
    "\n",
    "        :param pos: A tuple or array representing the new position of the agent in the grid.\n",
    "        \"\"\"\n",
    "        # Update the state (agent's position)\n",
    "        self.state = np.array(pos)\n",
    "\n",
    "        # Optionally, print the new state for debugging\n",
    "        # print(f\"New agent position: {self.state}\")\n",
    "\n",
    "    def transform(self, position):\n",
    "        \"\"\"\n",
    "        Apply the grid deformation to a given position.\n",
    "        :param position: (x, y) in original space.\n",
    "        :return: Transformed position in the deformed grid.\n",
    "        \"\"\"\n",
    "        return np.dot(self.transformation_matrix, position)\n",
    "\n",
    "    def inverse_transform(self, position):\n",
    "        \"\"\"\n",
    "        Map a position from the deformed grid back to the original space.\n",
    "        :param position: (x, y) in the deformed grid.\n",
    "        :return: Original position.\n",
    "        \"\"\"\n",
    "        return np.dot(self.inverse_transformation_matrix, position)\n",
    "    \n",
    "    def is_in_obstacle(self, position):\n",
    "        \"\"\"\n",
    "        Check if a given position is inside any obstacle.\n",
    "        :param position: The (x, y) coordinates to check in the original space.\n",
    "        :return: True if the position is inside an obstacle, False otherwise.\n",
    "        \"\"\"\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            bottom_left = self.transform(np.array([x_min, y_min]))\n",
    "            bottom_right = self.transform(np.array([x_max, y_min]))\n",
    "            top_left = self.transform(np.array([x_min, y_max]))\n",
    "            top_right = self.transform(np.array([x_max, y_max]))\n",
    "            obstacle = [bottom_left, bottom_right, top_right, top_left]\n",
    "            if is_point_in_parallelogram(position, obstacle):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def observe_obstacle_rectangle(self):\n",
    "        \"\"\"\n",
    "        Efficiently and precisely check for obstacles in the four cardinal directions (N, E, S, W).\n",
    "        Each direction checks for obstacles in a quarter-circle arc within the observation radius.\n",
    "        :return: A numpy array of shape (4,), where each entry indicates the presence of obstacles \n",
    "                in the respective direction (North, East, South, West).\n",
    "        \"\"\"\n",
    "        directions = [\"N\", \"E\", \"S\", \"W\"]\n",
    "        obstacle_presence = np.zeros(4)  # Default: no obstacles in any direction\n",
    "\n",
    "        # Precompute direction boundaries in radians\n",
    "        direction_ranges = [\n",
    "            (315, 45),   # North: [-45°, +45°]\n",
    "            (45, 135),   # East: [+45°, +135°]\n",
    "            (135, 225),  # South: [+135°, +225°]\n",
    "            (225, 315)   # West: [+225°, +315°]\n",
    "        ]\n",
    "        direction_ranges_rad = [(np.deg2rad(a1), np.deg2rad(a2)) for a1, a2 in direction_ranges]\n",
    "\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            x_min, y_min = self.transform([x_min, y_min])\n",
    "            x_max, y_max = self.transform([x_max, y_max])\n",
    "\n",
    "            # Generate sampled points along the edges of the obstacle\n",
    "            num_samples = 5  # Increase for more precision\n",
    "            edge_points = np.concatenate([\n",
    "                np.linspace([x_min, y_min], [x_max, y_min], num_samples),  # Bottom edge\n",
    "                np.linspace([x_max, y_min], [x_max, y_max], num_samples),  # Right edge\n",
    "                np.linspace([x_max, y_max], [x_min, y_max], num_samples),  # Top edge\n",
    "                np.linspace([x_min, y_max], [x_min, y_min], num_samples)   # Left edge\n",
    "            ])\n",
    "\n",
    "            # Compute vectors from agent to sampled points\n",
    "            vectors = edge_points - self.state\n",
    "            distances = np.linalg.norm(vectors, axis=1)\n",
    "\n",
    "            # Filter points that are outside the observation radius\n",
    "            within_radius = distances <= self.observation_radius\n",
    "            if not np.any(within_radius):\n",
    "                continue  # Skip obstacles entirely outside the radius\n",
    "\n",
    "            # Compute angles relative to positive Y-axis\n",
    "            angles = np.arctan2(vectors[:, 1], vectors[:, 0])  # Radians\n",
    "            angles = (angles + 2 * np.pi) % (2 * np.pi)  # Normalize to [0, 2π)\n",
    "\n",
    "            # Check which direction each point falls into\n",
    "            for i, (angle_min, angle_max) in enumerate(direction_ranges_rad):\n",
    "                if obstacle_presence[i] == 1:\n",
    "                    continue  # Early exit if the direction is already flagged\n",
    "                for angle in angles[within_radius]:\n",
    "                    if (angle_min <= angle < angle_max) or (\n",
    "                        angle_max < angle_min and (angle >= angle_min or angle < angle_max)\n",
    "                    ):\n",
    "                        obstacle_presence[i] = 1\n",
    "                        break  # No need to check further points for this direction\n",
    "\n",
    "        return obstacle_presence\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take a step in the environment, interpreting the action in the deformed space.\n",
    "        :param action: One of ['N', 'S', 'E', 'W'].\n",
    "        :return: Tuple (next_state, observation, reward, done, info).\n",
    "        \"\"\"\n",
    "        # Map actions to movements in the deformed space\n",
    "        moves = [np.array([0, self.step_size]),   # Move up in deformed space\n",
    "            np.array([0, -self.step_size]),  # Move down in deformed space\n",
    "            np.array([self.step_size, 0]),   # Move right in deformed space\n",
    "            np.array([-self.step_size, 0])   # Move left in deformed space\n",
    "        ]\n",
    "\n",
    "        # Get the movement vector in the deformed space\n",
    "        move = moves[action]\n",
    "\n",
    "        # Map the movement to the original space using the inverse transformation\n",
    "        # move_original = np.dot(self.inverse_transformation_matrix, move)\n",
    "\n",
    "        # Update state in the original grid space\n",
    "        next_state = self.state + move\n",
    "\n",
    "        num_samples = 10  # Number of points to sample along the path\n",
    "        path = np.linspace(self.state, next_state, num_samples)\n",
    "\n",
    "        # Check for collisions along the path\n",
    "        collision = any(self.is_in_obstacle(point) for point in path)\n",
    "\n",
    "        # Check if the new state is in an obstacle\n",
    "        if np.linalg.norm(next_state - self.transform(self.goal)) < self.observation_radius:\n",
    "            terminated = True\n",
    "            reward = 1.0 \n",
    "            info = {\"collision\": False, \"out\": False, 'goal': True}\n",
    "        # Check if the is inside the deformed grid boundaries\n",
    "        elif not is_point_in_parallelogram(next_state, self.transformed_corners):\n",
    "            reward = -2.0\n",
    "            info = {\"out\": True}\n",
    "            next_state = self.state\n",
    "            terminated = False\n",
    "        elif collision:   \n",
    "            reward = -2.0  # Penalty for hitting an obstacle\n",
    "            info = {\"collision\": True}\n",
    "            terminated = False\n",
    "        else:\n",
    "            terminated = False\n",
    "            reward = -0.5\n",
    "            info = {\"collision\": False, \"out\": False, \"goal\": False}\n",
    "    \n",
    "        self.state = next_state\n",
    "        self.timestep += 1\n",
    "        truncated = self.timestep > self.max_timesteps \n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        state = OrderedDict({\n",
    "                    \"pos\": self.state,\n",
    "                    \"theta\": self.transformation_matrix.flatten(),\n",
    "                })\n",
    "\n",
    "        # Return the transformed state, reward, and terminated truncated flag\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    def render_old(self):\n",
    "        \"\"\"\n",
    "        Render the deformed gridworld environment using Pygame, ensuring the entire deformed grid fits within the screen.\n",
    "        \"\"\"\n",
    "        import pygame  # Ensure Pygame is imported\n",
    "\n",
    "        # Define colors\n",
    "        WHITE = (255, 255, 255)\n",
    "        BLUE = (0, 0, 255)\n",
    "        GREEN = (0, 255, 0)\n",
    "        RED = (255, 0, 0)\n",
    "        YELLOW = (255, 255, 0)\n",
    "        BLACK = (0, 0, 0)\n",
    "\n",
    "        # Initialize the screen\n",
    "        if not hasattr(self, \"screen\"):\n",
    "            self.screen_width = 800\n",
    "            self.screen_height = 600\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            pygame.display.set_caption(\"Deformed Gridworld Environment\")\n",
    "\n",
    "        # Fill background with white\n",
    "        self.screen.fill(WHITE)\n",
    "\n",
    "        # Compute the bounding box of the deformed grid\n",
    "        corners = [\n",
    "            self.transform(np.array([0, 0])),\n",
    "            self.transform(np.array([self.grid_size[0], 0])),\n",
    "            self.transform(self.grid_size),\n",
    "            self.transform(np.array([0, self.grid_size[1]])),\n",
    "        ]\n",
    "        x_coords, y_coords = zip(*corners)\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "\n",
    "        # Define scaling factors to fit the deformed grid within the screen\n",
    "        scale_x = self.screen_width / (max_x - min_x)\n",
    "        scale_y = self.screen_height / (max_y - min_y)\n",
    "        scale = min(scale_x, scale_y)  # Uniform scaling to maintain aspect ratio\n",
    "\n",
    "        # Transform helper for rendering\n",
    "        def to_screen_coords(pos):\n",
    "            \"\"\"\n",
    "            Map transformed coordinates to screen coordinates, scaled and shifted to fit the screen.\n",
    "            \"\"\"\n",
    "            x, y = pos\n",
    "            x_screen = int((x - min_x) * scale)\n",
    "            y_screen = int((max_y - y) * scale)  # Flip y-axis for screen rendering\n",
    "            return x_screen, y_screen\n",
    "\n",
    "        # Draw the deformed grid boundaries\n",
    "        pygame.draw.polygon(self.screen, BLACK, [to_screen_coords(corner) for corner in corners], width=3)\n",
    "\n",
    "        # Draw the obstacles\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            bottom_left = self.transform(np.array([x_min, y_min]))\n",
    "            bottom_right = self.transform(np.array([x_max, y_min]))\n",
    "            top_left = self.transform(np.array([x_min, y_max]))\n",
    "            top_right = self.transform(np.array([x_max, y_max]))\n",
    "            \n",
    "            # Draw each obstacle as a polygon in the deformed space\n",
    "            pygame.draw.polygon(self.screen, RED, [\n",
    "                to_screen_coords(bottom_left),\n",
    "                to_screen_coords(bottom_right),\n",
    "                to_screen_coords(top_right),\n",
    "                to_screen_coords(top_left)\n",
    "            ])\n",
    "\n",
    "        # Draw the agent\n",
    "        agent_position = self.transform(self.state)\n",
    "        pygame.draw.circle(self\n",
    "        .screen, BLUE, to_screen_coords(agent_position), 10)\n",
    "\n",
    "        # Draw the goal\n",
    "        goal_position = self.transform(self.goal)\n",
    "        pygame.draw.circle(self.screen, GREEN, to_screen_coords(goal_position), 12)\n",
    "\n",
    "        # Draw observation radius as a dashed circle around the agent\n",
    "        observation_radius = self.observation_radius * max(self.transformation_matrix.diagonal())\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(agent_position), \n",
    "                        int(observation_radius * scale), 1)\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Handle key events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                # Press 'r' to reset environment\n",
    "                if event.key == pygame.K_r:\n",
    "                    self.reset()\n",
    "                # Press 'w' to quit\n",
    "                elif event.key == pygame.K_w:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                # Press 's' to save current state\n",
    "                elif event.key == pygame.K_s:\n",
    "                    self.save_state()\n",
    "                # Press space to pause/resume\n",
    "                elif event.key == pygame.K_SPACE:\n",
    "                    self.pause()\n",
    "                # Press arrow keys for manual control\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    return self.step(3)  # Left action\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    return self.step(2)  # Right action\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    return self.step(0)  # Up action\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    return self.step(1)  # Down action\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    def close(self):\n",
    "        self.render_mode = None\n",
    "        pygame.quit()\n",
    "    \n",
    "    def sample(self,num,limit):\n",
    "        low,high = limit\n",
    "        return low + np.random.rand(num)*(high-low)\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Render the deformed gridworld environment along with the original gridworld.\n",
    "        The original gridworld serves as a reference background.\n",
    "        \"\"\"\n",
    "        import pygame  # Ensure Pygame is imported\n",
    "\n",
    "        # Define colors\n",
    "        WHITE = (255, 255, 255)\n",
    "        LIGHT_GRAY = (200, 200, 200)\n",
    "        BLUE = (0, 0, 255)\n",
    "        GREEN = (0, 255, 0)\n",
    "        RED = (255, 0, 0)\n",
    "        PINK = (255, 105, 180)  \n",
    "        YELLOW = (255, 255, 0)\n",
    "        BLACK = (0, 0, 0)\n",
    "\n",
    "        # Initialize the screen\n",
    "        if not hasattr(self, \"screen\"):\n",
    "            self.screen_width = 1000\n",
    "            self.screen_height = 1000\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            pygame.display.set_caption(\"Deformed and Original Gridworld\")\n",
    "\n",
    "        # Fill background with white\n",
    "        self.screen.fill(WHITE)\n",
    "\n",
    "    # Compute the bounding box of the deformed grid\n",
    "        corners = [\n",
    "            np.array([0, 0]),\n",
    "            np.array([self.grid_size[0], 0]),\n",
    "            self.grid_size,\n",
    "            np.array([0, self.grid_size[1]]),\n",
    "        ]\n",
    "        transformed_corners = [self.transform(corner) for corner in corners]\n",
    "        x_coords, y_coords = zip(*transformed_corners)\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "\n",
    "        # Define scaling factors to fit the deformed grid within the screen\n",
    "        scale_x = self.screen_width / (max_x - min_x)\n",
    "        scale_y = self.screen_height / (max_y - min_y)\n",
    "        scale = min(scale_x, scale_y)  # Uniform scaling to maintain aspect ratio\n",
    "\n",
    "        # Add upward translation offset\n",
    "        y_translation = max(0, -min_y * scale)\n",
    "\n",
    "        # Transform helper for rendering\n",
    "        def to_screen_coords(pos):\n",
    "            \"\"\"\n",
    "            Map transformed coordinates to screen coordinates, scaled and shifted to fit the screen.\n",
    "            \"\"\"\n",
    "            x, y = pos\n",
    "            x_screen = int((x - min_x) * scale)\n",
    "            y_screen = int((max_y - y) * scale + y_translation)  # Flip y-axis and add upward translation\n",
    "            return x_screen, y_screen\n",
    "        \n",
    "        # Draw the un-deformed grid (background)\n",
    "        for i in range(int(self.grid_size[0]) + 1):\n",
    "            pygame.draw.line(self.screen, LIGHT_GRAY,\n",
    "                            to_screen_coords((i, 0)),\n",
    "                            to_screen_coords((i, self.grid_size[1])), width=1)\n",
    "        for j in range(int(self.grid_size[1]) + 1):\n",
    "            pygame.draw.line(self.screen, LIGHT_GRAY,\n",
    "                            to_screen_coords((0, j)),\n",
    "                            to_screen_coords((self.grid_size[0], j)), width=1)\n",
    "\n",
    "        # Draw the deformed grid boundaries\n",
    "        corners = [\n",
    "            np.array([0, 0]),\n",
    "            np.array([self.grid_size[0], 0]),\n",
    "            self.grid_size,\n",
    "            np.array([0, self.grid_size[1]]),\n",
    "        ]\n",
    "        transformed_corners = [self.transform(corner) for corner in corners]\n",
    "        pygame.draw.polygon(self.screen, BLACK, [to_screen_coords(corner) for corner in transformed_corners], width=3)\n",
    "\n",
    "        # Draw the obstacles in both grids\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            # Original obstacle\n",
    "            pygame.draw.rect(self.screen, PINK,\n",
    "                            (*to_screen_coords((x_min, y_max)),  # Top-left corner\n",
    "                            int((x_max - x_min) * scale),      # Width\n",
    "                            int((y_max - y_min) * scale)),    # Height\n",
    "                            width=0)\n",
    "\n",
    "            # Transformed obstacle\n",
    "            bottom_left = self.transform(np.array([x_min, y_min]))\n",
    "            bottom_right = self.transform(np.array([x_max, y_min]))\n",
    "            top_left = self.transform(np.array([x_min, y_max]))\n",
    "            top_right = self.transform(np.array([x_max, y_max]))\n",
    "            pygame.draw.polygon(self.screen, RED, [\n",
    "                to_screen_coords(bottom_left),\n",
    "                to_screen_coords(bottom_right),\n",
    "                to_screen_coords(top_right),\n",
    "                to_screen_coords(top_left)\n",
    "            ])\n",
    "\n",
    "        # Draw the agent in both grids\n",
    "        agent_position = self.state\n",
    "        transformed_agent_position = agent_position\n",
    "        pygame.draw.circle(self.screen, BLUE, to_screen_coords(agent_position), 10)  # Original\n",
    "        pygame.draw.circle(self.screen, GREEN, to_screen_coords(transformed_agent_position), 10)  # Transformed\n",
    "\n",
    "        # Draw the goal in both grids\n",
    "        goal_position = self.goal\n",
    "        transformed_goal_position = self.transform(goal_position)\n",
    "        pygame.draw.circle(self.screen, GREEN, to_screen_coords(goal_position), 12)  # Original\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(transformed_goal_position), 12)  # Transformed\n",
    "\n",
    "        # Draw observation radius as a dashed circle around the agent\n",
    "        observation_radius = self.observation_radius # stays the same in both grids\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(agent_position), \n",
    "                        int(self.observation_radius * scale), 1)  # Original\n",
    "        pygame.draw.circle(self.screen, YELLOW, to_screen_coords(transformed_agent_position), \n",
    "                        int(observation_radius * scale), 1)  # Transformed\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Handle key events\n",
    "        # Handle key events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                # Press 'r' to reset environment\n",
    "                if event.key == pygame.K_r:\n",
    "                    self.reset()\n",
    "                # Press 'w' to quit\n",
    "                elif event.key == pygame.K_w:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "                # Press 's' to save current state\n",
    "                elif event.key == pygame.K_s:\n",
    "                    self.save_state()\n",
    "                # Press space to pause/resume\n",
    "                elif event.key == pygame.K_SPACE:\n",
    "                    self.pause()\n",
    "                # Press arrow keys for manual control\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    return self.step(3)  # Left action\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    return self.step(2)  # Right action\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    return self.step(0)  # Up action\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    return self.step(1)  # Down action\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    def set_pos_nodeform(self):\n",
    "        \"\"\"\n",
    "        Set the agent's state to a new position.\n",
    "        \n",
    "        This function directly updates the agent's position (state) to the provided coordinates.\n",
    "\n",
    "        :param pos: A tuple or array representing the new position of the agent in the grid.\n",
    "        \"\"\"\n",
    "        low, high = -.2, 1.2 # depends on the shear (nto stretch since compression)\n",
    "        pos = self.sample(2,limit=(low,high))\n",
    "        \n",
    "        # Update the state (agent's position)\n",
    "        self.state = np.array(pos)\n",
    "\n",
    "        # Optionally, print the new state for debugging\n",
    "        # print(f\"New agent position: {self.state}\")\n",
    "\n",
    "        return pos\n",
    "    def is_in_obstacle_nodeform(self, position):\n",
    "        \"\"\"\n",
    "        Check if a given position is inside any obstacle.\n",
    "        :param position: The (x, y) coordinates to check in the original space.\n",
    "        :return: True if the position is inside an obstacle, False otherwise.\n",
    "        \"\"\"\n",
    "        for obs in self.obstacles:\n",
    "            (x_min, y_min), (x_max, y_max) = obs\n",
    "            if x_min <= position[0] <= x_max and y_min <= position[1] <= y_max:            \n",
    "                return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "# Example Usage\n",
    "# obstacles = [\n",
    "#     [(0.2, 0.2), (0.6, 0.6)],  # Obstacle 1\n",
    "#     [(0.6, 0.6), (0.8, 0.8)]   # Obstacle 2\n",
    "# ]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, 1),\n",
    "    shear=(.2, .2),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "# state, observation = env.reset(np.random.randint(100))\n",
    "#   \n",
    "# env.reset(seed=np.random.randint(1078890))\n",
    "done = False\n",
    "while not done:\n",
    "    try:\n",
    "        _, reward, terminated, truncated, _ = env.render()\n",
    "        if terminated or truncated:\n",
    "            print(reward)\n",
    "            env.close()\n",
    "            break\n",
    "    except:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((0.14625, 0.3325), (0.565, 0.55625)),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((0.14625, 0.3325), (0.565, 0.55625)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    state, observation = env.reset(np.random.randint(100))\n",
    "    env.set_pos(env.transform([0.9,0.9]))\n",
    "    assert np.linalg.norm(env.state - env.transform(env.goal)) < env.observation_radius\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "run_id = \"n82b50oj\"\n",
    "\n",
    "last_check = find_last_checkpoint(f\"../agents/pretrained/MDP/DQN_continous_{run_id}\")\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, 1),\n",
    "    shear=(.2, .2),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "model = DQN.load(f\"../agents/pretrained/MDP/DQN_continous_{run_id}/{last_check}\", env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQN' object has no attribute 'rollout_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m382\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DQN' object has no attribute 'rollout_buffer'"
     ]
    }
   ],
   "source": [
    "model.rollout_buffer.sample(382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:n82b50oj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▁▁▁▁▄▄▄▄▄▁▁▁▁▁███████</td></tr><tr><td>rollout/ep_rew_mean</td><td>██▆▆▆▄▄▄▅▅▇▇▇▇▇▂▂▂▁▁▁▁</td></tr><tr><td>rollout/exploration_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time/fps</td><td>▁▅▇██▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▁▂█▃▃▃▇▅▅▂▁▂▁▁▁▁▁▂▂▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>760844</td></tr><tr><td>rollout/ep_len_mean</td><td>461.12</td></tr><tr><td>rollout/ep_rew_mean</td><td>-237.445</td></tr><tr><td>rollout/exploration_rate</td><td>0.05</td></tr><tr><td>time/fps</td><td>72</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr><tr><td>train/loss</td><td>0.00375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-star-2</strong> at: <a href='https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld/runs/n82b50oj' target=\"_blank\">https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld/runs/n82b50oj</a><br/> View project at: <a href='https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld' target=\"_blank\">https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_130837-n82b50oj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:n82b50oj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/flaccagora/Desktop/RoboSurgery/src/environment/wandb/run-20241211_131759-n82b50oj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld/runs/n82b50oj' target=\"_blank\">pleasant-star-2</a></strong> to <a href='https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld' target=\"_blank\">https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld/runs/n82b50oj' target=\"_blank\">https://wandb.ai/matteo-nunziante/DQNsb3%20-%20MDP%20-%20ObservableDeformedGridworld/runs/n82b50oj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rl_model_760000_steps.zip.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 138\u001b[0m\n\u001b[1;32m    134\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--run_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn82b50oj\u001b[39m\u001b[38;5;124m\"\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb run id to resume from\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args()\n\u001b[0;32m--> 138\u001b[0m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 111\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mrun_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     last_check \u001b[38;5;241m=\u001b[39m find_last_checkpoint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDQN_continous_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     net_arch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m]\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:680\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    678\u001b[0m     get_system_info()\n\u001b[0;32m--> 680\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:403\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[1;32m    377\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[1;32m    378\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:240\u001b[0m, in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:291\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    285\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:272\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:264\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/pathlib.py:1044\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1043\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rl_model_760000_steps.zip.zip'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def find_last_checkpoint(directory):\n",
    "    # Define the regex pattern to match the checkpoint file names\n",
    "    pattern = re.compile(r\"rl_model_(\\d+)_steps\")\n",
    "\n",
    "    last_checkpoint = None\n",
    "    max_steps = -1\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            # Extract the step number\n",
    "            steps = int(match.group(1))\n",
    "            # Check if this is the highest step count seen so far\n",
    "            if steps > max_steps:\n",
    "                max_steps = steps\n",
    "                last_checkpoint = filename\n",
    "\n",
    "    return os.path.splitext(last_checkpoint)[0] if last_checkpoint else None\n",
    "\n",
    "\n",
    "def train_dqn(args):\n",
    "    from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "    from wandb.integration.sb3 import WandbCallback\n",
    "    import wandb\n",
    "\n",
    "    total_timesteps = args.total_timesteps\n",
    "    batch_size = args.batch_size\n",
    "    lr = args.learning_rate\n",
    "    target_update = args.target_update\n",
    "    gamma = args.gamma\n",
    "\n",
    "    config = {\n",
    "        \"policy_type\": \"MultiInputPolicy\",\n",
    "        \"env_name\": \"ObservableDeformedGridworld\",\n",
    "        \"total_timesteps\": total_timesteps,\n",
    "        \"Batch_Size\": batch_size,\n",
    "        'grid_size': (1.0,1.0),\n",
    "        'step_size': 0.1,\n",
    "        'obstacles':obstacles,\n",
    "        'observation_radius':0.2,\n",
    "    }\n",
    "\n",
    "    if args.run_id is not None:\n",
    "        run = wandb.init(\n",
    "            project=\"DQNsb3 - MDP - ObservableDeformedGridworld\",\n",
    "            config=config,\n",
    "            sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "            monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "            save_code=True,  # optional\n",
    "            resume=\"must\",\n",
    "            id=args.run_id\n",
    "        )\n",
    "    else:\n",
    "        run = wandb.init(\n",
    "        project=\"DQNsb3 - MDP - ObservableDeformedGridworld\",\n",
    "        config=config,\n",
    "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "        monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "        save_code=True,  # optional\n",
    "        )\n",
    "\n",
    "\n",
    "    # Save a checkpoint every 10000 steps\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "                            save_freq=10000,\n",
    "                            save_path=f\"DQN_continous_{run.id}\",\n",
    "                            name_prefix=\"rl_model\",\n",
    "                            save_replay_buffer=False,\n",
    "                            save_vecnormalize=True,\n",
    "                        )\n",
    "\n",
    "    callbacks = [ WandbCallback(\n",
    "                                verbose=2,\n",
    "                                log=\"parameters\",\n",
    "                                ),\n",
    "                checkpoint_callback,\n",
    "                ]\n",
    "\n",
    "\n",
    "    from stable_baselines3.common.monitor import Monitor\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "\n",
    "    def make_env():\n",
    "        env = ObservableDeformedGridworld(\n",
    "            grid_size=(1.0, 1.0),\n",
    "            obstacles=obstacles,\n",
    "            render_mode='human'\n",
    "        )\n",
    "\n",
    "        env = Monitor(env)  # record stats such as returns\n",
    "        return env\n",
    "\n",
    "    env = DummyVecEnv([make_env])\n",
    "\n",
    "\n",
    "    if args.run_id is not None:\n",
    "        last_check = find_last_checkpoint(f\"DQN_continous_{args.run_id}\")\n",
    "        model = DQN.load(last_check, env=env)\n",
    "    else:\n",
    "        net_arch=[128, 128, 128]\n",
    "        model = DQN(\"MultiInputPolicy\",env,batch_size=batch_size,gamma=gamma, \n",
    "                    target_update_interval=target_update, policy_kwargs=dict(net_arch=net_arch), verbose=1,\n",
    "                    device=\"cpu\", learning_rate=lr,\n",
    "                    train_freq=(1,\"episode\"), gradient_steps=1)\n",
    "        \n",
    "    model.learn(total_timesteps,progress_bar=True, callback=callbacks, log_interval=1, reset_num_timesteps=False)\n",
    "    model.save(f\"agents/pretrained/MDP/DQN_continous_{run.id}\")\n",
    "    env.close()\n",
    "    run.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.001)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--total_timesteps\", type=int, default=1000000) # env steps\n",
    "    parser.add_argument(\"--target_update\", type=int, default=555) # in env steps\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99)\n",
    "    parser.add_argument(\"--f\", type=str, default=None)\n",
    "    parser.add_argument(\"--run_id\", type=str, default=\"n82b50oj\", help=\"wandb run id to resume from\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_dqn(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def find_last_checkpoint(directory):\n",
    "    # Define the regex pattern to match the checkpoint file names\n",
    "    pattern = re.compile(r\"rl_model_(\\d+)_steps\")\n",
    "\n",
    "    last_checkpoint = None\n",
    "    max_steps = -1\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            # Extract the step number\n",
    "            steps = int(match.group(1))\n",
    "            # Check if this is the highest step count seen so far\n",
    "            if steps > max_steps:\n",
    "                max_steps = steps\n",
    "                last_checkpoint = filename\n",
    "\n",
    "    return os.path.splitext(last_checkpoint)[0] if last_checkpoint else None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_model_760000_steps\n"
     ]
    }
   ],
   "source": [
    "last_check = find_last_checkpoint(\"DQN_continous_n82b50oj\")\n",
    "print(last_check)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Linux-6.11.2-amd64-x86_64-with-glibc2.40 # 1 SMP PREEMPT_DYNAMIC Kali 6.11.2-1kali1 (2024-10-15)\n",
      "- Python: 3.11.10\n",
      "- Stable-Baselines3: 2.4.0\n",
      "- PyTorch: 2.5.1+cu124\n",
      "- GPU Enabled: True\n",
      "- Numpy: 1.26.4\n",
      "- Cloudpickle: 3.1.0\n",
      "- Gymnasium: 1.0.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Linux-6.10.3-200.fc40.x86_64-x86_64-with-glibc2.39 # 1 SMP PREEMPT_DYNAMIC Mon Aug  5 14:30:00 UTC 2024\n",
      "- Python: 3.11.10\n",
      "- Stable-Baselines3: 2.4.0\n",
      "- PyTorch: 2.5.1+cu121\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.26.3\n",
      "- Cloudpickle: 3.1.0\n",
      "- Gymnasium: 1.0.0\n",
      "\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(state, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[0;32m---> 33\u001b[0m state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(terminated, truncated)\n",
      "File \u001b[0;32m~/Desktop/RoboSurgery/src/environment/env.py:1391\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1388\u001b[0m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m \n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m state \u001b[38;5;241m=\u001b[39m OrderedDict({\n\u001b[1;32m   1394\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate,\n\u001b[1;32m   1395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_matrix\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m   1396\u001b[0m         })\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;66;03m# Return the transformed state, reward, and terminated truncated flag\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/RoboSurgery/src/environment/env.py:1435\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mset_caption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeformed and Original Gridworld\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;66;03m# Fill background with white\u001b[39;00m\n\u001b[0;32m-> 1435\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWHITE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;66;03m# Compute the bounding box of the deformed grid\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m     corners \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1439\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m   1440\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size,\n\u001b[1;32m   1442\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size[\u001b[38;5;241m1\u001b[39m]]),\n\u001b[1;32m   1443\u001b[0m     ]\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, .5),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "net_arch=[128, 128, 128]\n",
    "last_checkpoint = find_last_checkpoint(\"../agents/pretrained/MDP/DQN_continous_htpthl01\")\n",
    "model = DQN.load(f\"../agents/pretrained/MDP/DQN_continous_htpthl01/{last_checkpoint}\", env=env,  print_system_info=True)\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(.5, .5),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "state, _ = env.reset(seed=np.random.randint(100))\n",
    "env.set_deformation((1, 1), (.0, .0))\n",
    "while True:\n",
    "    action, _ = model.predict(state, deterministic=True)\n",
    "    print(action)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        print(terminated, truncated)\n",
    "        env.close()\n",
    "        break\n",
    "    # time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flaccagora/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-119.95 118.70361199222202\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import DQN\n",
    "from environment.env import Grid\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = Grid(\n",
    "    obstacles=obstacles, \n",
    "    shear_range=(-.2, .2),\n",
    "    stretch_range=(.4,1),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "last_checkpoint = find_last_checkpoint(\"../../agents/pretrained/MDP/DQN_continous_1vbmjd2a\")\n",
    "model = DQN.load(f\"../../agents/pretrained/MDP/DQN_continous_1vbmjd2a/{last_checkpoint}\", env=env)\n",
    "\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20, deterministic=True)\n",
    "print(mean_reward, std_reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('pos', array([ 0.40588055, -0.05670514])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -2.0\n",
      "None None\n",
      "OrderedDict([('pos', array([ 0.42588055, -0.05670514])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([ 0.42588055, -0.03670514])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([ 0.42588055, -0.01670514])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.42588055, 0.00329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.42588055, 0.02329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.42588055, 0.04329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.42588055, 0.06329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.42588055, 0.08329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.44588055, 0.08329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.44588055, 0.10329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.46588055, 0.10329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.46588055, 0.12329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.48588055, 0.12329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.48588055, 0.14329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.50588055, 0.14329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.50588055, 0.16329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.52588055, 0.16329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.52588055, 0.18329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.54588055, 0.18329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.54588055, 0.20329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.56588055, 0.20329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.56588055, 0.22329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.58588055, 0.22329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.58588055, 0.24329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.58588055, 0.26329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.58588055, 0.28329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.60588055, 0.28329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.62588055, 0.28329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.64588055, 0.28329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.64588055, 0.30329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.66588055, 0.30329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.66588055, 0.32329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.66588055, 0.34329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.68588055, 0.34329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.68588055, 0.36329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.68588055, 0.38329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.68588055, 0.40329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.70588055, 0.40329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n",
      "None None\n",
      "OrderedDict([('pos', array([0.72588055, 0.40329486])), ('theta', array([ 0.80373425, -0.0133121 , -0.19033908,  0.93468088]))]) -0.5\n"
     ]
    }
   ],
   "source": [
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), ((0.0, 0.00125), (0.01625, 0.99125)), ((0.0075, 0.00125), (0.99875, 0.04)), ((0.98875, 0.0075), (0.99875, 1.0)), ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "state, observation = env.reset(np.random.randint(1005647))\n",
    "previous = None \n",
    "while True:\n",
    "    try:\n",
    "        state, reward, terminated, truncated, info = env.render()\n",
    "        if state != previous:\n",
    "            print(state,reward)\n",
    "            previous = state  \n",
    "        if terminated or truncated:\n",
    "            print(terminated, truncated)\n",
    "            env.close()\n",
    "            break\n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pos_nodeform(self):\n",
    "    \"\"\"\n",
    "    Set the agent's state to a new position.\n",
    "    \n",
    "    This function directly updates the agent's position (state) to the provided coordinates.\n",
    "\n",
    "    :param pos: A tuple or array representing the new position of the agent in the grid.\n",
    "    \"\"\"\n",
    "    low, high = -.2, 1.2 # depends on the shear (nto stretch since compression)\n",
    "    pos = self.sample(2,limit=(low,high))\n",
    "    \n",
    "    # Update the state (agent's position)\n",
    "    self.state = np.array(pos)\n",
    "\n",
    "    # Optionally, print the new state for debugging\n",
    "    # print(f\"New agent position: {self.state}\")\n",
    "\n",
    "def is_in_obstacle_nodeform(self, position):\n",
    "    \"\"\"\n",
    "    Check if a given position is inside any obstacle.\n",
    "    :param position: The (x, y) coordinates to check in the original space.\n",
    "    :return: True if the position is inside an obstacle, False otherwise.\n",
    "    \"\"\"\n",
    "    for obs in self.obstacles:\n",
    "        (x_min, y_min), (x_max, y_max) = obs\n",
    "        if x_min <= position[0] <= x_max and y_min <= position[1] <= y_max:            \n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [16:00<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "num_positions = 1000\n",
    "num_defomations = 1000\n",
    "dataset = []\n",
    "\n",
    "for i in trange(num_positions):\n",
    "    pos = env.set_pos_nodeform()\n",
    "    obstacle = env.is_in_obstacle_nodeform(pos)\n",
    "\n",
    "    for _ in range(num_defomations):\n",
    "        env.set_deformation(env.sample(2,env.stretch_range), env.sample(2,env.shear_range))\n",
    "        defomed_obstacle = env.is_in_obstacle(pos)\n",
    "        \n",
    "        datapoint = {\"pos\":       pos,\n",
    "                    \"theta\":      env.transformation_matrix,\n",
    "                    \"obs\":        1 if obstacle else 0,\n",
    "                    \"deform_obs\": 1 if defomed_obstacle else 0,\n",
    "                }\n",
    "        # env.render()\n",
    "        dataset.append(datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [00:20<14:46,  1.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_defomations):\n\u001b[1;32m     18\u001b[0m     pos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mset_pos_nodeform()\n\u001b[0;32m---> 19\u001b[0m     defomed_obstacle \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_in_obstacle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     datapoint \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m:       pos,\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m:      env\u001b[38;5;241m.\u001b[39mtransformation_matrix,\n\u001b[1;32m     23\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m:        \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obstacle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     24\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeform_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m defomed_obstacle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     25\u001b[0m             }\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# env.render()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[51], line 142\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.is_in_obstacle\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobstacles:\n\u001b[1;32m    141\u001b[0m     (x_min, y_min), (x_max, y_max) \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m--> 142\u001b[0m     bottom_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     bottom_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([x_max, y_min]))\n\u001b[1;32m    144\u001b[0m     top_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([x_min, y_max]))\n",
      "Cell \u001b[0;32mIn[51], line 124\u001b[0m, in \u001b[0;36mObservableDeformedGridworld.transform\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, position):\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    Apply the grid deformation to a given position.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    :param position: (x, y) in original space.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    :return: Transformed position in the deformed grid.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformation_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "env = ObservableDeformedGridworld(\n",
    "    obstacles=obstacles, \n",
    "    stretch=(1, 1),\n",
    "    shear=(.0, .0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "num_positions = 1000\n",
    "num_defomations = 1000\n",
    "dataset = []\n",
    "\n",
    "for i in trange(num_positions):\n",
    "    env.set_deformation(env.sample(2,env.stretch_range), env.sample(2,env.shear_range))\n",
    "    obstacle = env.is_in_obstacle_nodeform(pos)\n",
    "\n",
    "    for _ in range(num_defomations):\n",
    "        pos = env.set_pos_nodeform()\n",
    "        defomed_obstacle = env.is_in_obstacle(pos)\n",
    "        \n",
    "        datapoint = {\"pos\":       pos,\n",
    "                    \"theta\":      env.transformation_matrix,\n",
    "                    \"obs\":        1 if obstacle else 0,\n",
    "                    \"deform_obs\": 1 if defomed_obstacle else 0,\n",
    "                }\n",
    "        # env.render()\n",
    "        dataset.append(datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "import pickle\n",
    "\n",
    "with open(\"dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# lod dataset\n",
    "with open(\"dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): List of dictionaries containing 'o', 'theta', 'qpos', and 'qpos_new'.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve one sample of data by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with inputs and expected outputs as tensors.\n",
    "        \"\"\"\n",
    "        # Extract the dictionary for the given index\n",
    "        data = self.data_list[idx]\n",
    "        \n",
    "        # Convert data to PyTorch tensors\n",
    "        o = torch.tensor(data['obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        theta = torch.tensor(data['theta'], dtype=torch.float32).flatten()\n",
    "        o_new = torch.tensor(data['deform_obs'], dtype=torch.float32).unsqueeze(0)\n",
    "        pos = torch.tensor(data['pos'], dtype=torch.float32)      \n",
    "        \n",
    "\n",
    "        # Inputs: qpos_new, o, theta\n",
    "        inputs = {\n",
    "            'deform_obs': o_new,\n",
    "            'theta': theta,\n",
    "            'pos': pos\n",
    "        }\n",
    "        \n",
    "        # Output: qpos_new\n",
    "        target = {\n",
    "            'pos': pos,\n",
    "            'obs': o\n",
    "        }\n",
    "        \n",
    "        return inputs, target\n",
    "\n",
    "\n",
    "# Instantiate the dataset\n",
    "custom_dataset = CustomDataset(dataset)\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(custom_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([1024, 1]), torch.Size([1024, 4]))\n"
     ]
    }
   ],
   "source": [
    "for inputs, target in data_loader:\n",
    "    print((inputs['deform_obs'].shape,inputs['theta'].shape))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "# Check the output size\n",
    "# Iterate through the DataLoader\n",
    "for inputs, target in data_loader:\n",
    "    print(model(inputs['pos'],inputs['deform_obs'],inputs['theta']).shape)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0665ffc4c197460d8e93cdce93f5e47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runningLoss: 0.36275911962607743\n",
      "runningLoss: 0.28178783790603995\n",
      "runningLoss: 0.2606878045149445\n",
      "runningLoss: 0.24350653864832228\n",
      "runningLoss: 0.22974412823467685\n"
     ]
    }
   ],
   "source": [
    "# train network \n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "# Instantiate the model\n",
    "model = NN()\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the model in training mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e2deebe0df4106853955292a46e62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runningLoss: 0.06769560960368344\n",
      "runningLoss: 0.06450088120455508\n",
      "runningLoss: 0.06130198488810777\n",
      "runningLoss: 0.05854604267415151\n",
      "runningLoss: 0.05574614926410063\n"
     ]
    }
   ],
   "source": [
    "# tqdm progress bar\n",
    "pbar = tqdm(total=len(data_loader),desc=\"Training\")\n",
    "pbar.refresh()\n",
    "pbar.reset()\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for i, (inputs, target) in enumerate(data_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs['pos'].to(device),inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target['obs'].to(device))\n",
    "\n",
    "        # Backward pass\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.reset()\n",
    "    print(\"runningLoss:\", running_loss/len(data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"obs_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter target with obstacle\n",
    "count = 0\n",
    "for inputs, target in data_loader:\n",
    "    count += torch.count_nonzero(target['obs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 121000, 0.121)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), count.item(), count.item()/len(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(121000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deform_obs': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), 'theta': tensor([[ 0.6069,  0.0460, -0.1410,  0.7324],\n",
      "        [ 0.4951, -0.0290, -0.1900,  0.5352],\n",
      "        [ 0.5310, -0.0502,  0.1989,  0.4344],\n",
      "        ...,\n",
      "        [ 0.5591, -0.1723,  0.1204,  0.5878],\n",
      "        [ 0.9620,  0.1982, -0.0428,  0.7177],\n",
      "        [ 0.4606, -0.0163,  0.0165,  0.8431]]), 'pos': tensor([[0.7033, 0.4231],\n",
      "        [0.5368, 0.4076],\n",
      "        [1.1467, 1.1071],\n",
      "        ...,\n",
      "        [0.4275, 1.1039],\n",
      "        [1.0132, 1.0841],\n",
      "        [0.0238, 1.0522]])}\n",
      "tensor([[4.3709e-04],\n",
      "        [4.6240e-01],\n",
      "        [6.8391e-05],\n",
      "        ...,\n",
      "        [4.8210e-02],\n",
      "        [1.5263e-03],\n",
      "        [1.8719e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, target in data_loader:\n",
    "        outputs = model(inputs['pos'].to(device),inputs['deform_obs'].to(device),inputs['theta'].to(device))\n",
    "        print(inputs)\n",
    "        print(outputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[outputs>0.5].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
