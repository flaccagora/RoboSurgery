{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flaccagora/.miniconda3/envs/robogym/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-119.95 118.70361199222202\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import DQN\n",
    "from environment.env import Grid\n",
    "from utils.checkpoints import find_last_checkpoint\n",
    "\n",
    "obstacles = [((0.14625, 0.3325), (0.565, 0.55625)), \n",
    "             ((0.52875, 0.5375), (0.7375, 0.84125)), \n",
    "             ((0.0, 0.00125), (0.01625, 0.99125)), \n",
    "             ((0.0075, 0.00125), (0.99875, 0.04)), \n",
    "             ((0.98875, 0.0075), (0.99875, 1.0)), \n",
    "             ((0.00125, 0.9825), (0.99875, 1.0))]\n",
    "\n",
    "env = Grid(\n",
    "    obstacles=obstacles, \n",
    "    shear_range=(-.2, .2),\n",
    "    stretch_range=(.4,1),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "last_checkpoint = find_last_checkpoint(\"../../agents/pretrained/MDP/DQN_continous_1vbmjd2a\")\n",
    "model = DQN.load(f\"../../agents/pretrained/MDP/DQN_continous_1vbmjd2a/{last_checkpoint}\", env=env)\n",
    "\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20, deterministic=True)\n",
    "print(mean_reward, std_reward)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
