{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "import torch\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import POMDPDeformedGridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4451]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(6, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,theta):\n",
    "        x = torch.cat([pos,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model_0.pth',map_location=torch.device('cpu') ,weights_only=True))\n",
    "\n",
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRETE BELIEF UPDATE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    \n",
    "    def __init__(self, env: POMDPDeformedGridworld, discretization=10, update='discrete_exact', obs_model=None):\n",
    "        self.env = env\n",
    "\n",
    "        stretch = np.linspace(.4, 1, discretization)\n",
    "        # shear = np.linspace(0,0, discretization)\n",
    "        xa,xb = np.meshgrid(stretch, stretch) # , shear, shear\n",
    "        positions = np.column_stack([xa.ravel(),xb.ravel()]), #  ya.ravel(),yb.ravel()\n",
    "        positions = torch.tensor(positions, dtype=torch.float32)\n",
    "        self.belief_points = positions.squeeze()\n",
    "        self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(positions)\n",
    "\n",
    "        if update == 'discrete_modelled': \n",
    "            assert obs_model is not None, f'Need an observation model for discrete_modelled belief update, given {obs_model}'\n",
    "            self.obs_model = obs_model\n",
    "            self.belief_update = self.discrete_belief_update\n",
    "        \n",
    "        elif update == 'discrete_exact':\n",
    "            self.belief_update = self.exact_belief_update\n",
    "        else:\n",
    "            raise NotImplementedError('Only discrete belief update is supported')\n",
    "        \n",
    "        self.original_def = env.transformation_matrix[0][0], env.transformation_matrix[1][1]\n",
    "        \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def discrete_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        pos = pomdp_state['pos']\n",
    "        obs = pomdp_state['obs']\n",
    "\n",
    "        batch_pos = pos.repeat(len(self.belief_points), 1)\n",
    "        \n",
    "        # need theta because working on two parameters only in this example\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "        \n",
    "\n",
    "        predictions = self.obs_model(batch_pos,theta)\n",
    "        likelihood = torch.exp(torch.distributions.Bernoulli(predictions).log_prob(obs))\n",
    "\n",
    "        tmp = likelihood.squeeze() * self.belief_values\n",
    "        self.belief_values = tmp  / tmp.sum()\n",
    "    \n",
    "    def exact_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        def f():\n",
    "            likelihood = []\n",
    "            for x in self.belief_points:\n",
    "                try:\n",
    "                    self.env.set_deformation([x[0], x[1]],[0,0]) # stretch, shear format\n",
    "                    likelihood.append(torch.all(torch.tensor(self.env.observe(list(pos))) == obs))\n",
    "                except:\n",
    "                    raise ValueError('Invalid belief point x', x)\n",
    "            self.env.set_deformation(self.original_def, [0,0])\n",
    "            return torch.tensor(likelihood, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        likelihood = f()\n",
    "        self.belief_values =  likelihood * self.belief_values\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from io import BytesIO\n",
    "\n",
    "# Modify belief_plot to save as an image\n",
    "def belief_plot(agent):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()    \n",
    "    # (Add your plotting logic here)\n",
    "    plt.imshow(agent.belief_values.detach().numpy().reshape(50,50))\n",
    "    # Save the figure to an in-memory buffer\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")  # Save as PNG into the buffer\n",
    "    plt.close()  # Close the plot to avoid memory leaks\n",
    "    buf.seek(0)  # Move to the beginning of the buffer\n",
    "\n",
    "    # Open the image from the buffer\n",
    "    return Image.open(buf)    \n",
    "\n",
    "def create_gif(images, filename=\"belief_animation.gif\", duration=100, loop=0):\n",
    "    \"\"\"\n",
    "    Create a GIF from a list of PIL Image objects.\n",
    "    \n",
    "    Args:\n",
    "        images (list): A list of PIL Image objects.\n",
    "        filename (str): Name of the output GIF file.\n",
    "        duration (int): Duration of each frame in milliseconds.\n",
    "        loop (int): Number of times to loop the GIF. 0 means infinite.\n",
    "    \"\"\"\n",
    "    if images:\n",
    "        images[0].save(\n",
    "            filename,\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=duration,\n",
    "            loop=loop\n",
    "        )\n",
    "        print(f\"GIF saved as {filename}\")\n",
    "    else:\n",
    "        print(\"No images to create a GIF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.4000])\n",
      "tensor([0.8408, 0.6204])\n",
      "tensor([0.5959, 0.6204])\n",
      "tensor([0.5959, 0.6082])\n",
      "tensor([0.5837, 0.6082])\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld(obs_type='single')\n",
    "pomdp_env.reset()\n",
    "pomdp_env.set_deformation([0.6, 0.6],[0,0])\n",
    "\n",
    "agent = POMDPAgent(pomdp_env,50, update='discrete_modelled', obs_model=obs_model)\n",
    "# agent = POMDPAgent(pomdp_env,50,update='discrete_exact')\n",
    "\n",
    "images = []\n",
    "b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "img = belief_plot(agent)\n",
    "images.append(img)      \n",
    "\n",
    "print(b)\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "        img = belief_plot(agent)\n",
    "        images.append(img)      \n",
    "        # assert torch.allclose(agent.belief_values.sum(), torch.tensor([1.0])), f\"Belief values do not sum to 1: {agent.belief_values.sum()}\"\n",
    "        if torch.any(b != agent.belief_points[torch.argmax(agent.belief_values)]):\n",
    "            b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "            print(b)\n",
    "    except:\n",
    "        print('Error')\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as belief_animation_single_obsmodel.gif\n"
     ]
    }
   ],
   "source": [
    "create_gif(images, filename=\"belief_animation_single_obsmodel.gif\", duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIATIONAL UPDATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
