{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "import torch\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import POMDPDeformedGridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2173]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(6, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,theta):\n",
    "        x = torch.cat([pos,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model_4.pth',map_location=torch.device('cpu') ,weights_only=True))\n",
    "\n",
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRETE BELIEF UPDATE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    \n",
    "    def __init__(self, env: POMDPDeformedGridworld, discretization=10, update='discrete_exact', obs_model=None):\n",
    "        self.env = env\n",
    "\n",
    "        if update == 'discrete_modelled' or update == 'discrete_exact':\n",
    "            stretch = np.linspace(.4, 1, discretization)\n",
    "            # shear = np.linspace(0,0, discretization)\n",
    "            xa,xb = np.meshgrid(stretch, stretch) # , shear, shear\n",
    "            positions = np.column_stack([xa.ravel(),xb.ravel()]), #  ya.ravel(),yb.ravel()\n",
    "            positions = torch.tensor(positions, dtype=torch.float32)\n",
    "            self.belief_points = positions.squeeze()\n",
    "            self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(positions)\n",
    "\n",
    "        if update == 'discrete_modelled': \n",
    "            assert obs_model is not None, f'Need an observation model for discrete_modelled belief update, given {obs_model}'\n",
    "            self.obs_model = obs_model\n",
    "            self.belief_update = self.discrete_belief_update\n",
    "        elif update == 'discrete_exact':\n",
    "            self.belief_update = self.exact_belief_update\n",
    "        elif update == 'variational':\n",
    "            from utils.belief import BetaVariationalBayesianInference\n",
    "            assert obs_model is not None, f'Need an observation model for variational belief update, given {obs_model}'\n",
    "            self.VI = BetaVariationalBayesianInference(obs_model, input_dim=2, latent_dim=4)\n",
    "\n",
    "            self.belief_update = self.variational_belief_update\n",
    "            self.X_history = [self.env.get_state()['pos']]\n",
    "            self.y_history = [self.env.get_state()['obs']]\n",
    "        else:\n",
    "            raise ValueError('Invalid belief update method')\n",
    "        \n",
    "        self.original_def = env.transformation_matrix[0][0], env.transformation_matrix[1][1]\n",
    "        \n",
    "    def act(self):\n",
    "        # action = \n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def discrete_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        pos = pomdp_state['pos']\n",
    "        obs = pomdp_state['obs']\n",
    "\n",
    "        batch_pos = pos.repeat(len(self.belief_points), 1)\n",
    "        \n",
    "        # need theta because working on two parameters only in this example\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "        \n",
    "\n",
    "        predictions = self.obs_model(batch_pos,theta)\n",
    "        likelihood = torch.exp(torch.distributions.Bernoulli(predictions).log_prob(obs))\n",
    "\n",
    "        tmp = likelihood.squeeze() * self.belief_values\n",
    "        self.belief_values = tmp  / tmp.sum()\n",
    "    \n",
    "    def exact_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        def f():\n",
    "            likelihood = []\n",
    "            for x in self.belief_points:\n",
    "                try:\n",
    "                    self.env.set_deformation([x[0], x[1]],[0,0]) # stretch, shear format\n",
    "                    likelihood.append(torch.all(torch.tensor(self.env.observe(list(pos))) == obs))\n",
    "                except:\n",
    "                    raise ValueError('Invalid belief point x', x)\n",
    "            self.env.set_deformation(self.original_def, [0,0])\n",
    "            return torch.tensor(likelihood, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        likelihood = f()\n",
    "        self.belief_values =  likelihood * self.belief_values\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "\n",
    "    def variational_belief_update(self, pomdp_state):\n",
    "        self.X_history.append(pomdp_state['pos'])\n",
    "        self.y_history.append(pomdp_state['obs'])\n",
    "\n",
    "        # X = posizione dell'agente (x,y)\n",
    "        X = torch.stack(self.X_history)\n",
    "\n",
    "        # ossevrazioni dell'agente negli stati pos=(x,y)\n",
    "        y = torch.stack(self.y_history)\n",
    "\n",
    "        # Create and fit the model\n",
    "        self.VI.fit(X, y, n_epochs=10, lr=0.05)\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        self.env.render()       \n",
    "        pomdp_state = self.env.get_state()\n",
    "        if torch.any(pomdp_state['pos'] != self.X_history[-1]):\n",
    "            self.belief_update(pomdp_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from io import BytesIO\n",
    "\n",
    "# Modify belief_plot to save as an image\n",
    "def belief_plot(agent):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()    \n",
    "    # (Add your plotting logic here)\n",
    "    plt.imshow(agent.belief_values.detach().numpy().reshape(50,50))\n",
    "    # Save the figure to an in-memory buffer\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")  # Save as PNG into the buffer\n",
    "    plt.close()  # Close the plot to avoid memory leaks\n",
    "    buf.seek(0)  # Move to the beginning of the buffer\n",
    "\n",
    "    # Open the image from the buffer\n",
    "    return Image.open(buf)    \n",
    "\n",
    "def create_gif(images, filename=\"belief_animation.gif\", duration=100, loop=0):\n",
    "    \"\"\"\n",
    "    Create a GIF from a list of PIL Image objects.\n",
    "    \n",
    "    Args:\n",
    "        images (list): A list of PIL Image objects.\n",
    "        filename (str): Name of the output GIF file.\n",
    "        duration (int): Duration of each frame in milliseconds.\n",
    "        loop (int): Number of times to loop the GIF. 0 means infinite.\n",
    "    \"\"\"\n",
    "    if images:\n",
    "        images[0].save(\n",
    "            filename,\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=duration,\n",
    "            loop=loop\n",
    "        )\n",
    "        print(f\"GIF saved as {filename}\")\n",
    "    else:\n",
    "        print(\"No images to create a GIF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52152/202773649.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  positions = torch.tensor(positions, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.4000])\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld(obs_type='single')\n",
    "pomdp_env.reset()\n",
    "pomdp_env.set_deformation([0.6, 0.6],[0,0])\n",
    "\n",
    "agent = POMDPAgent(pomdp_env,50, update='discrete_modelled', obs_model=obs_model)\n",
    "# agent = POMDPAgent(pomdp_env,50,update='discrete_exact')\n",
    "\n",
    "images = []\n",
    "b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "img = belief_plot(agent)\n",
    "images.append(img)      \n",
    "\n",
    "print(b)\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "        img = belief_plot(agent)\n",
    "        images.append(img)      \n",
    "        # assert torch.allclose(agent.belief_values.sum(), torch.tensor([1.0])), f\"Belief values do not sum to 1: {agent.belief_values.sum()}\"\n",
    "        if torch.any(b != agent.belief_points[torch.argmax(agent.belief_values)]):\n",
    "            b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "            print(b)\n",
    "    except:\n",
    "        print('Error')\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as belief_animation_single_obsmodel.gif\n"
     ]
    }
   ],
   "source": [
    "create_gif(images, filename=\"belief_animation_single_obsmodel.gif\", duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIATIONAL UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "\n",
    "class BetaVariationalBayesianInference:\n",
    "    def __init__(self, f, input_dim, latent_dim=1, hidden_dim=32):\n",
    "        \"\"\"\n",
    "        Initialize the variational Bayesian inference model with Beta distributions.\n",
    "        \n",
    "        Args:\n",
    "            f: callable, the known function linking X and y through theta\n",
    "            input_dim: int, dimension of input X\n",
    "            latent_dim: int, dimension of latent parameter theta\n",
    "            hidden_dim: int, dimension of hidden layers in the neural network\n",
    "        \"\"\"\n",
    "        self.f = f\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Variational parameters (alpha and beta of q(theta))\n",
    "        # Initialize to reasonable values (alpha=beta=2 gives a symmetric Beta)\n",
    "        self.q_alpha = nn.Parameter(2 * torch.ones(latent_dim))\n",
    "        self.q_beta = nn.Parameter(2 * torch.ones(latent_dim))\n",
    "        \n",
    "        # Prior parameters (can be customized)\n",
    "        self.prior_alpha = torch.ones(latent_dim)  # Default to Beta(1,1) = Uniform(0,1)\n",
    "        self.prior_beta = torch.ones(latent_dim)\n",
    "        \n",
    "        self.low = torch.tensor([.4, -.2, -.2, .4])\n",
    "        self.high = torch.tensor([1.0, .2, .2, 1.0])\n",
    "\n",
    "    def sample_latent(self, n_samples=1):\n",
    "        \"\"\"\n",
    "        Sample from the variational distribution q(theta) using the Beta distribution\n",
    "        \"\"\"\n",
    "        q_dist = dist.Beta(self.q_alpha, self.q_beta)\n",
    "        theta =  q_dist.rsample((n_samples,))\n",
    "        return self.low + (self.high - self.low) * theta\n",
    "    \n",
    "    def elbo(self, X, y, n_samples=10):\n",
    "        \"\"\"\n",
    "        Compute the evidence lower bound (ELBO) with Beta distributions\n",
    "        \n",
    "        Args:\n",
    "            X: torch.Tensor, input data (batch_size, input_dim)\n",
    "            y: torch.Tensor, observations (batch_size,)\n",
    "            n_samples: int, number of Monte Carlo samples\n",
    "        \"\"\"\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        # Sample from variational distribution\n",
    "        theta_samples = self.sample_latent(n_samples)  # (n_samples, latent_dim)\n",
    "        \n",
    "        # Compute log likelihood for each sample\n",
    "        log_likelihood = torch.zeros(n_samples, batch_size)\n",
    "        for i in range(n_samples):\n",
    "            theta = theta_samples[i]\n",
    "            y_pred = self.f(X, theta.expand(batch_size, -1)).squeeze()\n",
    "            log_likelihood[i] = dist.Bernoulli(y_pred).log_prob(y)\n",
    "        \n",
    "        # Average over samples\n",
    "        expected_log_likelihood = torch.mean(log_likelihood, dim=0).sum()\n",
    "        \n",
    "        # Compute KL divergence between Beta distributions\n",
    "        q_dist = dist.Beta(self.q_alpha, self.q_beta)\n",
    "        prior_dist = dist.Beta(self.prior_alpha, self.prior_beta)\n",
    "        kl_div = dist.kl_divergence(q_dist, prior_dist).sum()\n",
    "        \n",
    "        return expected_log_likelihood - kl_div\n",
    "    \n",
    "    def fit(self, X, y, n_epochs=100, batch_size=64, lr=0.1):\n",
    "        \"\"\"\n",
    "        Fit the model using variational inference\n",
    "        \n",
    "        Args:\n",
    "            X: torch.Tensor, input data\n",
    "            y: torch.Tensor, observations\n",
    "            n_epochs: int, number of training epochs\n",
    "            batch_size: int, batch size for stochastic optimization\n",
    "            lr: float, learning rate\n",
    "        \"\"\"\n",
    "        optimizer = Adam([self.q_alpha, self.q_beta], lr=lr)\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = -self.elbo(batch_X, batch_y, n_samples=100)  # Negative because we minimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Ensure parameters stay positive\n",
    "                with torch.no_grad():\n",
    "                    self.q_alpha.data.clamp_(min=1e-6)\n",
    "                    self.q_beta.data.clamp_(min=1e-6)\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                mean = self.q_alpha.detach() / (self.q_alpha.detach() + self.q_beta.detach())\n",
    "                mean = self.low + (self.high - self.low) * mean\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "                print(f\"Estimated theta mean: {mean}\")\n",
    "    \n",
    "    def get_posterior_params(self):\n",
    "        \"\"\"Return the learned posterior parameters\"\"\"\n",
    "        return {\n",
    "            'alpha': self.q_alpha.detach(),\n",
    "            'beta': self.q_beta.detach(),\n",
    "            'mean': self.low + (self.high - self.low) * (self.q_alpha / (self.q_alpha + self.q_beta)).detach(),\n",
    "            'mode': ((self.q_alpha - 1) / (self.q_alpha + self.q_beta - 2)).detach()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44897147790195435, 0.1206244380337072], [0.18191284832518556, 0.45778315464858027]]\n",
      "Epoch 10/10, Loss: 4.9005\n",
      "Estimated theta mean: tensor([ 0.6263, -0.0488,  0.0423,  0.7618])\n",
      "Epoch 10/10, Loss: 2.3943\n",
      "Estimated theta mean: tensor([ 0.5534, -0.0953,  0.0815,  0.8185])\n",
      "Epoch 10/10, Loss: 2.1555\n",
      "Estimated theta mean: tensor([ 0.5076, -0.0999,  0.1049,  0.8586])\n",
      "Epoch 10/10, Loss: 17.2414\n",
      "Estimated theta mean: tensor([ 0.5498, -0.0683,  0.0821,  0.8346])\n",
      "Epoch 10/10, Loss: 26.6275\n",
      "Estimated theta mean: tensor([ 0.5797, -0.0340,  0.0521,  0.7896])\n",
      "Epoch 10/10, Loss: 31.6377\n",
      "Estimated theta mean: tensor([ 0.5688, -0.0189,  0.0123,  0.7305])\n",
      "Epoch 10/10, Loss: 35.5514\n",
      "Estimated theta mean: tensor([ 0.5633, -0.0077, -0.0244,  0.7030])\n",
      "Epoch 10/10, Loss: 35.2344\n",
      "Estimated theta mean: tensor([ 0.5395,  0.0016, -0.0367,  0.7080])\n",
      "Epoch 10/10, Loss: 33.1707\n",
      "Estimated theta mean: tensor([ 0.5342,  0.0339, -0.0503,  0.7231])\n",
      "Epoch 10/10, Loss: 35.7730\n",
      "Estimated theta mean: tensor([ 0.5032,  0.0212, -0.0824,  0.7049])\n",
      "Epoch 10/10, Loss: 33.4035\n",
      "Estimated theta mean: tensor([ 0.4741,  0.0341, -0.1075,  0.7364])\n",
      "Epoch 10/10, Loss: 33.7621\n",
      "Estimated theta mean: tensor([ 0.4657,  0.0550, -0.1253,  0.7682])\n",
      "Epoch 10/10, Loss: 43.4597\n",
      "Estimated theta mean: tensor([ 0.4545,  0.0857, -0.1466,  0.7879])\n",
      "Epoch 10/10, Loss: 42.9511\n",
      "Estimated theta mean: tensor([ 0.4617,  0.1217, -0.1384,  0.8121])\n",
      "Epoch 10/10, Loss: 37.5703\n",
      "Estimated theta mean: tensor([ 0.4317,  0.1584, -0.1604,  0.8013])\n",
      "Epoch 10/10, Loss: 33.2660\n",
      "Estimated theta mean: tensor([ 0.4145,  0.1926, -0.1553,  0.8095])\n",
      "Epoch 10/10, Loss: 41.7164\n",
      "Estimated theta mean: tensor([ 0.4208,  0.1883, -0.1716,  0.7932])\n",
      "Epoch 10/10, Loss: 51.6435\n",
      "Estimated theta mean: tensor([ 0.4210,  0.1907, -0.1504,  0.7751])\n",
      "Epoch 10/10, Loss: 57.5973\n",
      "Estimated theta mean: tensor([ 0.4204,  0.1895, -0.1493,  0.7472])\n",
      "Epoch 10/10, Loss: 70.5259\n",
      "Estimated theta mean: tensor([ 0.4203,  0.1871, -0.1414,  0.7216])\n",
      "Epoch 10/10, Loss: 70.3060\n",
      "Estimated theta mean: tensor([ 0.4201,  0.1888, -0.1273,  0.7032])\n",
      "Epoch 10/10, Loss: 72.7492\n",
      "Estimated theta mean: tensor([ 0.4282,  0.1874, -0.1316,  0.6814])\n",
      "Epoch 10/10, Loss: 69.9830\n",
      "Estimated theta mean: tensor([ 0.4225,  0.1868, -0.1332,  0.6689])\n",
      "Epoch 10/10, Loss: 78.3049\n",
      "Estimated theta mean: tensor([ 0.4196,  0.1877, -0.1271,  0.6664])\n",
      "Epoch 10/10, Loss: 85.6685\n",
      "Estimated theta mean: tensor([ 0.4175,  0.1843, -0.1154,  0.6665])\n",
      "Epoch 10/10, Loss: 79.2577\n",
      "Estimated theta mean: tensor([ 0.4142,  0.1817, -0.1104,  0.6683])\n",
      "Epoch 10/10, Loss: 88.6161\n",
      "Estimated theta mean: tensor([ 0.4124,  0.1857, -0.1027,  0.6638])\n",
      "Epoch 10/10, Loss: 80.0720\n",
      "Estimated theta mean: tensor([ 0.4154,  0.1865, -0.0918,  0.6645])\n",
      "Epoch 10/10, Loss: 89.7474\n",
      "Estimated theta mean: tensor([ 0.4111,  0.1870, -0.0946,  0.6574])\n",
      "Epoch 10/10, Loss: 85.5804\n",
      "Estimated theta mean: tensor([ 0.4107,  0.1822, -0.0860,  0.6592])\n",
      "Epoch 10/10, Loss: 85.3838\n",
      "Estimated theta mean: tensor([ 0.4105,  0.1861, -0.0867,  0.6522])\n",
      "Epoch 10/10, Loss: 102.3298\n",
      "Estimated theta mean: tensor([ 0.4104,  0.1855, -0.0772,  0.6543])\n",
      "Epoch 10/10, Loss: 94.3763\n",
      "Estimated theta mean: tensor([ 0.4118,  0.1796, -0.0731,  0.6459])\n",
      "Epoch 10/10, Loss: 92.0837\n",
      "Estimated theta mean: tensor([ 0.4098,  0.1734, -0.0651,  0.6421])\n",
      "Epoch 10/10, Loss: 108.6476\n",
      "Estimated theta mean: tensor([ 0.4108,  0.1714, -0.0604,  0.6301])\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld(obs_type='single')\n",
    "pomdp_env.reset()\n",
    "print(pomdp_env.transformation_matrix)\n",
    "\n",
    "agent = POMDPAgent(pomdp_env,50, update='variational', obs_model=obs_model)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "    except:\n",
    "        print('Error')\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9547648571554864, -0.09006852783503004],\n",
       " [0.17217612734153898, 0.6915637745069985]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pomdp_env.transformation_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
