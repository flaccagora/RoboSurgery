{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "import torch\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import POMDPDeformedGridworld, Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ,weights_only=True))\n",
    "\n",
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([1.0]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bernoulli(probs: torch.Size([2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.Bernoulli(torch.tensor([0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRETE BELIEF UPDATE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    def __init__(self, env: POMDPDeformedGridworld, discretization=10, update='discrete_exact', obs_model=None):\n",
    "        self.env = env\n",
    "\n",
    "        if update == 'discrete_modelled': \n",
    "            assert obs_model is not None\n",
    "            self.obs_model = obs_model\n",
    "            # assuming discrete belief over 2 parameters\n",
    "            belief_points = np.linspace(env.stretch_range[0], env.stretch_range[1], discretization) \n",
    "            # zip belief points in every combination\n",
    "            import itertools\n",
    "            self.tmp_belief_points = { bp:0 for bp in itertools.product(belief_points, belief_points) }\n",
    "            self.belief_points = torch.tensor(list(self.tmp_belief_points.keys()), dtype=torch.float32)\n",
    "\n",
    "            self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(self.tmp_belief_points.keys())\n",
    "\n",
    "            self.belief_update = self.discrete_belief_update\n",
    "        \n",
    "        elif update == 'discrete_exact':\n",
    "                        # assuming discrete belief over 2 parameters\n",
    "            belief_points = np.linspace(env.stretch_range[0], env.stretch_range[1], discretization) \n",
    "            # zip belief points in every combination\n",
    "            import itertools\n",
    "            self.tmp_belief_points = { bp:0 for bp in itertools.product(belief_points, belief_points) }\n",
    "            self.belief_points = torch.tensor(list(self.tmp_belief_points.keys()), dtype=torch.float32)\n",
    "\n",
    "            self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(self.tmp_belief_points.keys())\n",
    "\n",
    "            self.belief_update = self.exact_belief_update\n",
    "        else:\n",
    "            raise NotImplementedError('Only discrete belief update is supported')\n",
    "        \n",
    "        self.original_def = env.transformation_matrix[0][0], env.transformation_matrix[1][1]\n",
    "        \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def discrete_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        batch_pos = pos.repeat(len(self.belief_points), 1)\n",
    "        batch_obs = obs.repeat(len(self.belief_points), 1)\n",
    "        \n",
    "        # need theta because working on two parameters only in this example\n",
    "        # siamo sicuri che sia l'ordine gisuto ??\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "        \n",
    "\n",
    "        likelihood = torch.distributions.Bernoulli(self.obs_model(batch_pos,batch_obs,theta)).sample()\n",
    "        self.belief_values =  torch.einsum(\"ij,j->i\",likelihood, self.belief_values)\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "    \n",
    "    def exact_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        # need theta because working on two parameters only in this example\n",
    "        # siamo sicuri che sia l'ordine gisuto ??\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "\n",
    "        def f():\n",
    "            likelihood = []\n",
    "            for x in theta:\n",
    "                self.env.set_deformation([x[0], x[3]],[x[2],x[1]])\n",
    "                likelihood.append(1 if self.env.is_collision(list(pos)) == obs else 0)\n",
    "            \n",
    "            self.env.set_deformation(self.original_def, [0,0])\n",
    "            return torch.tensor(likelihood, dtype=torch.float32)\n",
    "\n",
    "        likelihood = f()\n",
    "\n",
    "        self.belief_values =  likelihood * self.belief_values\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_plot(agent):\n",
    "    # plot belief values\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(agent.belief_values.detach().numpy().reshape(50, 50))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.4000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4857, 0.6939])\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(agent\u001b[38;5;241m.\u001b[39mbelief_values\u001b[38;5;241m.\u001b[39msum(), torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m])), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelief values do not sum to 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;241m.\u001b[39mbelief_values\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(b \u001b[38;5;241m!=\u001b[39m agent\u001b[38;5;241m.\u001b[39mbelief_points[torch\u001b[38;5;241m.\u001b[39margmax(agent\u001b[38;5;241m.\u001b[39mbelief_values)]):\n",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m, in \u001b[0;36mPOMDPAgent.render_act\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m pomdp_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbelief_update(pomdp_state)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/RoboSurgery/src/environment/env.py:1670\u001b[0m, in \u001b[0;36mGrid.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mset_caption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeformed and Original Gridworld\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;66;03m# Fill background with white\u001b[39;00m\n\u001b[0;32m-> 1670\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWHITE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;66;03m# Compute the bounding box of the deformed grid\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m     corners \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1674\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m   1675\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m   1676\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size,\n\u001b[1;32m   1677\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size[\u001b[38;5;241m1\u001b[39m]]),\n\u001b[1;32m   1678\u001b[0m     ]\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "pomdp_env.reset()\n",
    "pomdp_env.set_deformation([0.5, 0.8],[0,0])\n",
    "\n",
    "#agent = POMDPAgent(pomdp_env,50, update='discrete_modelled', obs_model=obs_model)\n",
    "agent = POMDPAgent(pomdp_env,50)\n",
    "\n",
    "b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "print(b)\n",
    "while True:\n",
    "        agent.render_act()\n",
    "        assert torch.allclose(agent.belief_values.sum(), torch.tensor([1.0])), f\"Belief values do not sum to 1: {agent.belief_values.sum()}\"\n",
    "        if torch.any(b != agent.belief_points[torch.argmax(agent.belief_values)]):\n",
    "            belief_plot(agent)        \n",
    "            b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "            print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIATIONAL UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# Variational distribution q(theta; lambda)\n",
    "class VariationalDistribution(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(VariationalDistribution, self).__init__()\n",
    "        self.mu = nn.Parameter(torch.zeros(dim))  # Mean of q(theta)\n",
    "        self.log_sigma = nn.Parameter(torch.zeros(dim))  # Log std dev of q(theta)\n",
    "    \n",
    "    def sample(self, num_samples=1):\n",
    "        epsilon = torch.randn(num_samples, self.mu.size(0), device=self.mu.device)  # Sample from N(0, I)\n",
    "        sigma = torch.exp(self.log_sigma)\n",
    "        return self.mu + sigma * epsilon  # Reparameterization trick\n",
    "    \n",
    "    def kl_divergence(self, prior_mu, prior_sigma):\n",
    "        # KL divergence between two Gaussians: KL[q || p]\n",
    "        prior = Normal(prior_mu, prior_sigma)\n",
    "        q = Normal(self.mu, torch.exp(self.log_sigma))\n",
    "        return torch.distributions.kl_divergence(q, prior).sum()\n",
    "\n",
    "def compute_elbo(phi_net, variational_dist, prior_mu, prior_sigma, target_o, num_samples=100):\n",
    "    \"\"\"\n",
    "    Compute the Evidence Lower Bound (ELBO) for variational inference.\n",
    "    \"\"\"\n",
    "    # Sample theta ~ q(theta; lambda)\n",
    "    theta_samples = variational_dist.sample(num_samples)\n",
    "    \n",
    "    # Forward pass through phi(theta)\n",
    "    phi_values = phi_net(theta_samples)  # phi(theta)\n",
    "    \n",
    "    # Reconstruction loss (negative log-likelihood approximation)\n",
    "    reconstruction_loss = ((phi_values - target_o) ** 2).mean()\n",
    "    \n",
    "    # KL divergence between q(theta) and prior p(theta)\n",
    "    kl_div = variational_dist.kl_divergence(prior_mu, prior_sigma)\n",
    "    \n",
    "    # ELBO: maximize likelihood - KL divergence\n",
    "    elbo = -reconstruction_loss - kl_div\n",
    "    return elbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    def __init__(self, env: POMDPDeformedGridworld, obs_model):\n",
    "        self.env = env\n",
    "        self.obs_model = obs_model\n",
    "        \n",
    "        # assuming gaussian belief over 4 parameter deformation matrix\n",
    "        self.belief = {\n",
    "            'mean': torch.tensor([0.5, 0.0, 0.0, 0.5], dtype=torch.float32, requires_grad=True),\n",
    "            'cov': torch.eye(4) * 0.1\n",
    "        }\n",
    "\n",
    "        self.prior_mu = self.belief['mean']\n",
    "        self.prior_sigma = self.belief['cov']\n",
    "\n",
    "        self.variational_distribution = VariationalDistribution(4)\n",
    "    \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def belief_update(self, pomdp_state):\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(list(self.obs_model.parameters()) + list(self.variational_distribution.parameters()), lr=1e-2)\n",
    "\n",
    "        # Training loop\n",
    "        num_epochs = 1000\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute ELBO\n",
    "            elbo = compute_elbo(self.obs_model, self.variational_distribution, self.prior_mu, self.prior_sigma, pomdp_state['obs'])\n",
    "            \n",
    "            # Maximize ELBO (minimize negative ELBO)\n",
    "            loss = -elbo\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, ELBO: {elbo.item():.4f}\")\n",
    "\n",
    "\n",
    "        self.prior_mu = self.variational_distribution.mu.detach()\n",
    "        self.prior_sigma = torch.exp(self.variational_distribution.log_sigma.detach())\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NN.forward() missing 2 required positional arguments: 'deform_obs' and 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m POMDPAgent(pomdp_env, obs_model)\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbelief_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpomdp_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mPOMDPAgent.belief_update\u001b[0;34m(self, pomdp_state)\u001b[0m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compute ELBO\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_distribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpomdp_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Maximize ELBO (minimize negative ELBO)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39melbo\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mcompute_elbo\u001b[0;34m(phi_net, variational_dist, prior_mu, prior_sigma, target_o, num_samples)\u001b[0m\n\u001b[1;32m     29\u001b[0m theta_samples \u001b[38;5;241m=\u001b[39m variational_dist\u001b[38;5;241m.\u001b[39msample(num_samples)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Forward pass through phi(theta)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m phi_values \u001b[38;5;241m=\u001b[39m \u001b[43mphi_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_samples\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# phi(theta)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Reconstruction loss (negative log-likelihood approximation)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m ((phi_values \u001b[38;5;241m-\u001b[39m target_o) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: NN.forward() missing 2 required positional arguments: 'deform_obs' and 'theta'"
     ]
    }
   ],
   "source": [
    "agent = POMDPAgent(pomdp_env, obs_model)\n",
    "\n",
    "agent.belief_update(pomdp_env.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64619/1319120195.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9985]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([1.0]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = POMDPAgent(pomdp_env, obs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "pomdp_env.reset()\n",
    "\n",
    "agent = POMDPAgent(pomdp_env, obs_model)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': tensor([0.5000, 0.0000, 0.0000, 0.5000], requires_grad=True),\n",
       " 'cov': tensor([[0.1000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.1000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.1000]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.belief\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Vector Outputs (Multi-class or Multi-dimensional)\n",
    "\n",
    "If h(M)h(M) outputs a vector instead of a scalar, compute the Jacobian as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for vector-valued outputs (e.g., multi-class observation model)\n",
    "mu = torch.tensor([0.5, 0.5, 0.1, 0.1], requires_grad=True)\n",
    "obs_pred = model(mu)  # Assume model now outputs a vector, e.g., shape (3,)\n",
    "jacobian = torch.zeros(obs_pred.shape[0], mu.shape[0])  # Preallocate Jacobian (3x4)\n",
    "\n",
    "# Compute Jacobian row by row\n",
    "for i in range(obs_pred.shape[0]):\n",
    "    model.zero_grad()  # Clear gradients\n",
    "    obs_pred[i].backward(retain_graph=True)  # Backprop for the i-th output\n",
    "    jacobian[i] = mu.grad  # Store the gradient\n",
    "    mu.grad.zero_()  # Reset gradients for next iteration\n",
    "\n",
    "print(\"Jacobian (multi-dimensional output):\")\n",
    "print(jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated belief mean: tensor([-1.6752, -0.7079,  0.0612, -2.2841], grad_fn=<AddBackward0>)\n",
      "Updated belief covariance: tensor([[0.8676, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8676, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8676, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.8676]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the observation model (neural network)\n",
    "class ObservationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObservationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)  # Input: 4D vector, hidden: 16 neurons\n",
    "        self.fc2 = nn.Linear(16, 1)  # Output: scalar (0 or 1)\n",
    "        self.activation = nn.Sigmoid()  # Sigmoid output (probability-like)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Kalman filter update step\n",
    "def kalman_update(mu, P, z, H, R):\n",
    "    \"\"\"\n",
    "    Perform the Kalman update step for the belief.\n",
    "    - mu: Current belief mean\n",
    "    - P: Current belief covariance\n",
    "    - z: Observation (0 or 1)\n",
    "    - H: Jacobian of the observation model\n",
    "    - R: Observation noise covariance\n",
    "    \"\"\"\n",
    "    # Compute the Kalman gain\n",
    "    K = torch.matmul(P, H.T) * torch.inverse(H @ P @ H.T + R).squeeze(0)\n",
    "    \n",
    "    # Update the belief\n",
    "    mu_new = mu + K * (z - H @ mu)\n",
    "    P_new = P - K @ H * P\n",
    "    \n",
    "    return mu_new, P_new\n",
    "\n",
    "# Initialize the neural network\n",
    "model = ObservationModel()\n",
    "\n",
    "# Current belief (Gaussian) parameters: mean (mu) and covariance (P)\n",
    "mu = torch.tensor([0.5, 0.56, 0.1, 0.1], dtype=torch.float32, requires_grad=True)  # Example mean of the belief\n",
    "P = torch.eye(4)  # Example covariance (identity for simplicity)\n",
    "\n",
    "# The observation model is a neural network, so let's predict the observation\n",
    "obs_pred = model(mu)  # Predicted observation for the current belief\n",
    "\n",
    "# For simplicity, assume we have an observation (0 or 1)\n",
    "z = torch.tensor([1.0])  # Example observed value\n",
    "\n",
    "# Compute the Jacobian (derivative of the observation model w.r.t. mu)\n",
    "obs_pred.backward()  # Compute the gradients of the prediction wrt mu\n",
    "H = mu.grad.clone()   # The Jacobian is just the gradient of the output with respect to the input (mu)\n",
    "\n",
    "# Reset gradients for the next iteration\n",
    "mu.grad.zero_()\n",
    "\n",
    "# Assume a simple observation noise model (R)\n",
    "R = torch.tensor([[0.01]])  # Small observation noise\n",
    "\n",
    "# Perform Kalman update\n",
    "mu_new, P_new = kalman_update(mu, P, z, H, R)\n",
    "\n",
    "print(\"Updated belief mean:\", mu_new)\n",
    "print(\"Updated belief covariance:\", P_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8000, 3.3302, 0.7704, 1.9053], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from a Gaussian distribution with mean mu and covariance P using pytorch\n",
    "def sample_gaussian(mu, P):\n",
    "    \"\"\"\n",
    "    Sample from a Gaussian distribution with mean mu and covariance P.\n",
    "    \n",
    "    Parameters:\n",
    "        mu (torch.Tensor): Mean of the Gaussian (vector).\n",
    "        P (torch.Tensor): Covariance matrix of the Gaussian.\n",
    "    \n",
    "    Returns:\n",
    "        sample (torch.Tensor): Sampled value from the Gaussian.\n",
    "    \"\"\"\n",
    "    # Generate a sample from a standard normal distribution\n",
    "    sample = torch.randn_like(mu)\n",
    "    \n",
    "    # Perform Cholesky decomposition of the covariance matrix\n",
    "    L = torch.linalg.cholesky(P)\n",
    "    \n",
    "    # Transform the sample to match the desired covariance\n",
    "    sample = mu + L @ sample\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Example usage\n",
    "sample_gaussian(mu_new, P_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape P torch.Size([4, 4])\n",
      "shape H torch.Size([4])\n",
      "shape R torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Compute the Kalman gain\n",
    "print('shape P', P.shape)\n",
    "print('shape H', H.shape)\n",
    "print('shape R', R.shape)\n",
    "K = torch.matmul(P, H.T) * torch.inverse(H @ P @ H.T + R).squeeze(0)\n",
    "\n",
    "# Update the belief\n",
    "mu_new = mu + K * (z - H @ mu)\n",
    "P_new = P - K @ H * P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1259, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1259, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1259, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1259]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K@ H * P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m P_new \u001b[38;5;241m=\u001b[39m P \u001b[38;5;241m-\u001b[39m \u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "P_new = P - K @ H @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0114, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([87.7421])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(H @ P @ H.T + R).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0451, -0.1558,  0.2192,  0.0721])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_pred = model(mu)  # Predicted observation for the current belief\n",
    "\n",
    "# For simplicity, assume we have an observation (0 or 1)\n",
    "z = torch.tensor([1.0])  # Example observed value\n",
    "\n",
    "# Compute the Jacobian (derivative of the observation model w.r.t. mu)\n",
    "obs_pred.backward()  # Compute the gradients of the prediction wrt mu\n",
    "H = mu.grad.clone()  # The Jacobian is\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  6.,  9., 12.],\n",
       "        [12.,  9.,  6.,  3.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1.0, 2.0, 3.0, 4.0],[4,3,2,1]], dtype=torch.float32, requires_grad=True)\n",
    "t\n",
    "a = 3\n",
    "\n",
    "t*a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
