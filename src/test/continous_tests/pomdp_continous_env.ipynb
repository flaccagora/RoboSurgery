{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "import torch\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import POMDPDeformedGridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ,weights_only=True))\n",
    "\n",
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([1.0]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRETE BELIEF UPDATE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    def __init__(self, env: POMDPDeformedGridworld, discretization=10, update='discrete_exact', obs_model=None):\n",
    "        self.env = env\n",
    "\n",
    "        if update == 'discrete_modelled': \n",
    "            assert obs_model is not None\n",
    "            self.obs_model = obs_model\n",
    "            # assuming discrete belief over 2 parameters\n",
    "            belief_points = np.linspace(env.stretch_range[0], env.stretch_range[1], discretization) \n",
    "            # zip belief points in every combination\n",
    "            import itertools\n",
    "            self.tmp_belief_points = { bp:0 for bp in itertools.product(belief_points, belief_points) }\n",
    "            self.belief_points = torch.tensor(list(self.tmp_belief_points.keys()), dtype=torch.float32)\n",
    "\n",
    "            self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(self.tmp_belief_points.keys())\n",
    "\n",
    "            self.belief_update = self.discrete_belief_update\n",
    "        \n",
    "        elif update == 'discrete_exact':\n",
    "                        # assuming discrete belief over 2 parameters\n",
    "            belief_points = np.linspace(env.stretch_range[0], env.stretch_range[1], discretization) \n",
    "            # zip belief points in every combination\n",
    "            import itertools\n",
    "            self.tmp_belief_points = { bp:0 for bp in itertools.product(belief_points, belief_points) }\n",
    "            self.belief_points = torch.tensor(list(self.tmp_belief_points.keys()), dtype=torch.float32)\n",
    "\n",
    "            self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(self.tmp_belief_points.keys())\n",
    "\n",
    "            self.belief_update = self.exact_belief_update\n",
    "        else:\n",
    "            raise NotImplementedError('Only discrete belief update is supported')\n",
    "        \n",
    "        self.original_def = env.transformation_matrix[0][0], env.transformation_matrix[1][1]\n",
    "        \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def discrete_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        batch_pos = pos.repeat(len(self.belief_points), 1)\n",
    "        batch_obs = obs.repeat(len(self.belief_points), 1)\n",
    "        \n",
    "        # need theta because working on two parameters only in this example\n",
    "        # siamo sicuri che sia l'ordine gisuto ??\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "        \n",
    "\n",
    "        likelihood = torch.distributions.Bernoulli(self.obs_model(batch_pos,batch_obs,theta)).sample()\n",
    "        self.belief_values =  torch.einsum(\"ij,j->i\",likelihood, self.belief_values)\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "    \n",
    "    def exact_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        # need theta because working on two parameters only in this example\n",
    "        # siamo sicuri che sia l'ordine gisuto ??\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "\n",
    "        def f():\n",
    "            likelihood = []\n",
    "            for x in theta:\n",
    "                self.env.set_deformation([x[0], x[3]],[x[2],x[1]])\n",
    "                likelihood.append(torch.all(torch.tensor(self.env.observe(list(pos))) == obs))\n",
    "            \n",
    "            self.env.set_deformation(self.original_def, [0,0])\n",
    "            return torch.tensor(likelihood, dtype=torch.float32)\n",
    "\n",
    "        likelihood = f()\n",
    "\n",
    "        self.belief_values =  likelihood * self.belief_values\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from io import BytesIO\n",
    "# Modify belief_plot to save as an image\n",
    "def belief_plot(agent):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()    \n",
    "    # (Add your plotting logic here)\n",
    "    plt.imshow(agent.belief_values.detach().numpy().reshape(50, 50))\n",
    "    # Save the figure to an in-memory buffer\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")  # Save as PNG into the buffer\n",
    "    plt.close()  # Close the plot to avoid memory leaks\n",
    "    buf.seek(0)  # Move to the beginning of the buffer\n",
    "\n",
    "    # Open the image from the buffer\n",
    "    return Image.open(buf)    \n",
    "\n",
    "def create_gif(images, filename=\"belief_animation.gif\", duration=100, loop=0):\n",
    "    \"\"\"\n",
    "    Create a GIF from a list of PIL Image objects.\n",
    "    \n",
    "    Args:\n",
    "        images (list): A list of PIL Image objects.\n",
    "        filename (str): Name of the output GIF file.\n",
    "        duration (int): Duration of each frame in milliseconds.\n",
    "        loop (int): Number of times to loop the GIF. 0 means infinite.\n",
    "    \"\"\"\n",
    "    if images:\n",
    "        images[0].save(\n",
    "            filename,\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=duration,\n",
    "            loop=loop\n",
    "        )\n",
    "        print(f\"GIF saved as {filename}\")\n",
    "    else:\n",
    "        print(\"No images to create a GIF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.4000])\n",
      "tensor([0.4980, 0.6571])\n",
      "tensor([0.4980, 0.6939])\n",
      "tensor([0.4980, 0.7306])\n",
      "tensor([0.4980, 0.7673])\n",
      "tensor([0.4980, 0.7918])\n"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld(obs_type='cardinal')\n",
    "pomdp_env.reset()\n",
    "pomdp_env.set_deformation([0.5, 0.8],[0,0])\n",
    "\n",
    "# agent = POMDPAgent(pomdp_env,50, update='discrete_modelled', obs_model=obs_model)\n",
    "agent = POMDPAgent(pomdp_env,50)\n",
    "\n",
    "images = []\n",
    "b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "img = belief_plot(agent)\n",
    "images.append(img)      \n",
    "\n",
    "print(b)\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "        img = belief_plot(agent)\n",
    "        images.append(img)      \n",
    "        assert torch.allclose(agent.belief_values.sum(), torch.tensor([1.0])), f\"Belief values do not sum to 1: {agent.belief_values.sum()}\"\n",
    "        if torch.any(b != agent.belief_points[torch.argmax(agent.belief_values)]):\n",
    "            b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "            print(b)\n",
    "    except:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as belief_animation_cardinal.gif\n"
     ]
    }
   ],
   "source": [
    "create_gif(images, filename=\"belief_animation_cardinal.gif\", duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "pomdp_env.reset()\n",
    "pomdp_env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIATIONAL UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# Variational distribution q(theta; lambda)\n",
    "class VariationalDistribution(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(VariationalDistribution, self).__init__()\n",
    "        self.mu = nn.Parameter(torch.zeros(dim))  # Mean of q(theta)\n",
    "        self.log_sigma = nn.Parameter(torch.zeros(dim))  # Log std dev of q(theta)\n",
    "    \n",
    "    def sample(self, num_samples=1):\n",
    "        epsilon = torch.randn(num_samples, self.mu.size(0), device=self.mu.device)  # Sample from N(0, I)\n",
    "        sigma = torch.exp(self.log_sigma)\n",
    "        return self.mu + sigma * epsilon  # Reparameterization trick\n",
    "    \n",
    "    def kl_divergence(self, prior_mu, prior_sigma):\n",
    "        # KL divergence between two Gaussians: KL[q || p]\n",
    "        prior = Normal(prior_mu, prior_sigma)\n",
    "        q = Normal(self.mu, torch.exp(self.log_sigma))\n",
    "        return torch.distributions.kl_divergence(q, prior).sum()\n",
    "\n",
    "def compute_elbo(phi_net, variational_dist, prior_mu, prior_sigma, target_o, num_samples=100):\n",
    "    \"\"\"\n",
    "    Compute the Evidence Lower Bound (ELBO) for variational inference.\n",
    "    \"\"\"\n",
    "    # Sample theta ~ q(theta; lambda)\n",
    "    theta_samples = variational_dist.sample(num_samples)\n",
    "    \n",
    "    # Forward pass through phi(theta)\n",
    "    phi_values = phi_net(theta_samples)  # phi(theta)\n",
    "    \n",
    "    # Reconstruction loss (negative log-likelihood approximation)\n",
    "    reconstruction_loss = ((phi_values - target_o) ** 2).mean()\n",
    "    \n",
    "    # KL divergence between q(theta) and prior p(theta)\n",
    "    kl_div = variational_dist.kl_divergence(prior_mu, prior_sigma)\n",
    "    \n",
    "    # ELBO: maximize likelihood - KL divergence\n",
    "    elbo = -reconstruction_loss - kl_div\n",
    "    return elbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    def __init__(self, env: POMDPDeformedGridworld, obs_model):\n",
    "        self.env = env\n",
    "        self.obs_model = obs_model\n",
    "        \n",
    "        # assuming gaussian belief over 4 parameter deformation matrix\n",
    "        self.belief = {\n",
    "            'mean': torch.tensor([0.5, 0.0, 0.0, 0.5], dtype=torch.float32, requires_grad=True),\n",
    "            'cov': torch.eye(4) * 0.1\n",
    "        }\n",
    "\n",
    "        self.prior_mu = self.belief['mean']\n",
    "        self.prior_sigma = self.belief['cov']\n",
    "\n",
    "        self.variational_distribution = VariationalDistribution(4)\n",
    "    \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def belief_update(self, pomdp_state):\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(list(self.obs_model.parameters()) + list(self.variational_distribution.parameters()), lr=1e-2)\n",
    "\n",
    "        # Training loop\n",
    "        num_epochs = 1000\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute ELBO\n",
    "            elbo = compute_elbo(self.obs_model, self.variational_distribution, self.prior_mu, self.prior_sigma, pomdp_state['obs'])\n",
    "            \n",
    "            # Maximize ELBO (minimize negative ELBO)\n",
    "            loss = -elbo\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, ELBO: {elbo.item():.4f}\")\n",
    "\n",
    "\n",
    "        self.prior_mu = self.variational_distribution.mu.detach()\n",
    "        self.prior_sigma = torch.exp(self.variational_distribution.log_sigma.detach())\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NN.forward() missing 2 required positional arguments: 'deform_obs' and 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m POMDPAgent(pomdp_env, obs_model)\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbelief_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpomdp_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mPOMDPAgent.belief_update\u001b[0;34m(self, pomdp_state)\u001b[0m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compute ELBO\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_distribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpomdp_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Maximize ELBO (minimize negative ELBO)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39melbo\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mcompute_elbo\u001b[0;34m(phi_net, variational_dist, prior_mu, prior_sigma, target_o, num_samples)\u001b[0m\n\u001b[1;32m     29\u001b[0m theta_samples \u001b[38;5;241m=\u001b[39m variational_dist\u001b[38;5;241m.\u001b[39msample(num_samples)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Forward pass through phi(theta)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m phi_values \u001b[38;5;241m=\u001b[39m \u001b[43mphi_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_samples\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# phi(theta)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Reconstruction loss (negative log-likelihood approximation)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m ((phi_values \u001b[38;5;241m-\u001b[39m target_o) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: NN.forward() missing 2 required positional arguments: 'deform_obs' and 'theta'"
     ]
    }
   ],
   "source": [
    "agent = POMDPAgent(pomdp_env, obs_model)\n",
    "\n",
    "agent.belief_update(pomdp_env.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64619/1319120195.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9985]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([1.0]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = POMDPAgent(pomdp_env, obs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "pomdp_env.reset()\n",
    "\n",
    "agent = POMDPAgent(pomdp_env, obs_model)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': tensor([0.5000, 0.0000, 0.0000, 0.5000], requires_grad=True),\n",
       " 'cov': tensor([[0.1000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.1000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.1000]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.belief\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Vector Outputs (Multi-class or Multi-dimensional)\n",
    "\n",
    "If h(M)h(M) outputs a vector instead of a scalar, compute the Jacobian as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for vector-valued outputs (e.g., multi-class observation model)\n",
    "mu = torch.tensor([0.5, 0.5, 0.1, 0.1], requires_grad=True)\n",
    "obs_pred = model(mu)  # Assume model now outputs a vector, e.g., shape (3,)\n",
    "jacobian = torch.zeros(obs_pred.shape[0], mu.shape[0])  # Preallocate Jacobian (3x4)\n",
    "\n",
    "# Compute Jacobian row by row\n",
    "for i in range(obs_pred.shape[0]):\n",
    "    model.zero_grad()  # Clear gradients\n",
    "    obs_pred[i].backward(retain_graph=True)  # Backprop for the i-th output\n",
    "    jacobian[i] = mu.grad  # Store the gradient\n",
    "    mu.grad.zero_()  # Reset gradients for next iteration\n",
    "\n",
    "print(\"Jacobian (multi-dimensional output):\")\n",
    "print(jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated belief mean: tensor([-1.6752, -0.7079,  0.0612, -2.2841], grad_fn=<AddBackward0>)\n",
      "Updated belief covariance: tensor([[0.8676, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8676, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8676, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.8676]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the observation model (neural network)\n",
    "class ObservationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObservationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)  # Input: 4D vector, hidden: 16 neurons\n",
    "        self.fc2 = nn.Linear(16, 1)  # Output: scalar (0 or 1)\n",
    "        self.activation = nn.Sigmoid()  # Sigmoid output (probability-like)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Kalman filter update step\n",
    "def kalman_update(mu, P, z, H, R):\n",
    "    \"\"\"\n",
    "    Perform the Kalman update step for the belief.\n",
    "    - mu: Current belief mean\n",
    "    - P: Current belief covariance\n",
    "    - z: Observation (0 or 1)\n",
    "    - H: Jacobian of the observation model\n",
    "    - R: Observation noise covariance\n",
    "    \"\"\"\n",
    "    # Compute the Kalman gain\n",
    "    K = torch.matmul(P, H.T) * torch.inverse(H @ P @ H.T + R).squeeze(0)\n",
    "    \n",
    "    # Update the belief\n",
    "    mu_new = mu + K * (z - H @ mu)\n",
    "    P_new = P - K @ H * P\n",
    "    \n",
    "    return mu_new, P_new\n",
    "\n",
    "# Initialize the neural network\n",
    "model = ObservationModel()\n",
    "\n",
    "# Current belief (Gaussian) parameters: mean (mu) and covariance (P)\n",
    "mu = torch.tensor([0.5, 0.56, 0.1, 0.1], dtype=torch.float32, requires_grad=True)  # Example mean of the belief\n",
    "P = torch.eye(4)  # Example covariance (identity for simplicity)\n",
    "\n",
    "# The observation model is a neural network, so let's predict the observation\n",
    "obs_pred = model(mu)  # Predicted observation for the current belief\n",
    "\n",
    "# For simplicity, assume we have an observation (0 or 1)\n",
    "z = torch.tensor([1.0])  # Example observed value\n",
    "\n",
    "# Compute the Jacobian (derivative of the observation model w.r.t. mu)\n",
    "obs_pred.backward()  # Compute the gradients of the prediction wrt mu\n",
    "H = mu.grad.clone()   # The Jacobian is just the gradient of the output with respect to the input (mu)\n",
    "\n",
    "# Reset gradients for the next iteration\n",
    "mu.grad.zero_()\n",
    "\n",
    "# Assume a simple observation noise model (R)\n",
    "R = torch.tensor([[0.01]])  # Small observation noise\n",
    "\n",
    "# Perform Kalman update\n",
    "mu_new, P_new = kalman_update(mu, P, z, H, R)\n",
    "\n",
    "print(\"Updated belief mean:\", mu_new)\n",
    "print(\"Updated belief covariance:\", P_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8000, 3.3302, 0.7704, 1.9053], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from a Gaussian distribution with mean mu and covariance P using pytorch\n",
    "def sample_gaussian(mu, P):\n",
    "    \"\"\"\n",
    "    Sample from a Gaussian distribution with mean mu and covariance P.\n",
    "    \n",
    "    Parameters:\n",
    "        mu (torch.Tensor): Mean of the Gaussian (vector).\n",
    "        P (torch.Tensor): Covariance matrix of the Gaussian.\n",
    "    \n",
    "    Returns:\n",
    "        sample (torch.Tensor): Sampled value from the Gaussian.\n",
    "    \"\"\"\n",
    "    # Generate a sample from a standard normal distribution\n",
    "    sample = torch.randn_like(mu)\n",
    "    \n",
    "    # Perform Cholesky decomposition of the covariance matrix\n",
    "    L = torch.linalg.cholesky(P)\n",
    "    \n",
    "    # Transform the sample to match the desired covariance\n",
    "    sample = mu + L @ sample\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Example usage\n",
    "sample_gaussian(mu_new, P_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape P torch.Size([4, 4])\n",
      "shape H torch.Size([4])\n",
      "shape R torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Compute the Kalman gain\n",
    "print('shape P', P.shape)\n",
    "print('shape H', H.shape)\n",
    "print('shape R', R.shape)\n",
    "K = torch.matmul(P, H.T) * torch.inverse(H @ P @ H.T + R).squeeze(0)\n",
    "\n",
    "# Update the belief\n",
    "mu_new = mu + K * (z - H @ mu)\n",
    "P_new = P - K @ H * P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1259, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1259, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1259, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1259]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K@ H * P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m P_new \u001b[38;5;241m=\u001b[39m P \u001b[38;5;241m-\u001b[39m \u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "P_new = P - K @ H @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0114, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([87.7421])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(H @ P @ H.T + R).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0451, -0.1558,  0.2192,  0.0721])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_pred = model(mu)  # Predicted observation for the current belief\n",
    "\n",
    "# For simplicity, assume we have an observation (0 or 1)\n",
    "z = torch.tensor([1.0])  # Example observed value\n",
    "\n",
    "# Compute the Jacobian (derivative of the observation model w.r.t. mu)\n",
    "obs_pred.backward()  # Compute the gradients of the prediction wrt mu\n",
    "H = mu.grad.clone()  # The Jacobian is\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  6.,  9., 12.],\n",
       "        [12.,  9.,  6.,  3.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1.0, 2.0, 3.0, 4.0],[4,3,2,1]], dtype=torch.float32, requires_grad=True)\n",
    "t\n",
    "a = 3\n",
    "\n",
    "t*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.4000])\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[True, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, True, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, False, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[False, False, True, False]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, True, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n",
      "[False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "pomdp_env.reset()\n",
    "pomdp_env.set_deformation([0.5, 0.8],[0,0])\n",
    "\n",
    "# agent = POMDPAgent(pomdp_env,50, update='discrete_modelled', obs_model=obs_model)\n",
    "agent = POMDPAgent(pomdp_env,50)\n",
    "\n",
    "images = []\n",
    "b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "print(b)\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "        print(agent.env.is_collision_cardinal(list(agent.env.get_state()['pos'])))\n",
    "    except:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[E,W,N,S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
