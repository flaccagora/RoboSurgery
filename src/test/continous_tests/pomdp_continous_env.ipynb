{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Discrete, Box\n",
    "import torch\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from environment.env import POMDPDeformedGridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ,weights_only=True))\n",
    "\n",
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([1.0]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRETE BELIEF UPDATE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    def __init__(self, env: POMDPDeformedGridworld, obs_model, discretization=10, update='discrete'):\n",
    "        self.env = env\n",
    "        self.obs_model = obs_model\n",
    "\n",
    "        if update == 'discrete': \n",
    "            # assuming discrete belief over 2 parameters\n",
    "            belief_points = np.linspace(env.stretch_range[0], env.stretch_range[1], discretization) \n",
    "            # zip belief points in every combination\n",
    "            import itertools\n",
    "            self.tmp_belief_points = { bp:0 for bp in itertools.product(belief_points, belief_points) }\n",
    "            self.belief_points = torch.tensor(list(self.tmp_belief_points.keys()), dtype=torch.float32)\n",
    "\n",
    "            self.belief_values = torch.ones(self.belief_points.shape[0], dtype=torch.float32) / len(self.tmp_belief_points.keys())\n",
    "\n",
    "            self.belief_update = self.discrete_belief_update\n",
    "        else:\n",
    "            raise NotImplementedError('Only discrete belief update is supported')\n",
    "        \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def discrete_belief_update(self, pomdp_state):\n",
    "        \"\"\"discrete belief update\"\"\"\n",
    "        obs = pomdp_state['obs']\n",
    "        pos = pomdp_state['pos']\n",
    "\n",
    "        batch_pos = pos.repeat(len(self.belief_points), 1)\n",
    "        batch_obs = obs.repeat(len(self.belief_points), 1)\n",
    "        \n",
    "        # need theta because working on two parameters only in this example\n",
    "        # siamo sicuri che sia l'ordine gisuto ??\n",
    "        theta = torch.cat([self.belief_points, torch.zeros(len(self.belief_points), 2)], dim=1)\n",
    "        # permute theta to match the order of pos\n",
    "        theta = theta[:, [0,3,2,1]]\n",
    "        \n",
    "\n",
    "        likelihood = self.obs_model(batch_pos,batch_obs, theta)\n",
    "        self.belief_values =  torch.einsum(\"ij,j->i\",likelihood, self.belief_values)\n",
    "        self.belief_values = self.belief_values / self.belief_values.sum()\n",
    "        \n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "agent = POMDPAgent(pomdp_env, obs_model, discretization=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.4947])\n",
      "tensor([0.4000, 0.4632])\n",
      "tensor([0.4000, 0.4947])\n",
      "tensor([0.4000, 0.4632])\n",
      "tensor([0.4000, 0.4947])\n",
      "tensor([0.4000, 1.0000])\n",
      "tensor([1.0000, 0.6526])\n",
      "tensor([1., 1.])\n",
      "tensor([0.4000, 1.0000])\n",
      "tensor([0.4000, 0.4947])\n",
      "tensor([0.4000, 0.4000])\n",
      "tensor([0.4000, 0.4316])\n",
      "tensor([0.4632, 1.0000])\n",
      "tensor([0.5895, 0.9684])\n",
      "tensor([0.6211, 0.9684])\n",
      "tensor([0.4000, 0.5579])\n",
      "tensor([0.4316, 0.4632])\n",
      "tensor([0.4000, 0.4000])\n",
      "tensor([1., 1.])\n",
      "tensor([1.0000, 0.4000])\n",
      "tensor([0.7789, 0.4000])\n",
      "tensor([1.0000, 0.4000])\n",
      "tensor([0.4000, 1.0000])\n",
      "tensor([0.7789, 0.4000])\n",
      "tensor([1.0000, 0.4000])\n",
      "tensor([0.4000, 1.0000])\n",
      "tensor([0.7789, 0.4000])\n",
      "tensor([1.0000, 0.4000])\n",
      "raised exception\n"
     ]
    }
   ],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "\n",
    "pomdp_env.set_deformation([0.5, 0.8],[0,0])\n",
    "\n",
    "agent = POMDPAgent(pomdp_env, obs_model,20)\n",
    "b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "        assert torch.allclose(agent.belief_values.sum(), torch.tensor([1.0])), f\"Belief values do not sum to 1: {agent.belief_values.sum()}\"\n",
    "        # print(agent.belief_values)\n",
    "        # print argmax\n",
    "        if torch.any(b != agent.belief_points[torch.argmax(agent.belief_values)]):\n",
    "            b = agent.belief_points[torch.argmax(agent.belief_values)]\n",
    "            print(b)\n",
    "    except:\n",
    "        print('raised exception')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Belief values do not sum to 1: nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(agent\u001b[38;5;241m.\u001b[39mbelief_values\u001b[38;5;241m.\u001b[39msum(), torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m])), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelief values do not sum to 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;241m.\u001b[39mbelief_values\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Belief values do not sum to 1: nan"
     ]
    }
   ],
   "source": [
    "assert torch.allclose(agent.belief_values.sum(), torch.tensor([1.0])), f\"Belief values do not sum to 1: {agent.belief_values.sum()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot belief values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(agent.belief_values.detach().numpy().reshape(20, 20))\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIATIONAL UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# Variational distribution q(theta; lambda)\n",
    "class VariationalDistribution(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(VariationalDistribution, self).__init__()\n",
    "        self.mu = nn.Parameter(torch.zeros(dim))  # Mean of q(theta)\n",
    "        self.log_sigma = nn.Parameter(torch.zeros(dim))  # Log std dev of q(theta)\n",
    "    \n",
    "    def sample(self, num_samples=1):\n",
    "        epsilon = torch.randn(num_samples, self.mu.size(0), device=self.mu.device)  # Sample from N(0, I)\n",
    "        sigma = torch.exp(self.log_sigma)\n",
    "        return self.mu + sigma * epsilon  # Reparameterization trick\n",
    "    \n",
    "    def kl_divergence(self, prior_mu, prior_sigma):\n",
    "        # KL divergence between two Gaussians: KL[q || p]\n",
    "        prior = Normal(prior_mu, prior_sigma)\n",
    "        q = Normal(self.mu, torch.exp(self.log_sigma))\n",
    "        return torch.distributions.kl_divergence(q, prior).sum()\n",
    "\n",
    "def compute_elbo(phi_net, variational_dist, prior_mu, prior_sigma, target_o, num_samples=100):\n",
    "    \"\"\"\n",
    "    Compute the Evidence Lower Bound (ELBO) for variational inference.\n",
    "    \"\"\"\n",
    "    # Sample theta ~ q(theta; lambda)\n",
    "    theta_samples = variational_dist.sample(num_samples)\n",
    "    \n",
    "    # Forward pass through phi(theta)\n",
    "    phi_values = phi_net(theta_samples)  # phi(theta)\n",
    "    \n",
    "    # Reconstruction loss (negative log-likelihood approximation)\n",
    "    reconstruction_loss = ((phi_values - target_o) ** 2).mean()\n",
    "    \n",
    "    # KL divergence between q(theta) and prior p(theta)\n",
    "    kl_div = variational_dist.kl_divergence(prior_mu, prior_sigma)\n",
    "    \n",
    "    # ELBO: maximize likelihood - KL divergence\n",
    "    elbo = -reconstruction_loss - kl_div\n",
    "    return elbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POMDPAgent():\n",
    "    def __init__(self, env: POMDPDeformedGridworld, obs_model):\n",
    "        self.env = env\n",
    "        self.obs_model = obs_model\n",
    "        \n",
    "        # assuming gaussian belief over 4 parameter deformation matrix\n",
    "        self.belief = {\n",
    "            'mean': torch.tensor([0.5, 0.0, 0.0, 0.5], dtype=torch.float32, requires_grad=True),\n",
    "            'cov': torch.eye(4) * 0.1\n",
    "        }\n",
    "\n",
    "        self.prior_mu = self.belief['mean']\n",
    "        self.prior_sigma = self.belief['cov']\n",
    "\n",
    "        self.variational_distribution = VariationalDistribution(4)\n",
    "    \n",
    "    def act(self):\n",
    "        action = input('Enter action: ')\n",
    "        pomdp_state, reward, terminated,truncated, info = self.env.step(int(action))\n",
    "        print(pomdp_state)\n",
    "        self.belief_update(pomdp_state)\n",
    "\n",
    "    def belief_update(self, pomdp_state):\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(list(self.obs_model.parameters()) + list(self.variational_distribution.parameters()), lr=1e-2)\n",
    "\n",
    "        # Training loop\n",
    "        num_epochs = 1000\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute ELBO\n",
    "            elbo = compute_elbo(self.obs_model, self.variational_distribution, self.prior_mu, self.prior_sigma, pomdp_state['obs'])\n",
    "            \n",
    "            # Maximize ELBO (minimize negative ELBO)\n",
    "            loss = -elbo\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, ELBO: {elbo.item():.4f}\")\n",
    "\n",
    "\n",
    "        self.prior_mu = self.variational_distribution.mu.detach()\n",
    "        self.prior_sigma = torch.exp(self.variational_distribution.log_sigma.detach())\n",
    "\n",
    "    def render_act(self):\n",
    "        \"\"\"For testing belief convergence\"\"\"\n",
    "        pomdp_state = self.env.get_state()\n",
    "        self.belief_update(pomdp_state)\n",
    "        self.env.render()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NN.forward() missing 2 required positional arguments: 'deform_obs' and 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m POMDPAgent(pomdp_env, obs_model)\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbelief_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpomdp_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mPOMDPAgent.belief_update\u001b[0;34m(self, pomdp_state)\u001b[0m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compute ELBO\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_distribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpomdp_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Maximize ELBO (minimize negative ELBO)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39melbo\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mcompute_elbo\u001b[0;34m(phi_net, variational_dist, prior_mu, prior_sigma, target_o, num_samples)\u001b[0m\n\u001b[1;32m     29\u001b[0m theta_samples \u001b[38;5;241m=\u001b[39m variational_dist\u001b[38;5;241m.\u001b[39msample(num_samples)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Forward pass through phi(theta)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m phi_values \u001b[38;5;241m=\u001b[39m \u001b[43mphi_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_samples\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# phi(theta)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Reconstruction loss (negative log-likelihood approximation)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m ((phi_values \u001b[38;5;241m-\u001b[39m target_o) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/robogym/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: NN.forward() missing 2 required positional arguments: 'deform_obs' and 'theta'"
     ]
    }
   ],
   "source": [
    "agent = POMDPAgent(pomdp_env, obs_model)\n",
    "\n",
    "agent.belief_update(pomdp_env.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64619/1319120195.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(7, 128)\n",
    "        self.f2 = nn.Linear(128, 128)\n",
    "        self.f3 = nn.Linear(128, 128)\n",
    "        self.f4 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, pos,deform_obs,theta):\n",
    "        x = torch.cat([pos,deform_obs,theta], dim=1)\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = F.sigmoid(self.f4(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "obs_model = NN()\n",
    "\n",
    "# Load the model\n",
    "obs_model.load_state_dict(torch.load('obs_model.pth',map_location=torch.device('cpu') ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9985]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_model.eval()\n",
    "obs_model(torch.tensor([0.5, 0.5]).unsqueeze(0), torch.tensor([1.0]).unsqueeze(0), torch.tensor([0.5, 0.0, 0.0, 0.5]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = POMDPAgent(pomdp_env, obs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomdp_env = POMDPDeformedGridworld()\n",
    "pomdp_env.reset()\n",
    "\n",
    "agent = POMDPAgent(pomdp_env, obs_model)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        agent.render_act()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': tensor([0.5000, 0.0000, 0.0000, 0.5000], requires_grad=True),\n",
       " 'cov': tensor([[0.1000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.1000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.1000]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.belief\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Vector Outputs (Multi-class or Multi-dimensional)\n",
    "\n",
    "If h(M)h(M) outputs a vector instead of a scalar, compute the Jacobian as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for vector-valued outputs (e.g., multi-class observation model)\n",
    "mu = torch.tensor([0.5, 0.5, 0.1, 0.1], requires_grad=True)\n",
    "obs_pred = model(mu)  # Assume model now outputs a vector, e.g., shape (3,)\n",
    "jacobian = torch.zeros(obs_pred.shape[0], mu.shape[0])  # Preallocate Jacobian (3x4)\n",
    "\n",
    "# Compute Jacobian row by row\n",
    "for i in range(obs_pred.shape[0]):\n",
    "    model.zero_grad()  # Clear gradients\n",
    "    obs_pred[i].backward(retain_graph=True)  # Backprop for the i-th output\n",
    "    jacobian[i] = mu.grad  # Store the gradient\n",
    "    mu.grad.zero_()  # Reset gradients for next iteration\n",
    "\n",
    "print(\"Jacobian (multi-dimensional output):\")\n",
    "print(jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated belief mean: tensor([-1.6752, -0.7079,  0.0612, -2.2841], grad_fn=<AddBackward0>)\n",
      "Updated belief covariance: tensor([[0.8676, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8676, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8676, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.8676]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the observation model (neural network)\n",
    "class ObservationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObservationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)  # Input: 4D vector, hidden: 16 neurons\n",
    "        self.fc2 = nn.Linear(16, 1)  # Output: scalar (0 or 1)\n",
    "        self.activation = nn.Sigmoid()  # Sigmoid output (probability-like)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Kalman filter update step\n",
    "def kalman_update(mu, P, z, H, R):\n",
    "    \"\"\"\n",
    "    Perform the Kalman update step for the belief.\n",
    "    - mu: Current belief mean\n",
    "    - P: Current belief covariance\n",
    "    - z: Observation (0 or 1)\n",
    "    - H: Jacobian of the observation model\n",
    "    - R: Observation noise covariance\n",
    "    \"\"\"\n",
    "    # Compute the Kalman gain\n",
    "    K = torch.matmul(P, H.T) * torch.inverse(H @ P @ H.T + R).squeeze(0)\n",
    "    \n",
    "    # Update the belief\n",
    "    mu_new = mu + K * (z - H @ mu)\n",
    "    P_new = P - K @ H * P\n",
    "    \n",
    "    return mu_new, P_new\n",
    "\n",
    "# Initialize the neural network\n",
    "model = ObservationModel()\n",
    "\n",
    "# Current belief (Gaussian) parameters: mean (mu) and covariance (P)\n",
    "mu = torch.tensor([0.5, 0.56, 0.1, 0.1], dtype=torch.float32, requires_grad=True)  # Example mean of the belief\n",
    "P = torch.eye(4)  # Example covariance (identity for simplicity)\n",
    "\n",
    "# The observation model is a neural network, so let's predict the observation\n",
    "obs_pred = model(mu)  # Predicted observation for the current belief\n",
    "\n",
    "# For simplicity, assume we have an observation (0 or 1)\n",
    "z = torch.tensor([1.0])  # Example observed value\n",
    "\n",
    "# Compute the Jacobian (derivative of the observation model w.r.t. mu)\n",
    "obs_pred.backward()  # Compute the gradients of the prediction wrt mu\n",
    "H = mu.grad.clone()   # The Jacobian is just the gradient of the output with respect to the input (mu)\n",
    "\n",
    "# Reset gradients for the next iteration\n",
    "mu.grad.zero_()\n",
    "\n",
    "# Assume a simple observation noise model (R)\n",
    "R = torch.tensor([[0.01]])  # Small observation noise\n",
    "\n",
    "# Perform Kalman update\n",
    "mu_new, P_new = kalman_update(mu, P, z, H, R)\n",
    "\n",
    "print(\"Updated belief mean:\", mu_new)\n",
    "print(\"Updated belief covariance:\", P_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8000, 3.3302, 0.7704, 1.9053], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from a Gaussian distribution with mean mu and covariance P using pytorch\n",
    "def sample_gaussian(mu, P):\n",
    "    \"\"\"\n",
    "    Sample from a Gaussian distribution with mean mu and covariance P.\n",
    "    \n",
    "    Parameters:\n",
    "        mu (torch.Tensor): Mean of the Gaussian (vector).\n",
    "        P (torch.Tensor): Covariance matrix of the Gaussian.\n",
    "    \n",
    "    Returns:\n",
    "        sample (torch.Tensor): Sampled value from the Gaussian.\n",
    "    \"\"\"\n",
    "    # Generate a sample from a standard normal distribution\n",
    "    sample = torch.randn_like(mu)\n",
    "    \n",
    "    # Perform Cholesky decomposition of the covariance matrix\n",
    "    L = torch.linalg.cholesky(P)\n",
    "    \n",
    "    # Transform the sample to match the desired covariance\n",
    "    sample = mu + L @ sample\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Example usage\n",
    "sample_gaussian(mu_new, P_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape P torch.Size([4, 4])\n",
      "shape H torch.Size([4])\n",
      "shape R torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Compute the Kalman gain\n",
    "print('shape P', P.shape)\n",
    "print('shape H', H.shape)\n",
    "print('shape R', R.shape)\n",
    "K = torch.matmul(P, H.T) * torch.inverse(H @ P @ H.T + R).squeeze(0)\n",
    "\n",
    "# Update the belief\n",
    "mu_new = mu + K * (z - H @ mu)\n",
    "P_new = P - K @ H * P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1259, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1259, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1259, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1259]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K@ H * P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m P_new \u001b[38;5;241m=\u001b[39m P \u001b[38;5;241m-\u001b[39m \u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "P_new = P - K @ H @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0114, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([87.7421])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(H @ P @ H.T + R).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0451, -0.1558,  0.2192,  0.0721])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_pred = model(mu)  # Predicted observation for the current belief\n",
    "\n",
    "# For simplicity, assume we have an observation (0 or 1)\n",
    "z = torch.tensor([1.0])  # Example observed value\n",
    "\n",
    "# Compute the Jacobian (derivative of the observation model w.r.t. mu)\n",
    "obs_pred.backward()  # Compute the gradients of the prediction wrt mu\n",
    "H = mu.grad.clone()  # The Jacobian is\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  6.,  9., 12.],\n",
       "        [12.,  9.,  6.,  3.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1.0, 2.0, 3.0, 4.0],[4,3,2,1]], dtype=torch.float32, requires_grad=True)\n",
    "t\n",
    "a = 3\n",
    "\n",
    "t*a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
